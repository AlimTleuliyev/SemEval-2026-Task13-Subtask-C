{
  "best_global_step": 10000,
  "best_metric": 0.8679424026858762,
  "best_model_checkpoint": "./models/modernbert_base_full/checkpoint-10000",
  "epoch": 3.0,
  "eval_steps": 1000,
  "global_step": 10548,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00028443433122377873,
      "grad_norm": Infinity,
      "learning_rate": 0.0,
      "loss": 7.0803,
      "step": 1
    },
    {
      "epoch": 0.028443433122377872,
      "grad_norm": 11.802011489868164,
      "learning_rate": 1.8767772511848342e-06,
      "loss": 5.2144,
      "step": 100
    },
    {
      "epoch": 0.056886866244755745,
      "grad_norm": 26.429576873779297,
      "learning_rate": 3.772511848341233e-06,
      "loss": 3.4706,
      "step": 200
    },
    {
      "epoch": 0.08533029936713361,
      "grad_norm": 27.84320068359375,
      "learning_rate": 5.66824644549763e-06,
      "loss": 2.6236,
      "step": 300
    },
    {
      "epoch": 0.11377373248951149,
      "grad_norm": 38.64419937133789,
      "learning_rate": 7.563981042654029e-06,
      "loss": 2.2023,
      "step": 400
    },
    {
      "epoch": 0.14221716561188935,
      "grad_norm": 30.295778274536133,
      "learning_rate": 9.459715639810427e-06,
      "loss": 1.9293,
      "step": 500
    },
    {
      "epoch": 0.17066059873426723,
      "grad_norm": 25.206077575683594,
      "learning_rate": 1.1355450236966825e-05,
      "loss": 1.8283,
      "step": 600
    },
    {
      "epoch": 0.1991040318566451,
      "grad_norm": 15.022041320800781,
      "learning_rate": 1.3251184834123222e-05,
      "loss": 1.6539,
      "step": 700
    },
    {
      "epoch": 0.22754746497902298,
      "grad_norm": 26.594480514526367,
      "learning_rate": 1.5146919431279623e-05,
      "loss": 1.6112,
      "step": 800
    },
    {
      "epoch": 0.25599089810140085,
      "grad_norm": 16.57659149169922,
      "learning_rate": 1.704265402843602e-05,
      "loss": 1.5588,
      "step": 900
    },
    {
      "epoch": 0.2844343312237787,
      "grad_norm": 16.110713958740234,
      "learning_rate": 1.8938388625592418e-05,
      "loss": 1.4495,
      "step": 1000
    },
    {
      "epoch": 0.2844343312237787,
      "eval_f1_macro": 0.7787274286789567,
      "eval_loss": 0.3558904826641083,
      "eval_runtime": 591.607,
      "eval_samples_per_second": 338.062,
      "eval_steps_per_second": 2.642,
      "step": 1000
    },
    {
      "epoch": 0.3128777643461566,
      "grad_norm": 13.731091499328613,
      "learning_rate": 1.9907300115874858e-05,
      "loss": 1.5006,
      "step": 1100
    },
    {
      "epoch": 0.34132119746853445,
      "grad_norm": 21.092727661132812,
      "learning_rate": 1.969661856104498e-05,
      "loss": 1.3693,
      "step": 1200
    },
    {
      "epoch": 0.3697646305909123,
      "grad_norm": 15.216771125793457,
      "learning_rate": 1.9485937006215108e-05,
      "loss": 1.3729,
      "step": 1300
    },
    {
      "epoch": 0.3982080637132902,
      "grad_norm": 14.29715633392334,
      "learning_rate": 1.927525545138523e-05,
      "loss": 1.3064,
      "step": 1400
    },
    {
      "epoch": 0.42665149683566805,
      "grad_norm": 18.282384872436523,
      "learning_rate": 1.906457389655536e-05,
      "loss": 1.2833,
      "step": 1500
    },
    {
      "epoch": 0.45509492995804596,
      "grad_norm": 13.443832397460938,
      "learning_rate": 1.8853892341725482e-05,
      "loss": 1.2597,
      "step": 1600
    },
    {
      "epoch": 0.4835383630804238,
      "grad_norm": 14.590373039245605,
      "learning_rate": 1.864321078689561e-05,
      "loss": 1.2597,
      "step": 1700
    },
    {
      "epoch": 0.5119817962028017,
      "grad_norm": 13.348322868347168,
      "learning_rate": 1.8432529232065736e-05,
      "loss": 1.2043,
      "step": 1800
    },
    {
      "epoch": 0.5404252293251796,
      "grad_norm": 32.86909103393555,
      "learning_rate": 1.822184767723586e-05,
      "loss": 1.1909,
      "step": 1900
    },
    {
      "epoch": 0.5688686624475574,
      "grad_norm": 8.667860984802246,
      "learning_rate": 1.8011166122405986e-05,
      "loss": 1.1618,
      "step": 2000
    },
    {
      "epoch": 0.5688686624475574,
      "eval_f1_macro": 0.8031577128237816,
      "eval_loss": 0.2952704429626465,
      "eval_runtime": 589.494,
      "eval_samples_per_second": 339.274,
      "eval_steps_per_second": 2.651,
      "step": 2000
    },
    {
      "epoch": 0.5973120955699353,
      "grad_norm": 7.7225799560546875,
      "learning_rate": 1.780048456757611e-05,
      "loss": 1.1361,
      "step": 2100
    },
    {
      "epoch": 0.6257555286923132,
      "grad_norm": 11.276484489440918,
      "learning_rate": 1.7589803012746237e-05,
      "loss": 1.143,
      "step": 2200
    },
    {
      "epoch": 0.6541989618146911,
      "grad_norm": 17.38803482055664,
      "learning_rate": 1.737912145791636e-05,
      "loss": 1.1249,
      "step": 2300
    },
    {
      "epoch": 0.6826423949370689,
      "grad_norm": 9.131571769714355,
      "learning_rate": 1.7168439903086487e-05,
      "loss": 1.1124,
      "step": 2400
    },
    {
      "epoch": 0.7110858280594468,
      "grad_norm": 8.710923194885254,
      "learning_rate": 1.695775834825661e-05,
      "loss": 1.1212,
      "step": 2500
    },
    {
      "epoch": 0.7395292611818246,
      "grad_norm": 9.241067886352539,
      "learning_rate": 1.6747076793426738e-05,
      "loss": 1.0733,
      "step": 2600
    },
    {
      "epoch": 0.7679726943042026,
      "grad_norm": 9.726804733276367,
      "learning_rate": 1.653639523859686e-05,
      "loss": 1.0805,
      "step": 2700
    },
    {
      "epoch": 0.7964161274265804,
      "grad_norm": 10.695276260375977,
      "learning_rate": 1.632571368376699e-05,
      "loss": 1.0462,
      "step": 2800
    },
    {
      "epoch": 0.8248595605489583,
      "grad_norm": 8.124917030334473,
      "learning_rate": 1.6115032128937115e-05,
      "loss": 1.0427,
      "step": 2900
    },
    {
      "epoch": 0.8533029936713361,
      "grad_norm": 9.342881202697754,
      "learning_rate": 1.590435057410724e-05,
      "loss": 1.0388,
      "step": 3000
    },
    {
      "epoch": 0.8533029936713361,
      "eval_f1_macro": 0.8406110366701287,
      "eval_loss": 0.2616581916809082,
      "eval_runtime": 588.6894,
      "eval_samples_per_second": 339.738,
      "eval_steps_per_second": 2.655,
      "step": 3000
    },
    {
      "epoch": 0.881746426793714,
      "grad_norm": 9.369446754455566,
      "learning_rate": 1.5693669019277366e-05,
      "loss": 1.0219,
      "step": 3100
    },
    {
      "epoch": 0.9101898599160919,
      "grad_norm": 7.885892868041992,
      "learning_rate": 1.548298746444749e-05,
      "loss": 1.0615,
      "step": 3200
    },
    {
      "epoch": 0.9386332930384698,
      "grad_norm": 9.875008583068848,
      "learning_rate": 1.5272305909617616e-05,
      "loss": 1.0135,
      "step": 3300
    },
    {
      "epoch": 0.9670767261608476,
      "grad_norm": 9.369109153747559,
      "learning_rate": 1.506162435478774e-05,
      "loss": 1.0237,
      "step": 3400
    },
    {
      "epoch": 0.9955201592832255,
      "grad_norm": 15.406951904296875,
      "learning_rate": 1.4850942799957867e-05,
      "loss": 1.0067,
      "step": 3500
    },
    {
      "epoch": 1.0238924838227974,
      "grad_norm": 10.8352689743042,
      "learning_rate": 1.4640261245127992e-05,
      "loss": 0.915,
      "step": 3600
    },
    {
      "epoch": 1.0523359169451754,
      "grad_norm": 9.933257102966309,
      "learning_rate": 1.4429579690298117e-05,
      "loss": 0.9323,
      "step": 3700
    },
    {
      "epoch": 1.080779350067553,
      "grad_norm": 26.88369369506836,
      "learning_rate": 1.4218898135468239e-05,
      "loss": 0.9002,
      "step": 3800
    },
    {
      "epoch": 1.109222783189931,
      "grad_norm": 13.57818603515625,
      "learning_rate": 1.4008216580638366e-05,
      "loss": 0.8902,
      "step": 3900
    },
    {
      "epoch": 1.1376662163123088,
      "grad_norm": 10.00123119354248,
      "learning_rate": 1.3797535025808491e-05,
      "loss": 0.918,
      "step": 4000
    },
    {
      "epoch": 1.1376662163123088,
      "eval_f1_macro": 0.8490951880203939,
      "eval_loss": 0.2461642622947693,
      "eval_runtime": 589.3023,
      "eval_samples_per_second": 339.384,
      "eval_steps_per_second": 2.652,
      "step": 4000
    },
    {
      "epoch": 1.1661096494346868,
      "grad_norm": 8.813664436340332,
      "learning_rate": 1.3586853470978616e-05,
      "loss": 0.9344,
      "step": 4100
    },
    {
      "epoch": 1.1945530825570647,
      "grad_norm": 7.469683647155762,
      "learning_rate": 1.3376171916148742e-05,
      "loss": 0.9079,
      "step": 4200
    },
    {
      "epoch": 1.2229965156794425,
      "grad_norm": 7.358949661254883,
      "learning_rate": 1.3165490361318867e-05,
      "loss": 0.911,
      "step": 4300
    },
    {
      "epoch": 1.2514399488018204,
      "grad_norm": 14.179739952087402,
      "learning_rate": 1.2954808806488992e-05,
      "loss": 0.908,
      "step": 4400
    },
    {
      "epoch": 1.2798833819241984,
      "grad_norm": 8.8256254196167,
      "learning_rate": 1.2744127251659117e-05,
      "loss": 0.9021,
      "step": 4500
    },
    {
      "epoch": 1.308326815046576,
      "grad_norm": 10.51315689086914,
      "learning_rate": 1.2533445696829243e-05,
      "loss": 0.8753,
      "step": 4600
    },
    {
      "epoch": 1.336770248168954,
      "grad_norm": 8.453068733215332,
      "learning_rate": 1.2322764141999368e-05,
      "loss": 0.9055,
      "step": 4700
    },
    {
      "epoch": 1.3652136812913318,
      "grad_norm": 8.505894660949707,
      "learning_rate": 1.2112082587169493e-05,
      "loss": 0.8878,
      "step": 4800
    },
    {
      "epoch": 1.3936571144137098,
      "grad_norm": 8.963418960571289,
      "learning_rate": 1.1901401032339618e-05,
      "loss": 0.8587,
      "step": 4900
    },
    {
      "epoch": 1.4221005475360875,
      "grad_norm": 10.418354988098145,
      "learning_rate": 1.1690719477509744e-05,
      "loss": 0.9024,
      "step": 5000
    },
    {
      "epoch": 1.4221005475360875,
      "eval_f1_macro": 0.8513442433273899,
      "eval_loss": 0.24233494699001312,
      "eval_runtime": 588.6062,
      "eval_samples_per_second": 339.786,
      "eval_steps_per_second": 2.655,
      "step": 5000
    },
    {
      "epoch": 1.4505439806584655,
      "grad_norm": 11.640713691711426,
      "learning_rate": 1.148003792267987e-05,
      "loss": 0.8772,
      "step": 5100
    },
    {
      "epoch": 1.4789874137808434,
      "grad_norm": 11.261161804199219,
      "learning_rate": 1.1269356367849996e-05,
      "loss": 0.8857,
      "step": 5200
    },
    {
      "epoch": 1.5074308469032212,
      "grad_norm": 9.789798736572266,
      "learning_rate": 1.1058674813020121e-05,
      "loss": 0.8729,
      "step": 5300
    },
    {
      "epoch": 1.5358742800255991,
      "grad_norm": 15.70868968963623,
      "learning_rate": 1.0847993258190246e-05,
      "loss": 0.8913,
      "step": 5400
    },
    {
      "epoch": 1.564317713147977,
      "grad_norm": 9.263629913330078,
      "learning_rate": 1.0637311703360371e-05,
      "loss": 0.8561,
      "step": 5500
    },
    {
      "epoch": 1.5927611462703548,
      "grad_norm": 7.665436267852783,
      "learning_rate": 1.0426630148530497e-05,
      "loss": 0.8621,
      "step": 5600
    },
    {
      "epoch": 1.6212045793927325,
      "grad_norm": 9.66658878326416,
      "learning_rate": 1.0215948593700622e-05,
      "loss": 0.8749,
      "step": 5700
    },
    {
      "epoch": 1.6496480125151107,
      "grad_norm": 7.326372146606445,
      "learning_rate": 1.0005267038870747e-05,
      "loss": 0.8827,
      "step": 5800
    },
    {
      "epoch": 1.6780914456374885,
      "grad_norm": 13.10745620727539,
      "learning_rate": 9.794585484040872e-06,
      "loss": 0.83,
      "step": 5900
    },
    {
      "epoch": 1.7065348787598662,
      "grad_norm": 12.870473861694336,
      "learning_rate": 9.583903929210998e-06,
      "loss": 0.8498,
      "step": 6000
    },
    {
      "epoch": 1.7065348787598662,
      "eval_f1_macro": 0.8592084996158984,
      "eval_loss": 0.22628404200077057,
      "eval_runtime": 589.2137,
      "eval_samples_per_second": 339.435,
      "eval_steps_per_second": 2.653,
      "step": 6000
    },
    {
      "epoch": 1.7349783118822442,
      "grad_norm": 9.936917304992676,
      "learning_rate": 9.373222374381123e-06,
      "loss": 0.8651,
      "step": 6100
    },
    {
      "epoch": 1.7634217450046221,
      "grad_norm": 8.782368659973145,
      "learning_rate": 9.162540819551248e-06,
      "loss": 0.8437,
      "step": 6200
    },
    {
      "epoch": 1.7918651781269999,
      "grad_norm": 11.307519912719727,
      "learning_rate": 8.951859264721375e-06,
      "loss": 0.8609,
      "step": 6300
    },
    {
      "epoch": 1.8203086112493778,
      "grad_norm": 8.40150260925293,
      "learning_rate": 8.7411777098915e-06,
      "loss": 0.8731,
      "step": 6400
    },
    {
      "epoch": 1.8487520443717558,
      "grad_norm": 11.45564079284668,
      "learning_rate": 8.530496155061625e-06,
      "loss": 0.8472,
      "step": 6500
    },
    {
      "epoch": 1.8771954774941335,
      "grad_norm": 9.225118637084961,
      "learning_rate": 8.31981460023175e-06,
      "loss": 0.8445,
      "step": 6600
    },
    {
      "epoch": 1.9056389106165113,
      "grad_norm": 8.068068504333496,
      "learning_rate": 8.109133045401876e-06,
      "loss": 0.8416,
      "step": 6700
    },
    {
      "epoch": 1.9340823437388894,
      "grad_norm": 9.367648124694824,
      "learning_rate": 7.898451490572001e-06,
      "loss": 0.8365,
      "step": 6800
    },
    {
      "epoch": 1.9625257768612672,
      "grad_norm": 10.652840614318848,
      "learning_rate": 7.687769935742126e-06,
      "loss": 0.8293,
      "step": 6900
    },
    {
      "epoch": 1.990969209983645,
      "grad_norm": 12.491552352905273,
      "learning_rate": 7.477088380912252e-06,
      "loss": 0.811,
      "step": 7000
    },
    {
      "epoch": 1.990969209983645,
      "eval_f1_macro": 0.8629479429225028,
      "eval_loss": 0.22145752608776093,
      "eval_runtime": 589.0554,
      "eval_samples_per_second": 339.527,
      "eval_steps_per_second": 2.653,
      "step": 7000
    },
    {
      "epoch": 2.019341534523217,
      "grad_norm": 10.571395874023438,
      "learning_rate": 7.266406826082377e-06,
      "loss": 0.7575,
      "step": 7100
    },
    {
      "epoch": 2.047784967645595,
      "grad_norm": 7.025107383728027,
      "learning_rate": 7.055725271252503e-06,
      "loss": 0.7036,
      "step": 7200
    },
    {
      "epoch": 2.0762284007679725,
      "grad_norm": 8.157675743103027,
      "learning_rate": 6.845043716422628e-06,
      "loss": 0.7035,
      "step": 7300
    },
    {
      "epoch": 2.1046718338903507,
      "grad_norm": 26.779800415039062,
      "learning_rate": 6.6343621615927535e-06,
      "loss": 0.6868,
      "step": 7400
    },
    {
      "epoch": 2.1331152670127285,
      "grad_norm": 9.829116821289062,
      "learning_rate": 6.423680606762879e-06,
      "loss": 0.6975,
      "step": 7500
    },
    {
      "epoch": 2.161558700135106,
      "grad_norm": 13.770512580871582,
      "learning_rate": 6.212999051933004e-06,
      "loss": 0.6875,
      "step": 7600
    },
    {
      "epoch": 2.1900021332574844,
      "grad_norm": 11.433330535888672,
      "learning_rate": 6.002317497103129e-06,
      "loss": 0.6711,
      "step": 7700
    },
    {
      "epoch": 2.218445566379862,
      "grad_norm": 9.552383422851562,
      "learning_rate": 5.791635942273255e-06,
      "loss": 0.6896,
      "step": 7800
    },
    {
      "epoch": 2.24688899950224,
      "grad_norm": 10.339981079101562,
      "learning_rate": 5.5809543874433805e-06,
      "loss": 0.6918,
      "step": 7900
    },
    {
      "epoch": 2.2753324326246176,
      "grad_norm": 11.207277297973633,
      "learning_rate": 5.370272832613506e-06,
      "loss": 0.703,
      "step": 8000
    },
    {
      "epoch": 2.2753324326246176,
      "eval_f1_macro": 0.8641741257631941,
      "eval_loss": 0.22334446012973785,
      "eval_runtime": 589.6196,
      "eval_samples_per_second": 339.202,
      "eval_steps_per_second": 2.651,
      "step": 8000
    },
    {
      "epoch": 2.3037758657469958,
      "grad_norm": 12.880768775939941,
      "learning_rate": 5.159591277783631e-06,
      "loss": 0.6866,
      "step": 8100
    },
    {
      "epoch": 2.3322192988693735,
      "grad_norm": 11.414399147033691,
      "learning_rate": 4.948909722953756e-06,
      "loss": 0.6736,
      "step": 8200
    },
    {
      "epoch": 2.3606627319917513,
      "grad_norm": 7.698513984680176,
      "learning_rate": 4.7382281681238814e-06,
      "loss": 0.6731,
      "step": 8300
    },
    {
      "epoch": 2.3891061651141294,
      "grad_norm": 10.76761245727539,
      "learning_rate": 4.527546613294007e-06,
      "loss": 0.6608,
      "step": 8400
    },
    {
      "epoch": 2.417549598236507,
      "grad_norm": 11.411924362182617,
      "learning_rate": 4.316865058464132e-06,
      "loss": 0.6806,
      "step": 8500
    },
    {
      "epoch": 2.445993031358885,
      "grad_norm": 9.092586517333984,
      "learning_rate": 4.106183503634257e-06,
      "loss": 0.6914,
      "step": 8600
    },
    {
      "epoch": 2.474436464481263,
      "grad_norm": 10.81569766998291,
      "learning_rate": 3.895501948804382e-06,
      "loss": 0.6746,
      "step": 8700
    },
    {
      "epoch": 2.502879897603641,
      "grad_norm": 10.031603813171387,
      "learning_rate": 3.684820393974508e-06,
      "loss": 0.6659,
      "step": 8800
    },
    {
      "epoch": 2.5313233307260186,
      "grad_norm": 10.247474670410156,
      "learning_rate": 3.474138839144633e-06,
      "loss": 0.673,
      "step": 8900
    },
    {
      "epoch": 2.5597667638483967,
      "grad_norm": 8.063573837280273,
      "learning_rate": 3.263457284314758e-06,
      "loss": 0.6773,
      "step": 9000
    },
    {
      "epoch": 2.5597667638483967,
      "eval_f1_macro": 0.8657307062316952,
      "eval_loss": 0.2204168736934662,
      "eval_runtime": 589.3507,
      "eval_samples_per_second": 339.357,
      "eval_steps_per_second": 2.652,
      "step": 9000
    },
    {
      "epoch": 2.5882101969707745,
      "grad_norm": 10.475592613220215,
      "learning_rate": 3.0527757294848838e-06,
      "loss": 0.6669,
      "step": 9100
    },
    {
      "epoch": 2.616653630093152,
      "grad_norm": 9.389370918273926,
      "learning_rate": 2.842094174655009e-06,
      "loss": 0.6917,
      "step": 9200
    },
    {
      "epoch": 2.64509706321553,
      "grad_norm": 8.902517318725586,
      "learning_rate": 2.6314126198251342e-06,
      "loss": 0.6908,
      "step": 9300
    },
    {
      "epoch": 2.673540496337908,
      "grad_norm": 10.800983428955078,
      "learning_rate": 2.42073106499526e-06,
      "loss": 0.6797,
      "step": 9400
    },
    {
      "epoch": 2.701983929460286,
      "grad_norm": 12.683361053466797,
      "learning_rate": 2.210049510165385e-06,
      "loss": 0.6713,
      "step": 9500
    },
    {
      "epoch": 2.7304273625826636,
      "grad_norm": 10.081172943115234,
      "learning_rate": 1.9993679553355104e-06,
      "loss": 0.6493,
      "step": 9600
    },
    {
      "epoch": 2.7588707957050413,
      "grad_norm": 9.641876220703125,
      "learning_rate": 1.7886864005056358e-06,
      "loss": 0.6599,
      "step": 9700
    },
    {
      "epoch": 2.7873142288274195,
      "grad_norm": 9.201966285705566,
      "learning_rate": 1.5780048456757613e-06,
      "loss": 0.6589,
      "step": 9800
    },
    {
      "epoch": 2.8157576619497973,
      "grad_norm": 7.794130325317383,
      "learning_rate": 1.3673232908458867e-06,
      "loss": 0.6603,
      "step": 9900
    },
    {
      "epoch": 2.844201095072175,
      "grad_norm": 8.722225189208984,
      "learning_rate": 1.156641736016012e-06,
      "loss": 0.6498,
      "step": 10000
    },
    {
      "epoch": 2.844201095072175,
      "eval_f1_macro": 0.8679424026858762,
      "eval_loss": 0.21816988289356232,
      "eval_runtime": 589.669,
      "eval_samples_per_second": 339.173,
      "eval_steps_per_second": 2.651,
      "step": 10000
    },
    {
      "epoch": 2.872644528194553,
      "grad_norm": 10.647810935974121,
      "learning_rate": 9.459601811861373e-07,
      "loss": 0.6828,
      "step": 10100
    },
    {
      "epoch": 2.901087961316931,
      "grad_norm": 8.818092346191406,
      "learning_rate": 7.352786263562625e-07,
      "loss": 0.6589,
      "step": 10200
    },
    {
      "epoch": 2.9295313944393087,
      "grad_norm": 9.395851135253906,
      "learning_rate": 5.245970715263879e-07,
      "loss": 0.6708,
      "step": 10300
    },
    {
      "epoch": 2.957974827561687,
      "grad_norm": 11.627765655517578,
      "learning_rate": 3.1391551669651327e-07,
      "loss": 0.6382,
      "step": 10400
    },
    {
      "epoch": 2.9864182606840646,
      "grad_norm": 11.738740921020508,
      "learning_rate": 1.032339618666386e-07,
      "loss": 0.6509,
      "step": 10500
    }
  ],
  "logging_steps": 100,
  "max_steps": 10548,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.16464960792e+17,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
