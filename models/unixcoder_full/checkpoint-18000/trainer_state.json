{
  "best_global_step": 18000,
  "best_metric": 0.8694378198787841,
  "best_model_checkpoint": "./models/unixcoder_full/checkpoint-18000",
  "epoch": 5.1194624191139875,
  "eval_steps": 1000,
  "global_step": 18000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00028443433122377873,
      "grad_norm": 5.858745574951172,
      "learning_rate": 0.0,
      "loss": 1.3839,
      "step": 1
    },
    {
      "epoch": 0.028443433122377872,
      "grad_norm": 2.0881640911102295,
      "learning_rate": 8.042242079610074e-07,
      "loss": 1.2716,
      "step": 100
    },
    {
      "epoch": 0.056886866244755745,
      "grad_norm": 3.6447813510894775,
      "learning_rate": 1.6165718927701056e-06,
      "loss": 1.0278,
      "step": 200
    },
    {
      "epoch": 0.08533029936713361,
      "grad_norm": 2.6914772987365723,
      "learning_rate": 2.428919577579204e-06,
      "loss": 0.8252,
      "step": 300
    },
    {
      "epoch": 0.11377373248951149,
      "grad_norm": 3.876256227493286,
      "learning_rate": 3.241267262388302e-06,
      "loss": 0.6855,
      "step": 400
    },
    {
      "epoch": 0.14221716561188935,
      "grad_norm": 4.8485822677612305,
      "learning_rate": 4.053614947197401e-06,
      "loss": 0.571,
      "step": 500
    },
    {
      "epoch": 0.17066059873426723,
      "grad_norm": 6.81203031539917,
      "learning_rate": 4.865962632006499e-06,
      "loss": 0.5171,
      "step": 600
    },
    {
      "epoch": 0.1991040318566451,
      "grad_norm": 3.31716251373291,
      "learning_rate": 5.678310316815597e-06,
      "loss": 0.4659,
      "step": 700
    },
    {
      "epoch": 0.22754746497902298,
      "grad_norm": 3.4757399559020996,
      "learning_rate": 6.490658001624695e-06,
      "loss": 0.4433,
      "step": 800
    },
    {
      "epoch": 0.25599089810140085,
      "grad_norm": 3.6193902492523193,
      "learning_rate": 7.303005686433794e-06,
      "loss": 0.4313,
      "step": 900
    },
    {
      "epoch": 0.2844343312237787,
      "grad_norm": 5.568661212921143,
      "learning_rate": 8.115353371242892e-06,
      "loss": 0.4039,
      "step": 1000
    },
    {
      "epoch": 0.2844343312237787,
      "eval_f1_macro": 0.7751869355935974,
      "eval_loss": 0.38714396953582764,
      "eval_runtime": 217.3428,
      "eval_samples_per_second": 920.205,
      "eval_steps_per_second": 7.191,
      "step": 1000
    },
    {
      "epoch": 0.3128777643461566,
      "grad_norm": 3.002124786376953,
      "learning_rate": 8.92770105605199e-06,
      "loss": 0.4046,
      "step": 1100
    },
    {
      "epoch": 0.34132119746853445,
      "grad_norm": 2.5191948413848877,
      "learning_rate": 9.740048740861089e-06,
      "loss": 0.3736,
      "step": 1200
    },
    {
      "epoch": 0.3697646305909123,
      "grad_norm": 2.9540607929229736,
      "learning_rate": 1.0552396425670189e-05,
      "loss": 0.3738,
      "step": 1300
    },
    {
      "epoch": 0.3982080637132902,
      "grad_norm": 4.9358696937561035,
      "learning_rate": 1.1364744110479287e-05,
      "loss": 0.3645,
      "step": 1400
    },
    {
      "epoch": 0.42665149683566805,
      "grad_norm": 3.787217378616333,
      "learning_rate": 1.2177091795288385e-05,
      "loss": 0.3558,
      "step": 1500
    },
    {
      "epoch": 0.45509492995804596,
      "grad_norm": 4.623349666595459,
      "learning_rate": 1.2989439480097483e-05,
      "loss": 0.3456,
      "step": 1600
    },
    {
      "epoch": 0.4835383630804238,
      "grad_norm": 2.5008206367492676,
      "learning_rate": 1.3801787164906581e-05,
      "loss": 0.3481,
      "step": 1700
    },
    {
      "epoch": 0.5119817962028017,
      "grad_norm": 3.6695609092712402,
      "learning_rate": 1.461413484971568e-05,
      "loss": 0.3412,
      "step": 1800
    },
    {
      "epoch": 0.5404252293251796,
      "grad_norm": 4.996117115020752,
      "learning_rate": 1.542648253452478e-05,
      "loss": 0.3349,
      "step": 1900
    },
    {
      "epoch": 0.5688686624475574,
      "grad_norm": 3.915815591812134,
      "learning_rate": 1.6238830219333876e-05,
      "loss": 0.3272,
      "step": 2000
    },
    {
      "epoch": 0.5688686624475574,
      "eval_f1_macro": 0.8043882709926464,
      "eval_loss": 0.31467360258102417,
      "eval_runtime": 217.5102,
      "eval_samples_per_second": 919.497,
      "eval_steps_per_second": 7.186,
      "step": 2000
    },
    {
      "epoch": 0.5973120955699353,
      "grad_norm": 2.353384494781494,
      "learning_rate": 1.7051177904142976e-05,
      "loss": 0.3159,
      "step": 2100
    },
    {
      "epoch": 0.6257555286923132,
      "grad_norm": 2.4854321479797363,
      "learning_rate": 1.7863525588952072e-05,
      "loss": 0.3183,
      "step": 2200
    },
    {
      "epoch": 0.6541989618146911,
      "grad_norm": 4.410479545593262,
      "learning_rate": 1.8675873273761172e-05,
      "loss": 0.3174,
      "step": 2300
    },
    {
      "epoch": 0.6826423949370689,
      "grad_norm": 2.156060218811035,
      "learning_rate": 1.948822095857027e-05,
      "loss": 0.3052,
      "step": 2400
    },
    {
      "epoch": 0.7110858280594468,
      "grad_norm": 3.959800958633423,
      "learning_rate": 1.9966591422121896e-05,
      "loss": 0.3121,
      "step": 2500
    },
    {
      "epoch": 0.7395292611818246,
      "grad_norm": 2.1192424297332764,
      "learning_rate": 1.9876297968397295e-05,
      "loss": 0.304,
      "step": 2600
    },
    {
      "epoch": 0.7679726943042026,
      "grad_norm": 2.3463656902313232,
      "learning_rate": 1.9786004514672686e-05,
      "loss": 0.292,
      "step": 2700
    },
    {
      "epoch": 0.7964161274265804,
      "grad_norm": 2.1365561485290527,
      "learning_rate": 1.9695711060948085e-05,
      "loss": 0.2865,
      "step": 2800
    },
    {
      "epoch": 0.8248595605489583,
      "grad_norm": 2.7598917484283447,
      "learning_rate": 1.9605417607223476e-05,
      "loss": 0.2887,
      "step": 2900
    },
    {
      "epoch": 0.8533029936713361,
      "grad_norm": 4.180458068847656,
      "learning_rate": 1.951512415349887e-05,
      "loss": 0.2877,
      "step": 3000
    },
    {
      "epoch": 0.8533029936713361,
      "eval_f1_macro": 0.8352328993340138,
      "eval_loss": 0.2668435275554657,
      "eval_runtime": 217.327,
      "eval_samples_per_second": 920.272,
      "eval_steps_per_second": 7.192,
      "step": 3000
    },
    {
      "epoch": 0.881746426793714,
      "grad_norm": 2.237090587615967,
      "learning_rate": 1.942483069977427e-05,
      "loss": 0.2837,
      "step": 3100
    },
    {
      "epoch": 0.9101898599160919,
      "grad_norm": 2.1193788051605225,
      "learning_rate": 1.933453724604966e-05,
      "loss": 0.2834,
      "step": 3200
    },
    {
      "epoch": 0.9386332930384698,
      "grad_norm": 7.800462245941162,
      "learning_rate": 1.9244243792325056e-05,
      "loss": 0.2782,
      "step": 3300
    },
    {
      "epoch": 0.9670767261608476,
      "grad_norm": 2.1836373805999756,
      "learning_rate": 1.9153950338600455e-05,
      "loss": 0.2759,
      "step": 3400
    },
    {
      "epoch": 0.9955201592832255,
      "grad_norm": 2.578866481781006,
      "learning_rate": 1.9063656884875846e-05,
      "loss": 0.2714,
      "step": 3500
    },
    {
      "epoch": 1.0238924838227974,
      "grad_norm": 1.8278597593307495,
      "learning_rate": 1.8973363431151245e-05,
      "loss": 0.2529,
      "step": 3600
    },
    {
      "epoch": 1.0523359169451754,
      "grad_norm": 2.9125959873199463,
      "learning_rate": 1.8883069977426636e-05,
      "loss": 0.2603,
      "step": 3700
    },
    {
      "epoch": 1.080779350067553,
      "grad_norm": 1.8890424966812134,
      "learning_rate": 1.879277652370203e-05,
      "loss": 0.2509,
      "step": 3800
    },
    {
      "epoch": 1.109222783189931,
      "grad_norm": 2.3724143505096436,
      "learning_rate": 1.870248306997743e-05,
      "loss": 0.2496,
      "step": 3900
    },
    {
      "epoch": 1.1376662163123088,
      "grad_norm": 2.9160664081573486,
      "learning_rate": 1.861218961625282e-05,
      "loss": 0.2481,
      "step": 4000
    },
    {
      "epoch": 1.1376662163123088,
      "eval_f1_macro": 0.8452936406663901,
      "eval_loss": 0.25491419434547424,
      "eval_runtime": 217.4066,
      "eval_samples_per_second": 919.935,
      "eval_steps_per_second": 7.189,
      "step": 4000
    },
    {
      "epoch": 1.1661096494346868,
      "grad_norm": 1.5545322895050049,
      "learning_rate": 1.852189616252822e-05,
      "loss": 0.2557,
      "step": 4100
    },
    {
      "epoch": 1.1945530825570647,
      "grad_norm": 1.5710690021514893,
      "learning_rate": 1.8431602708803615e-05,
      "loss": 0.2461,
      "step": 4200
    },
    {
      "epoch": 1.2229965156794425,
      "grad_norm": 1.7702608108520508,
      "learning_rate": 1.8341309255079006e-05,
      "loss": 0.25,
      "step": 4300
    },
    {
      "epoch": 1.2514399488018204,
      "grad_norm": 2.5913379192352295,
      "learning_rate": 1.8251015801354405e-05,
      "loss": 0.2442,
      "step": 4400
    },
    {
      "epoch": 1.2798833819241984,
      "grad_norm": 2.205885887145996,
      "learning_rate": 1.8160722347629796e-05,
      "loss": 0.249,
      "step": 4500
    },
    {
      "epoch": 1.308326815046576,
      "grad_norm": 2.000635862350464,
      "learning_rate": 1.8070428893905195e-05,
      "loss": 0.2367,
      "step": 4600
    },
    {
      "epoch": 1.336770248168954,
      "grad_norm": 2.02303147315979,
      "learning_rate": 1.798013544018059e-05,
      "loss": 0.2443,
      "step": 4700
    },
    {
      "epoch": 1.3652136812913318,
      "grad_norm": 1.4741793870925903,
      "learning_rate": 1.788984198645598e-05,
      "loss": 0.2397,
      "step": 4800
    },
    {
      "epoch": 1.3936571144137098,
      "grad_norm": 2.219395160675049,
      "learning_rate": 1.779954853273138e-05,
      "loss": 0.2339,
      "step": 4900
    },
    {
      "epoch": 1.4221005475360875,
      "grad_norm": 2.574878692626953,
      "learning_rate": 1.770925507900677e-05,
      "loss": 0.2446,
      "step": 5000
    },
    {
      "epoch": 1.4221005475360875,
      "eval_f1_macro": 0.8419499768420083,
      "eval_loss": 0.26096832752227783,
      "eval_runtime": 217.3349,
      "eval_samples_per_second": 920.239,
      "eval_steps_per_second": 7.192,
      "step": 5000
    },
    {
      "epoch": 1.4505439806584655,
      "grad_norm": 1.7471935749053955,
      "learning_rate": 1.761896162528217e-05,
      "loss": 0.2396,
      "step": 5100
    },
    {
      "epoch": 1.4789874137808434,
      "grad_norm": 2.098825693130493,
      "learning_rate": 1.7528668171557565e-05,
      "loss": 0.2446,
      "step": 5200
    },
    {
      "epoch": 1.5074308469032212,
      "grad_norm": 2.5573506355285645,
      "learning_rate": 1.7438374717832956e-05,
      "loss": 0.2361,
      "step": 5300
    },
    {
      "epoch": 1.5358742800255991,
      "grad_norm": 1.8034286499023438,
      "learning_rate": 1.7348081264108355e-05,
      "loss": 0.2388,
      "step": 5400
    },
    {
      "epoch": 1.564317713147977,
      "grad_norm": 2.567797899246216,
      "learning_rate": 1.725778781038375e-05,
      "loss": 0.2333,
      "step": 5500
    },
    {
      "epoch": 1.5927611462703548,
      "grad_norm": 2.011643409729004,
      "learning_rate": 1.7167494356659145e-05,
      "loss": 0.2336,
      "step": 5600
    },
    {
      "epoch": 1.6212045793927325,
      "grad_norm": 1.7983808517456055,
      "learning_rate": 1.707720090293454e-05,
      "loss": 0.2351,
      "step": 5700
    },
    {
      "epoch": 1.6496480125151107,
      "grad_norm": 1.9101215600967407,
      "learning_rate": 1.698690744920993e-05,
      "loss": 0.238,
      "step": 5800
    },
    {
      "epoch": 1.6780914456374885,
      "grad_norm": 2.6209287643432617,
      "learning_rate": 1.689661399548533e-05,
      "loss": 0.2275,
      "step": 5900
    },
    {
      "epoch": 1.7065348787598662,
      "grad_norm": 1.6348172426223755,
      "learning_rate": 1.6806320541760725e-05,
      "loss": 0.23,
      "step": 6000
    },
    {
      "epoch": 1.7065348787598662,
      "eval_f1_macro": 0.8472704160342197,
      "eval_loss": 0.2572162449359894,
      "eval_runtime": 217.271,
      "eval_samples_per_second": 920.509,
      "eval_steps_per_second": 7.194,
      "step": 6000
    },
    {
      "epoch": 1.7349783118822442,
      "grad_norm": 2.0849738121032715,
      "learning_rate": 1.671602708803612e-05,
      "loss": 0.2336,
      "step": 6100
    },
    {
      "epoch": 1.7634217450046221,
      "grad_norm": 2.1639158725738525,
      "learning_rate": 1.6625733634311515e-05,
      "loss": 0.2269,
      "step": 6200
    },
    {
      "epoch": 1.7918651781269999,
      "grad_norm": 2.752408742904663,
      "learning_rate": 1.6535440180586906e-05,
      "loss": 0.232,
      "step": 6300
    },
    {
      "epoch": 1.8203086112493778,
      "grad_norm": 3.152714967727661,
      "learning_rate": 1.6445146726862305e-05,
      "loss": 0.2324,
      "step": 6400
    },
    {
      "epoch": 1.8487520443717558,
      "grad_norm": 2.1554832458496094,
      "learning_rate": 1.63548532731377e-05,
      "loss": 0.2289,
      "step": 6500
    },
    {
      "epoch": 1.8771954774941335,
      "grad_norm": 1.9365503787994385,
      "learning_rate": 1.6264559819413095e-05,
      "loss": 0.2284,
      "step": 6600
    },
    {
      "epoch": 1.9056389106165113,
      "grad_norm": 1.7561029195785522,
      "learning_rate": 1.617426636568849e-05,
      "loss": 0.2265,
      "step": 6700
    },
    {
      "epoch": 1.9340823437388894,
      "grad_norm": 1.567237377166748,
      "learning_rate": 1.6083972911963885e-05,
      "loss": 0.2237,
      "step": 6800
    },
    {
      "epoch": 1.9625257768612672,
      "grad_norm": 3.214427947998047,
      "learning_rate": 1.599367945823928e-05,
      "loss": 0.223,
      "step": 6900
    },
    {
      "epoch": 1.990969209983645,
      "grad_norm": 3.114264726638794,
      "learning_rate": 1.5903386004514675e-05,
      "loss": 0.2198,
      "step": 7000
    },
    {
      "epoch": 1.990969209983645,
      "eval_f1_macro": 0.8570717372668037,
      "eval_loss": 0.24189269542694092,
      "eval_runtime": 217.3997,
      "eval_samples_per_second": 919.964,
      "eval_steps_per_second": 7.19,
      "step": 7000
    },
    {
      "epoch": 2.019341534523217,
      "grad_norm": 1.7010998725891113,
      "learning_rate": 1.581309255079007e-05,
      "loss": 0.2063,
      "step": 7100
    },
    {
      "epoch": 2.047784967645595,
      "grad_norm": 2.1068410873413086,
      "learning_rate": 1.5722799097065465e-05,
      "loss": 0.198,
      "step": 7200
    },
    {
      "epoch": 2.0762284007679725,
      "grad_norm": 1.7599906921386719,
      "learning_rate": 1.563250564334086e-05,
      "loss": 0.2012,
      "step": 7300
    },
    {
      "epoch": 2.1046718338903507,
      "grad_norm": 1.5782686471939087,
      "learning_rate": 1.5542212189616255e-05,
      "loss": 0.1956,
      "step": 7400
    },
    {
      "epoch": 2.1331152670127285,
      "grad_norm": 1.4862337112426758,
      "learning_rate": 1.545191873589165e-05,
      "loss": 0.2031,
      "step": 7500
    },
    {
      "epoch": 2.161558700135106,
      "grad_norm": 2.068819761276245,
      "learning_rate": 1.5361625282167045e-05,
      "loss": 0.1981,
      "step": 7600
    },
    {
      "epoch": 2.1900021332574844,
      "grad_norm": 1.7956677675247192,
      "learning_rate": 1.527133182844244e-05,
      "loss": 0.1928,
      "step": 7700
    },
    {
      "epoch": 2.218445566379862,
      "grad_norm": 2.175845146179199,
      "learning_rate": 1.5181038374717833e-05,
      "loss": 0.2003,
      "step": 7800
    },
    {
      "epoch": 2.24688899950224,
      "grad_norm": 1.7342925071716309,
      "learning_rate": 1.509074492099323e-05,
      "loss": 0.1993,
      "step": 7900
    },
    {
      "epoch": 2.2753324326246176,
      "grad_norm": 1.939759612083435,
      "learning_rate": 1.5000451467268625e-05,
      "loss": 0.2012,
      "step": 8000
    },
    {
      "epoch": 2.2753324326246176,
      "eval_f1_macro": 0.8615865109416778,
      "eval_loss": 0.23630264401435852,
      "eval_runtime": 217.383,
      "eval_samples_per_second": 920.035,
      "eval_steps_per_second": 7.19,
      "step": 8000
    },
    {
      "epoch": 2.3037758657469958,
      "grad_norm": 2.108776330947876,
      "learning_rate": 1.4910158013544018e-05,
      "loss": 0.1979,
      "step": 8100
    },
    {
      "epoch": 2.3322192988693735,
      "grad_norm": 2.1066696643829346,
      "learning_rate": 1.4819864559819415e-05,
      "loss": 0.193,
      "step": 8200
    },
    {
      "epoch": 2.3606627319917513,
      "grad_norm": 1.8116214275360107,
      "learning_rate": 1.4729571106094808e-05,
      "loss": 0.1914,
      "step": 8300
    },
    {
      "epoch": 2.3891061651141294,
      "grad_norm": 1.8591346740722656,
      "learning_rate": 1.4639277652370205e-05,
      "loss": 0.1936,
      "step": 8400
    },
    {
      "epoch": 2.417549598236507,
      "grad_norm": 1.7917861938476562,
      "learning_rate": 1.45489841986456e-05,
      "loss": 0.1951,
      "step": 8500
    },
    {
      "epoch": 2.445993031358885,
      "grad_norm": 1.9411687850952148,
      "learning_rate": 1.4458690744920993e-05,
      "loss": 0.1948,
      "step": 8600
    },
    {
      "epoch": 2.474436464481263,
      "grad_norm": 2.083300828933716,
      "learning_rate": 1.436839729119639e-05,
      "loss": 0.2004,
      "step": 8700
    },
    {
      "epoch": 2.502879897603641,
      "grad_norm": 1.8870998620986938,
      "learning_rate": 1.4278103837471785e-05,
      "loss": 0.1931,
      "step": 8800
    },
    {
      "epoch": 2.5313233307260186,
      "grad_norm": 2.114799976348877,
      "learning_rate": 1.418781038374718e-05,
      "loss": 0.195,
      "step": 8900
    },
    {
      "epoch": 2.5597667638483967,
      "grad_norm": 1.747604250907898,
      "learning_rate": 1.4097516930022575e-05,
      "loss": 0.1989,
      "step": 9000
    },
    {
      "epoch": 2.5597667638483967,
      "eval_f1_macro": 0.8584386642682569,
      "eval_loss": 0.2435002475976944,
      "eval_runtime": 217.3961,
      "eval_samples_per_second": 919.98,
      "eval_steps_per_second": 7.19,
      "step": 9000
    },
    {
      "epoch": 2.5882101969707745,
      "grad_norm": 1.9714943170547485,
      "learning_rate": 1.4007223476297968e-05,
      "loss": 0.1935,
      "step": 9100
    },
    {
      "epoch": 2.616653630093152,
      "grad_norm": 2.180551767349243,
      "learning_rate": 1.3916930022573365e-05,
      "loss": 0.203,
      "step": 9200
    },
    {
      "epoch": 2.64509706321553,
      "grad_norm": 1.8682496547698975,
      "learning_rate": 1.382663656884876e-05,
      "loss": 0.2051,
      "step": 9300
    },
    {
      "epoch": 2.673540496337908,
      "grad_norm": 2.6627981662750244,
      "learning_rate": 1.3736343115124156e-05,
      "loss": 0.1968,
      "step": 9400
    },
    {
      "epoch": 2.701983929460286,
      "grad_norm": 1.5457864999771118,
      "learning_rate": 1.364604966139955e-05,
      "loss": 0.1953,
      "step": 9500
    },
    {
      "epoch": 2.7304273625826636,
      "grad_norm": 2.366441011428833,
      "learning_rate": 1.3555756207674945e-05,
      "loss": 0.1908,
      "step": 9600
    },
    {
      "epoch": 2.7588707957050413,
      "grad_norm": 1.8526870012283325,
      "learning_rate": 1.346546275395034e-05,
      "loss": 0.1969,
      "step": 9700
    },
    {
      "epoch": 2.7873142288274195,
      "grad_norm": 1.6785982847213745,
      "learning_rate": 1.3375169300225735e-05,
      "loss": 0.1966,
      "step": 9800
    },
    {
      "epoch": 2.8157576619497973,
      "grad_norm": 1.768031358718872,
      "learning_rate": 1.3284875846501131e-05,
      "loss": 0.1965,
      "step": 9900
    },
    {
      "epoch": 2.844201095072175,
      "grad_norm": 2.3029167652130127,
      "learning_rate": 1.3194582392776525e-05,
      "loss": 0.1916,
      "step": 10000
    },
    {
      "epoch": 2.844201095072175,
      "eval_f1_macro": 0.8654643828200712,
      "eval_loss": 0.22428253293037415,
      "eval_runtime": 217.3639,
      "eval_samples_per_second": 920.116,
      "eval_steps_per_second": 7.191,
      "step": 10000
    },
    {
      "epoch": 2.872644528194553,
      "grad_norm": 2.1213181018829346,
      "learning_rate": 1.310428893905192e-05,
      "loss": 0.2022,
      "step": 10100
    },
    {
      "epoch": 2.901087961316931,
      "grad_norm": 2.166560411453247,
      "learning_rate": 1.3013995485327315e-05,
      "loss": 0.1904,
      "step": 10200
    },
    {
      "epoch": 2.9295313944393087,
      "grad_norm": 1.6742208003997803,
      "learning_rate": 1.292370203160271e-05,
      "loss": 0.1952,
      "step": 10300
    },
    {
      "epoch": 2.957974827561687,
      "grad_norm": 1.934638500213623,
      "learning_rate": 1.2833408577878106e-05,
      "loss": 0.1903,
      "step": 10400
    },
    {
      "epoch": 2.9864182606840646,
      "grad_norm": 1.7798296213150024,
      "learning_rate": 1.27431151241535e-05,
      "loss": 0.1907,
      "step": 10500
    },
    {
      "epoch": 3.0147905852236363,
      "grad_norm": 1.8705774545669556,
      "learning_rate": 1.2652821670428895e-05,
      "loss": 0.1808,
      "step": 10600
    },
    {
      "epoch": 3.0432340183460145,
      "grad_norm": 1.703891634941101,
      "learning_rate": 1.2562528216704291e-05,
      "loss": 0.1663,
      "step": 10700
    },
    {
      "epoch": 3.071677451468392,
      "grad_norm": 1.8282033205032349,
      "learning_rate": 1.2472234762979685e-05,
      "loss": 0.171,
      "step": 10800
    },
    {
      "epoch": 3.10012088459077,
      "grad_norm": 2.375535011291504,
      "learning_rate": 1.2381941309255081e-05,
      "loss": 0.171,
      "step": 10900
    },
    {
      "epoch": 3.128564317713148,
      "grad_norm": 1.6606837511062622,
      "learning_rate": 1.2291647855530475e-05,
      "loss": 0.1673,
      "step": 11000
    },
    {
      "epoch": 3.128564317713148,
      "eval_f1_macro": 0.8590395598327933,
      "eval_loss": 0.24746102094650269,
      "eval_runtime": 217.2022,
      "eval_samples_per_second": 920.801,
      "eval_steps_per_second": 7.196,
      "step": 11000
    },
    {
      "epoch": 3.157007750835526,
      "grad_norm": 2.734713554382324,
      "learning_rate": 1.220135440180587e-05,
      "loss": 0.1715,
      "step": 11100
    },
    {
      "epoch": 3.1854511839579036,
      "grad_norm": 2.2021191120147705,
      "learning_rate": 1.2111060948081266e-05,
      "loss": 0.1672,
      "step": 11200
    },
    {
      "epoch": 3.213894617080282,
      "grad_norm": 2.8130664825439453,
      "learning_rate": 1.202076749435666e-05,
      "loss": 0.174,
      "step": 11300
    },
    {
      "epoch": 3.2423380502026595,
      "grad_norm": 2.05892014503479,
      "learning_rate": 1.1930474040632055e-05,
      "loss": 0.1692,
      "step": 11400
    },
    {
      "epoch": 3.2707814833250373,
      "grad_norm": 2.5165810585021973,
      "learning_rate": 1.1840180586907451e-05,
      "loss": 0.1606,
      "step": 11500
    },
    {
      "epoch": 3.2992249164474154,
      "grad_norm": 2.1470487117767334,
      "learning_rate": 1.1749887133182845e-05,
      "loss": 0.1662,
      "step": 11600
    },
    {
      "epoch": 3.327668349569793,
      "grad_norm": 2.1096949577331543,
      "learning_rate": 1.1659593679458241e-05,
      "loss": 0.1731,
      "step": 11700
    },
    {
      "epoch": 3.356111782692171,
      "grad_norm": 2.2739417552948,
      "learning_rate": 1.1569300225733635e-05,
      "loss": 0.1664,
      "step": 11800
    },
    {
      "epoch": 3.3845552158145487,
      "grad_norm": 2.639411449432373,
      "learning_rate": 1.147900677200903e-05,
      "loss": 0.1632,
      "step": 11900
    },
    {
      "epoch": 3.412998648936927,
      "grad_norm": 2.370925188064575,
      "learning_rate": 1.1388713318284426e-05,
      "loss": 0.1672,
      "step": 12000
    },
    {
      "epoch": 3.412998648936927,
      "eval_f1_macro": 0.866122417107094,
      "eval_loss": 0.2347395122051239,
      "eval_runtime": 217.4311,
      "eval_samples_per_second": 919.832,
      "eval_steps_per_second": 7.188,
      "step": 12000
    },
    {
      "epoch": 3.4414420820593046,
      "grad_norm": 2.1896955966949463,
      "learning_rate": 1.129841986455982e-05,
      "loss": 0.1658,
      "step": 12100
    },
    {
      "epoch": 3.4698855151816823,
      "grad_norm": 2.6375348567962646,
      "learning_rate": 1.1208126410835216e-05,
      "loss": 0.1584,
      "step": 12200
    },
    {
      "epoch": 3.4983289483040605,
      "grad_norm": 2.188612937927246,
      "learning_rate": 1.111783295711061e-05,
      "loss": 0.1666,
      "step": 12300
    },
    {
      "epoch": 3.5267723814264382,
      "grad_norm": 3.7916712760925293,
      "learning_rate": 1.1027539503386004e-05,
      "loss": 0.1689,
      "step": 12400
    },
    {
      "epoch": 3.555215814548816,
      "grad_norm": 2.449514150619507,
      "learning_rate": 1.0937246049661401e-05,
      "loss": 0.1685,
      "step": 12500
    },
    {
      "epoch": 3.5836592476711937,
      "grad_norm": 1.8874390125274658,
      "learning_rate": 1.0846952595936794e-05,
      "loss": 0.1641,
      "step": 12600
    },
    {
      "epoch": 3.612102680793572,
      "grad_norm": 1.9655561447143555,
      "learning_rate": 1.0756659142212191e-05,
      "loss": 0.1707,
      "step": 12700
    },
    {
      "epoch": 3.6405461139159496,
      "grad_norm": 2.52311110496521,
      "learning_rate": 1.0666365688487586e-05,
      "loss": 0.1666,
      "step": 12800
    },
    {
      "epoch": 3.6689895470383274,
      "grad_norm": 2.4574108123779297,
      "learning_rate": 1.057607223476298e-05,
      "loss": 0.1639,
      "step": 12900
    },
    {
      "epoch": 3.6974329801607055,
      "grad_norm": 2.462627410888672,
      "learning_rate": 1.0485778781038376e-05,
      "loss": 0.163,
      "step": 13000
    },
    {
      "epoch": 3.6974329801607055,
      "eval_f1_macro": 0.8632021160419895,
      "eval_loss": 0.25088703632354736,
      "eval_runtime": 217.2847,
      "eval_samples_per_second": 920.451,
      "eval_steps_per_second": 7.193,
      "step": 13000
    },
    {
      "epoch": 3.7258764132830833,
      "grad_norm": 2.0739359855651855,
      "learning_rate": 1.039548532731377e-05,
      "loss": 0.1717,
      "step": 13100
    },
    {
      "epoch": 3.754319846405461,
      "grad_norm": 1.3466298580169678,
      "learning_rate": 1.0305191873589166e-05,
      "loss": 0.1638,
      "step": 13200
    },
    {
      "epoch": 3.782763279527839,
      "grad_norm": 1.7448128461837769,
      "learning_rate": 1.0214898419864561e-05,
      "loss": 0.1642,
      "step": 13300
    },
    {
      "epoch": 3.811206712650217,
      "grad_norm": 2.0125982761383057,
      "learning_rate": 1.0124604966139954e-05,
      "loss": 0.1622,
      "step": 13400
    },
    {
      "epoch": 3.8396501457725947,
      "grad_norm": 2.304746627807617,
      "learning_rate": 1.0034311512415351e-05,
      "loss": 0.1665,
      "step": 13500
    },
    {
      "epoch": 3.868093578894973,
      "grad_norm": 2.2760796546936035,
      "learning_rate": 9.944018058690746e-06,
      "loss": 0.167,
      "step": 13600
    },
    {
      "epoch": 3.8965370120173506,
      "grad_norm": 2.1790077686309814,
      "learning_rate": 9.853724604966141e-06,
      "loss": 0.1613,
      "step": 13700
    },
    {
      "epoch": 3.9249804451397283,
      "grad_norm": 2.0879106521606445,
      "learning_rate": 9.763431151241536e-06,
      "loss": 0.1622,
      "step": 13800
    },
    {
      "epoch": 3.9534238782621065,
      "grad_norm": 2.8732221126556396,
      "learning_rate": 9.673137697516931e-06,
      "loss": 0.1607,
      "step": 13900
    },
    {
      "epoch": 3.9818673113844842,
      "grad_norm": 2.00719952583313,
      "learning_rate": 9.582844243792326e-06,
      "loss": 0.1654,
      "step": 14000
    },
    {
      "epoch": 3.9818673113844842,
      "eval_f1_macro": 0.8679328170392977,
      "eval_loss": 0.2285321056842804,
      "eval_runtime": 217.357,
      "eval_samples_per_second": 920.145,
      "eval_steps_per_second": 7.191,
      "step": 14000
    },
    {
      "epoch": 4.010239635924056,
      "grad_norm": 2.154111385345459,
      "learning_rate": 9.492550790067721e-06,
      "loss": 0.1495,
      "step": 14100
    },
    {
      "epoch": 4.038683069046434,
      "grad_norm": 2.2444911003112793,
      "learning_rate": 9.402257336343116e-06,
      "loss": 0.1467,
      "step": 14200
    },
    {
      "epoch": 4.067126502168811,
      "grad_norm": 2.56764554977417,
      "learning_rate": 9.311963882618511e-06,
      "loss": 0.1413,
      "step": 14300
    },
    {
      "epoch": 4.09556993529119,
      "grad_norm": 1.6766855716705322,
      "learning_rate": 9.221670428893906e-06,
      "loss": 0.139,
      "step": 14400
    },
    {
      "epoch": 4.124013368413568,
      "grad_norm": 2.201211929321289,
      "learning_rate": 9.131376975169301e-06,
      "loss": 0.1367,
      "step": 14500
    },
    {
      "epoch": 4.152456801535945,
      "grad_norm": 2.379082441329956,
      "learning_rate": 9.041083521444696e-06,
      "loss": 0.1379,
      "step": 14600
    },
    {
      "epoch": 4.180900234658323,
      "grad_norm": 2.5182533264160156,
      "learning_rate": 8.950790067720091e-06,
      "loss": 0.1361,
      "step": 14700
    },
    {
      "epoch": 4.2093436677807015,
      "grad_norm": 2.07246470451355,
      "learning_rate": 8.860496613995486e-06,
      "loss": 0.1381,
      "step": 14800
    },
    {
      "epoch": 4.237787100903079,
      "grad_norm": 1.8982174396514893,
      "learning_rate": 8.770203160270881e-06,
      "loss": 0.1407,
      "step": 14900
    },
    {
      "epoch": 4.266230534025457,
      "grad_norm": 2.073260545730591,
      "learning_rate": 8.679909706546276e-06,
      "loss": 0.1421,
      "step": 15000
    },
    {
      "epoch": 4.266230534025457,
      "eval_f1_macro": 0.8654691888354886,
      "eval_loss": 0.25424641370773315,
      "eval_runtime": 217.3011,
      "eval_samples_per_second": 920.382,
      "eval_steps_per_second": 7.193,
      "step": 15000
    },
    {
      "epoch": 4.294673967147835,
      "grad_norm": 2.5411362648010254,
      "learning_rate": 8.589616252821671e-06,
      "loss": 0.1341,
      "step": 15100
    },
    {
      "epoch": 4.323117400270212,
      "grad_norm": 3.4099762439727783,
      "learning_rate": 8.499322799097066e-06,
      "loss": 0.1439,
      "step": 15200
    },
    {
      "epoch": 4.351560833392591,
      "grad_norm": 1.5718226432800293,
      "learning_rate": 8.409029345372461e-06,
      "loss": 0.1443,
      "step": 15300
    },
    {
      "epoch": 4.380004266514969,
      "grad_norm": 2.349238634109497,
      "learning_rate": 8.318735891647856e-06,
      "loss": 0.1356,
      "step": 15400
    },
    {
      "epoch": 4.408447699637346,
      "grad_norm": 2.736563205718994,
      "learning_rate": 8.228442437923251e-06,
      "loss": 0.1436,
      "step": 15500
    },
    {
      "epoch": 4.436891132759724,
      "grad_norm": 2.0803539752960205,
      "learning_rate": 8.138148984198646e-06,
      "loss": 0.1424,
      "step": 15600
    },
    {
      "epoch": 4.465334565882102,
      "grad_norm": 2.4422695636749268,
      "learning_rate": 8.047855530474041e-06,
      "loss": 0.1476,
      "step": 15700
    },
    {
      "epoch": 4.49377799900448,
      "grad_norm": 1.783575177192688,
      "learning_rate": 7.957562076749436e-06,
      "loss": 0.1328,
      "step": 15800
    },
    {
      "epoch": 4.522221432126858,
      "grad_norm": 2.4493863582611084,
      "learning_rate": 7.867268623024831e-06,
      "loss": 0.1457,
      "step": 15900
    },
    {
      "epoch": 4.550664865249235,
      "grad_norm": 2.038050413131714,
      "learning_rate": 7.776975169300226e-06,
      "loss": 0.1402,
      "step": 16000
    },
    {
      "epoch": 4.550664865249235,
      "eval_f1_macro": 0.8676435981315963,
      "eval_loss": 0.2438107281923294,
      "eval_runtime": 217.3583,
      "eval_samples_per_second": 920.14,
      "eval_steps_per_second": 7.191,
      "step": 16000
    },
    {
      "epoch": 4.579108298371613,
      "grad_norm": 2.9367384910583496,
      "learning_rate": 7.686681715575621e-06,
      "loss": 0.1416,
      "step": 16100
    },
    {
      "epoch": 4.6075517314939916,
      "grad_norm": 3.0090832710266113,
      "learning_rate": 7.596388261851017e-06,
      "loss": 0.1435,
      "step": 16200
    },
    {
      "epoch": 4.635995164616369,
      "grad_norm": 1.4498564004898071,
      "learning_rate": 7.506094808126412e-06,
      "loss": 0.1418,
      "step": 16300
    },
    {
      "epoch": 4.664438597738747,
      "grad_norm": 2.986456871032715,
      "learning_rate": 7.415801354401806e-06,
      "loss": 0.1424,
      "step": 16400
    },
    {
      "epoch": 4.692882030861125,
      "grad_norm": 1.9505444765090942,
      "learning_rate": 7.325507900677201e-06,
      "loss": 0.1374,
      "step": 16500
    },
    {
      "epoch": 4.7213254639835025,
      "grad_norm": 2.3456130027770996,
      "learning_rate": 7.235214446952597e-06,
      "loss": 0.14,
      "step": 16600
    },
    {
      "epoch": 4.749768897105881,
      "grad_norm": 1.8802907466888428,
      "learning_rate": 7.144920993227992e-06,
      "loss": 0.1415,
      "step": 16700
    },
    {
      "epoch": 4.778212330228259,
      "grad_norm": 2.4854636192321777,
      "learning_rate": 7.054627539503387e-06,
      "loss": 0.141,
      "step": 16800
    },
    {
      "epoch": 4.806655763350636,
      "grad_norm": 2.423563003540039,
      "learning_rate": 6.964334085778781e-06,
      "loss": 0.1386,
      "step": 16900
    },
    {
      "epoch": 4.835099196473014,
      "grad_norm": 2.6050760746002197,
      "learning_rate": 6.874040632054176e-06,
      "loss": 0.1418,
      "step": 17000
    },
    {
      "epoch": 4.835099196473014,
      "eval_f1_macro": 0.8632686814962897,
      "eval_loss": 0.2501925826072693,
      "eval_runtime": 217.2005,
      "eval_samples_per_second": 920.808,
      "eval_steps_per_second": 7.196,
      "step": 17000
    },
    {
      "epoch": 4.8635426295953925,
      "grad_norm": 2.039167881011963,
      "learning_rate": 6.783747178329572e-06,
      "loss": 0.1411,
      "step": 17100
    },
    {
      "epoch": 4.89198606271777,
      "grad_norm": 2.512986421585083,
      "learning_rate": 6.693453724604967e-06,
      "loss": 0.1378,
      "step": 17200
    },
    {
      "epoch": 4.920429495840148,
      "grad_norm": 2.4922659397125244,
      "learning_rate": 6.603160270880362e-06,
      "loss": 0.1397,
      "step": 17300
    },
    {
      "epoch": 4.948872928962526,
      "grad_norm": 3.819324254989624,
      "learning_rate": 6.512866817155756e-06,
      "loss": 0.1418,
      "step": 17400
    },
    {
      "epoch": 4.9773163620849035,
      "grad_norm": 2.97226881980896,
      "learning_rate": 6.422573363431152e-06,
      "loss": 0.1377,
      "step": 17500
    },
    {
      "epoch": 5.005688686624476,
      "grad_norm": 2.835029363632202,
      "learning_rate": 6.332279909706547e-06,
      "loss": 0.1375,
      "step": 17600
    },
    {
      "epoch": 5.034132119746854,
      "grad_norm": 2.0764403343200684,
      "learning_rate": 6.241986455981942e-06,
      "loss": 0.1159,
      "step": 17700
    },
    {
      "epoch": 5.062575552869231,
      "grad_norm": 1.9334636926651,
      "learning_rate": 6.151693002257338e-06,
      "loss": 0.1162,
      "step": 17800
    },
    {
      "epoch": 5.091018985991609,
      "grad_norm": 2.461751699447632,
      "learning_rate": 6.061399548532732e-06,
      "loss": 0.117,
      "step": 17900
    },
    {
      "epoch": 5.1194624191139875,
      "grad_norm": 2.468216896057129,
      "learning_rate": 5.971106094808127e-06,
      "loss": 0.1219,
      "step": 18000
    },
    {
      "epoch": 5.1194624191139875,
      "eval_f1_macro": 0.8694378198787841,
      "eval_loss": 0.25506311655044556,
      "eval_runtime": 217.4437,
      "eval_samples_per_second": 919.778,
      "eval_steps_per_second": 7.188,
      "step": 18000
    }
  ],
  "logging_steps": 100,
  "max_steps": 24612,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 7,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2075756284082816e+18,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
