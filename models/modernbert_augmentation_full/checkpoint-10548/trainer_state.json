{
  "best_global_step": 10000,
  "best_metric": 0.8072475173475012,
  "best_model_checkpoint": "./models/modernbert_augmentation_full/checkpoint-10000",
  "epoch": 3.0,
  "eval_steps": 1000,
  "global_step": 10548,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00028443433122377873,
      "grad_norm": Infinity,
      "learning_rate": 0.0,
      "loss": 5.9608,
      "step": 1
    },
    {
      "epoch": 0.028443433122377872,
      "grad_norm": 14.141789436340332,
      "learning_rate": 1.8767772511848342e-06,
      "loss": 4.6743,
      "step": 100
    },
    {
      "epoch": 0.056886866244755745,
      "grad_norm": 22.658323287963867,
      "learning_rate": 3.772511848341233e-06,
      "loss": 3.3888,
      "step": 200
    },
    {
      "epoch": 0.08533029936713361,
      "grad_norm": 29.358240127563477,
      "learning_rate": 5.66824644549763e-06,
      "loss": 2.6847,
      "step": 300
    },
    {
      "epoch": 0.11377373248951149,
      "grad_norm": 17.48407745361328,
      "learning_rate": 7.563981042654029e-06,
      "loss": 2.2884,
      "step": 400
    },
    {
      "epoch": 0.14221716561188935,
      "grad_norm": 31.077438354492188,
      "learning_rate": 9.459715639810427e-06,
      "loss": 2.0416,
      "step": 500
    },
    {
      "epoch": 0.17066059873426723,
      "grad_norm": 29.9604434967041,
      "learning_rate": 1.1355450236966825e-05,
      "loss": 1.9798,
      "step": 600
    },
    {
      "epoch": 0.1991040318566451,
      "grad_norm": 20.51716423034668,
      "learning_rate": 1.3251184834123222e-05,
      "loss": 1.7919,
      "step": 700
    },
    {
      "epoch": 0.22754746497902298,
      "grad_norm": 39.624813079833984,
      "learning_rate": 1.5146919431279623e-05,
      "loss": 1.7328,
      "step": 800
    },
    {
      "epoch": 0.25599089810140085,
      "grad_norm": 19.13629150390625,
      "learning_rate": 1.704265402843602e-05,
      "loss": 1.6884,
      "step": 900
    },
    {
      "epoch": 0.2844343312237787,
      "grad_norm": 14.734429359436035,
      "learning_rate": 1.8938388625592418e-05,
      "loss": 1.6004,
      "step": 1000
    },
    {
      "epoch": 0.2844343312237787,
      "eval_f1_macro": 0.7443654834437687,
      "eval_loss": 0.4414750039577484,
      "eval_runtime": 589.9475,
      "eval_samples_per_second": 339.013,
      "eval_steps_per_second": 2.649,
      "step": 1000
    },
    {
      "epoch": 0.3128777643461566,
      "grad_norm": 15.892980575561523,
      "learning_rate": 1.9907300115874858e-05,
      "loss": 1.6437,
      "step": 1100
    },
    {
      "epoch": 0.34132119746853445,
      "grad_norm": 14.772615432739258,
      "learning_rate": 1.969661856104498e-05,
      "loss": 1.4873,
      "step": 1200
    },
    {
      "epoch": 0.3697646305909123,
      "grad_norm": 13.526727676391602,
      "learning_rate": 1.9485937006215108e-05,
      "loss": 1.4817,
      "step": 1300
    },
    {
      "epoch": 0.3982080637132902,
      "grad_norm": 25.03652000427246,
      "learning_rate": 1.927525545138523e-05,
      "loss": 1.4385,
      "step": 1400
    },
    {
      "epoch": 0.42665149683566805,
      "grad_norm": 19.774927139282227,
      "learning_rate": 1.906457389655536e-05,
      "loss": 1.3741,
      "step": 1500
    },
    {
      "epoch": 0.45509492995804596,
      "grad_norm": 14.373128890991211,
      "learning_rate": 1.8853892341725482e-05,
      "loss": 1.3943,
      "step": 1600
    },
    {
      "epoch": 0.4835383630804238,
      "grad_norm": 10.35561752319336,
      "learning_rate": 1.864321078689561e-05,
      "loss": 1.3552,
      "step": 1700
    },
    {
      "epoch": 0.5119817962028017,
      "grad_norm": 17.34040069580078,
      "learning_rate": 1.8432529232065736e-05,
      "loss": 1.3107,
      "step": 1800
    },
    {
      "epoch": 0.5404252293251796,
      "grad_norm": 13.053321838378906,
      "learning_rate": 1.822184767723586e-05,
      "loss": 1.3074,
      "step": 1900
    },
    {
      "epoch": 0.5688686624475574,
      "grad_norm": 13.164009094238281,
      "learning_rate": 1.8011166122405986e-05,
      "loss": 1.2746,
      "step": 2000
    },
    {
      "epoch": 0.5688686624475574,
      "eval_f1_macro": 0.7666542972941892,
      "eval_loss": 0.3822929561138153,
      "eval_runtime": 589.1866,
      "eval_samples_per_second": 339.451,
      "eval_steps_per_second": 2.653,
      "step": 2000
    },
    {
      "epoch": 0.5973120955699353,
      "grad_norm": 19.42584991455078,
      "learning_rate": 1.780048456757611e-05,
      "loss": 1.2478,
      "step": 2100
    },
    {
      "epoch": 0.6257555286923132,
      "grad_norm": 14.49954605102539,
      "learning_rate": 1.7589803012746237e-05,
      "loss": 1.2226,
      "step": 2200
    },
    {
      "epoch": 0.6541989618146911,
      "grad_norm": 19.845869064331055,
      "learning_rate": 1.737912145791636e-05,
      "loss": 1.2151,
      "step": 2300
    },
    {
      "epoch": 0.6826423949370689,
      "grad_norm": 8.833301544189453,
      "learning_rate": 1.7168439903086487e-05,
      "loss": 1.1914,
      "step": 2400
    },
    {
      "epoch": 0.7110858280594468,
      "grad_norm": 10.621519088745117,
      "learning_rate": 1.695775834825661e-05,
      "loss": 1.2062,
      "step": 2500
    },
    {
      "epoch": 0.7395292611818246,
      "grad_norm": 8.392071723937988,
      "learning_rate": 1.6747076793426738e-05,
      "loss": 1.1935,
      "step": 2600
    },
    {
      "epoch": 0.7679726943042026,
      "grad_norm": 10.985806465148926,
      "learning_rate": 1.653639523859686e-05,
      "loss": 1.1553,
      "step": 2700
    },
    {
      "epoch": 0.7964161274265804,
      "grad_norm": 10.6315336227417,
      "learning_rate": 1.632571368376699e-05,
      "loss": 1.1455,
      "step": 2800
    },
    {
      "epoch": 0.8248595605489583,
      "grad_norm": 10.467647552490234,
      "learning_rate": 1.6115032128937115e-05,
      "loss": 1.1592,
      "step": 2900
    },
    {
      "epoch": 0.8533029936713361,
      "grad_norm": 6.315155029296875,
      "learning_rate": 1.590435057410724e-05,
      "loss": 1.1252,
      "step": 3000
    },
    {
      "epoch": 0.8533029936713361,
      "eval_f1_macro": 0.762623385298203,
      "eval_loss": 0.3906070291996002,
      "eval_runtime": 589.1452,
      "eval_samples_per_second": 339.475,
      "eval_steps_per_second": 2.653,
      "step": 3000
    },
    {
      "epoch": 0.881746426793714,
      "grad_norm": 12.703368186950684,
      "learning_rate": 1.5693669019277366e-05,
      "loss": 1.1377,
      "step": 3100
    },
    {
      "epoch": 0.9101898599160919,
      "grad_norm": 9.409849166870117,
      "learning_rate": 1.548298746444749e-05,
      "loss": 1.1353,
      "step": 3200
    },
    {
      "epoch": 0.9386332930384698,
      "grad_norm": 11.168050765991211,
      "learning_rate": 1.5272305909617616e-05,
      "loss": 1.125,
      "step": 3300
    },
    {
      "epoch": 0.9670767261608476,
      "grad_norm": 11.264666557312012,
      "learning_rate": 1.506162435478774e-05,
      "loss": 1.1123,
      "step": 3400
    },
    {
      "epoch": 0.9955201592832255,
      "grad_norm": 10.783181190490723,
      "learning_rate": 1.4850942799957867e-05,
      "loss": 1.107,
      "step": 3500
    },
    {
      "epoch": 1.0238924838227974,
      "grad_norm": 7.637876033782959,
      "learning_rate": 1.4640261245127992e-05,
      "loss": 1.0221,
      "step": 3600
    },
    {
      "epoch": 1.0523359169451754,
      "grad_norm": 10.76158332824707,
      "learning_rate": 1.4429579690298117e-05,
      "loss": 1.0434,
      "step": 3700
    },
    {
      "epoch": 1.080779350067553,
      "grad_norm": 8.572842597961426,
      "learning_rate": 1.4218898135468239e-05,
      "loss": 1.0189,
      "step": 3800
    },
    {
      "epoch": 1.109222783189931,
      "grad_norm": 10.598355293273926,
      "learning_rate": 1.4008216580638366e-05,
      "loss": 0.998,
      "step": 3900
    },
    {
      "epoch": 1.1376662163123088,
      "grad_norm": 10.129782676696777,
      "learning_rate": 1.3797535025808491e-05,
      "loss": 0.9983,
      "step": 4000
    },
    {
      "epoch": 1.1376662163123088,
      "eval_f1_macro": 0.7820928442074104,
      "eval_loss": 0.407315731048584,
      "eval_runtime": 587.7339,
      "eval_samples_per_second": 340.29,
      "eval_steps_per_second": 2.659,
      "step": 4000
    },
    {
      "epoch": 1.1661096494346868,
      "grad_norm": 11.647200584411621,
      "learning_rate": 1.3586853470978616e-05,
      "loss": 1.0223,
      "step": 4100
    },
    {
      "epoch": 1.1945530825570647,
      "grad_norm": 10.507254600524902,
      "learning_rate": 1.3376171916148742e-05,
      "loss": 0.9916,
      "step": 4200
    },
    {
      "epoch": 1.2229965156794425,
      "grad_norm": 7.820980072021484,
      "learning_rate": 1.3165490361318867e-05,
      "loss": 1.007,
      "step": 4300
    },
    {
      "epoch": 1.2514399488018204,
      "grad_norm": 14.604844093322754,
      "learning_rate": 1.2954808806488992e-05,
      "loss": 0.9993,
      "step": 4400
    },
    {
      "epoch": 1.2798833819241984,
      "grad_norm": 11.44324016571045,
      "learning_rate": 1.2744127251659117e-05,
      "loss": 0.9866,
      "step": 4500
    },
    {
      "epoch": 1.308326815046576,
      "grad_norm": 13.037067413330078,
      "learning_rate": 1.2533445696829243e-05,
      "loss": 0.9665,
      "step": 4600
    },
    {
      "epoch": 1.336770248168954,
      "grad_norm": 7.464720249176025,
      "learning_rate": 1.2322764141999368e-05,
      "loss": 0.9974,
      "step": 4700
    },
    {
      "epoch": 1.3652136812913318,
      "grad_norm": 9.721668243408203,
      "learning_rate": 1.2112082587169493e-05,
      "loss": 0.9709,
      "step": 4800
    },
    {
      "epoch": 1.3936571144137098,
      "grad_norm": 11.40792179107666,
      "learning_rate": 1.1901401032339618e-05,
      "loss": 0.9732,
      "step": 4900
    },
    {
      "epoch": 1.4221005475360875,
      "grad_norm": 14.193339347839355,
      "learning_rate": 1.1690719477509744e-05,
      "loss": 0.9746,
      "step": 5000
    },
    {
      "epoch": 1.4221005475360875,
      "eval_f1_macro": 0.7908323221694022,
      "eval_loss": 0.3854709267616272,
      "eval_runtime": 585.7563,
      "eval_samples_per_second": 341.439,
      "eval_steps_per_second": 2.668,
      "step": 5000
    },
    {
      "epoch": 1.4505439806584655,
      "grad_norm": 12.597928047180176,
      "learning_rate": 1.148003792267987e-05,
      "loss": 0.9763,
      "step": 5100
    },
    {
      "epoch": 1.4789874137808434,
      "grad_norm": 12.337923049926758,
      "learning_rate": 1.1269356367849996e-05,
      "loss": 0.9686,
      "step": 5200
    },
    {
      "epoch": 1.5074308469032212,
      "grad_norm": 8.611709594726562,
      "learning_rate": 1.1058674813020121e-05,
      "loss": 0.9581,
      "step": 5300
    },
    {
      "epoch": 1.5358742800255991,
      "grad_norm": 13.517553329467773,
      "learning_rate": 1.0847993258190246e-05,
      "loss": 0.9581,
      "step": 5400
    },
    {
      "epoch": 1.564317713147977,
      "grad_norm": 10.169903755187988,
      "learning_rate": 1.0637311703360371e-05,
      "loss": 0.9422,
      "step": 5500
    },
    {
      "epoch": 1.5927611462703548,
      "grad_norm": 7.606008052825928,
      "learning_rate": 1.0426630148530497e-05,
      "loss": 0.9469,
      "step": 5600
    },
    {
      "epoch": 1.6212045793927325,
      "grad_norm": 9.038195610046387,
      "learning_rate": 1.0215948593700622e-05,
      "loss": 0.9664,
      "step": 5700
    },
    {
      "epoch": 1.6496480125151107,
      "grad_norm": 7.9724202156066895,
      "learning_rate": 1.0005267038870747e-05,
      "loss": 0.9691,
      "step": 5800
    },
    {
      "epoch": 1.6780914456374885,
      "grad_norm": 16.446252822875977,
      "learning_rate": 9.794585484040872e-06,
      "loss": 0.9317,
      "step": 5900
    },
    {
      "epoch": 1.7065348787598662,
      "grad_norm": 10.102714538574219,
      "learning_rate": 9.583903929210998e-06,
      "loss": 0.9406,
      "step": 6000
    },
    {
      "epoch": 1.7065348787598662,
      "eval_f1_macro": 0.7836824380485137,
      "eval_loss": 0.40177643299102783,
      "eval_runtime": 586.1147,
      "eval_samples_per_second": 341.23,
      "eval_steps_per_second": 2.667,
      "step": 6000
    },
    {
      "epoch": 1.7349783118822442,
      "grad_norm": 10.08722972869873,
      "learning_rate": 9.373222374381123e-06,
      "loss": 0.9422,
      "step": 6100
    },
    {
      "epoch": 1.7634217450046221,
      "grad_norm": 11.014583587646484,
      "learning_rate": 9.162540819551248e-06,
      "loss": 0.9257,
      "step": 6200
    },
    {
      "epoch": 1.7918651781269999,
      "grad_norm": 14.619074821472168,
      "learning_rate": 8.951859264721375e-06,
      "loss": 0.947,
      "step": 6300
    },
    {
      "epoch": 1.8203086112493778,
      "grad_norm": 9.988765716552734,
      "learning_rate": 8.7411777098915e-06,
      "loss": 0.9592,
      "step": 6400
    },
    {
      "epoch": 1.8487520443717558,
      "grad_norm": 17.74214744567871,
      "learning_rate": 8.530496155061625e-06,
      "loss": 0.9271,
      "step": 6500
    },
    {
      "epoch": 1.8771954774941335,
      "grad_norm": 9.89383602142334,
      "learning_rate": 8.31981460023175e-06,
      "loss": 0.9442,
      "step": 6600
    },
    {
      "epoch": 1.9056389106165113,
      "grad_norm": 7.668569087982178,
      "learning_rate": 8.109133045401876e-06,
      "loss": 0.9344,
      "step": 6700
    },
    {
      "epoch": 1.9340823437388894,
      "grad_norm": 11.553939819335938,
      "learning_rate": 7.898451490572001e-06,
      "loss": 0.9478,
      "step": 6800
    },
    {
      "epoch": 1.9625257768612672,
      "grad_norm": 29.342695236206055,
      "learning_rate": 7.687769935742126e-06,
      "loss": 0.9274,
      "step": 6900
    },
    {
      "epoch": 1.990969209983645,
      "grad_norm": 13.495636940002441,
      "learning_rate": 7.477088380912252e-06,
      "loss": 0.9179,
      "step": 7000
    },
    {
      "epoch": 1.990969209983645,
      "eval_f1_macro": 0.8067278837621258,
      "eval_loss": 0.3420841693878174,
      "eval_runtime": 585.6324,
      "eval_samples_per_second": 341.511,
      "eval_steps_per_second": 2.669,
      "step": 7000
    },
    {
      "epoch": 2.019341534523217,
      "grad_norm": 8.704317092895508,
      "learning_rate": 7.266406826082377e-06,
      "loss": 0.8458,
      "step": 7100
    },
    {
      "epoch": 2.047784967645595,
      "grad_norm": 9.212255477905273,
      "learning_rate": 7.055725271252503e-06,
      "loss": 0.8021,
      "step": 7200
    },
    {
      "epoch": 2.0762284007679725,
      "grad_norm": 9.548757553100586,
      "learning_rate": 6.845043716422628e-06,
      "loss": 0.8018,
      "step": 7300
    },
    {
      "epoch": 2.1046718338903507,
      "grad_norm": 8.82098388671875,
      "learning_rate": 6.6343621615927535e-06,
      "loss": 0.7756,
      "step": 7400
    },
    {
      "epoch": 2.1331152670127285,
      "grad_norm": 10.08976936340332,
      "learning_rate": 6.423680606762879e-06,
      "loss": 0.8028,
      "step": 7500
    },
    {
      "epoch": 2.161558700135106,
      "grad_norm": 10.589619636535645,
      "learning_rate": 6.212999051933004e-06,
      "loss": 0.7902,
      "step": 7600
    },
    {
      "epoch": 2.1900021332574844,
      "grad_norm": 11.093317031860352,
      "learning_rate": 6.002317497103129e-06,
      "loss": 0.766,
      "step": 7700
    },
    {
      "epoch": 2.218445566379862,
      "grad_norm": 10.26932144165039,
      "learning_rate": 5.791635942273255e-06,
      "loss": 0.7874,
      "step": 7800
    },
    {
      "epoch": 2.24688899950224,
      "grad_norm": 9.119915008544922,
      "learning_rate": 5.5809543874433805e-06,
      "loss": 0.7988,
      "step": 7900
    },
    {
      "epoch": 2.2753324326246176,
      "grad_norm": 8.740785598754883,
      "learning_rate": 5.370272832613506e-06,
      "loss": 0.8089,
      "step": 8000
    },
    {
      "epoch": 2.2753324326246176,
      "eval_f1_macro": 0.8013934123450862,
      "eval_loss": 0.3757208585739136,
      "eval_runtime": 588.994,
      "eval_samples_per_second": 339.562,
      "eval_steps_per_second": 2.654,
      "step": 8000
    },
    {
      "epoch": 2.3037758657469958,
      "grad_norm": 11.423422813415527,
      "learning_rate": 5.159591277783631e-06,
      "loss": 0.7879,
      "step": 8100
    },
    {
      "epoch": 2.3322192988693735,
      "grad_norm": 12.114550590515137,
      "learning_rate": 4.948909722953756e-06,
      "loss": 0.7644,
      "step": 8200
    },
    {
      "epoch": 2.3606627319917513,
      "grad_norm": 9.107661247253418,
      "learning_rate": 4.7382281681238814e-06,
      "loss": 0.7624,
      "step": 8300
    },
    {
      "epoch": 2.3891061651141294,
      "grad_norm": 9.122854232788086,
      "learning_rate": 4.527546613294007e-06,
      "loss": 0.7771,
      "step": 8400
    },
    {
      "epoch": 2.417549598236507,
      "grad_norm": 13.212602615356445,
      "learning_rate": 4.316865058464132e-06,
      "loss": 0.7712,
      "step": 8500
    },
    {
      "epoch": 2.445993031358885,
      "grad_norm": 8.306890487670898,
      "learning_rate": 4.106183503634257e-06,
      "loss": 0.7881,
      "step": 8600
    },
    {
      "epoch": 2.474436464481263,
      "grad_norm": 13.248808860778809,
      "learning_rate": 3.895501948804382e-06,
      "loss": 0.7811,
      "step": 8700
    },
    {
      "epoch": 2.502879897603641,
      "grad_norm": 11.010550498962402,
      "learning_rate": 3.684820393974508e-06,
      "loss": 0.7716,
      "step": 8800
    },
    {
      "epoch": 2.5313233307260186,
      "grad_norm": 11.019254684448242,
      "learning_rate": 3.474138839144633e-06,
      "loss": 0.763,
      "step": 8900
    },
    {
      "epoch": 2.5597667638483967,
      "grad_norm": 7.668501853942871,
      "learning_rate": 3.263457284314758e-06,
      "loss": 0.7683,
      "step": 9000
    },
    {
      "epoch": 2.5597667638483967,
      "eval_f1_macro": 0.8039122001009245,
      "eval_loss": 0.37156063318252563,
      "eval_runtime": 586.5867,
      "eval_samples_per_second": 340.956,
      "eval_steps_per_second": 2.665,
      "step": 9000
    },
    {
      "epoch": 2.5882101969707745,
      "grad_norm": 10.89794635772705,
      "learning_rate": 3.0527757294848838e-06,
      "loss": 0.7613,
      "step": 9100
    },
    {
      "epoch": 2.616653630093152,
      "grad_norm": 11.790863990783691,
      "learning_rate": 2.842094174655009e-06,
      "loss": 0.7873,
      "step": 9200
    },
    {
      "epoch": 2.64509706321553,
      "grad_norm": 9.724597930908203,
      "learning_rate": 2.6314126198251342e-06,
      "loss": 0.7944,
      "step": 9300
    },
    {
      "epoch": 2.673540496337908,
      "grad_norm": 10.167797088623047,
      "learning_rate": 2.42073106499526e-06,
      "loss": 0.7782,
      "step": 9400
    },
    {
      "epoch": 2.701983929460286,
      "grad_norm": 9.973942756652832,
      "learning_rate": 2.210049510165385e-06,
      "loss": 0.7554,
      "step": 9500
    },
    {
      "epoch": 2.7304273625826636,
      "grad_norm": 9.266180992126465,
      "learning_rate": 1.9993679553355104e-06,
      "loss": 0.745,
      "step": 9600
    },
    {
      "epoch": 2.7588707957050413,
      "grad_norm": 10.042920112609863,
      "learning_rate": 1.7886864005056358e-06,
      "loss": 0.7573,
      "step": 9700
    },
    {
      "epoch": 2.7873142288274195,
      "grad_norm": 10.709399223327637,
      "learning_rate": 1.5780048456757613e-06,
      "loss": 0.7509,
      "step": 9800
    },
    {
      "epoch": 2.8157576619497973,
      "grad_norm": 9.655155181884766,
      "learning_rate": 1.3673232908458867e-06,
      "loss": 0.7616,
      "step": 9900
    },
    {
      "epoch": 2.844201095072175,
      "grad_norm": 12.176102638244629,
      "learning_rate": 1.156641736016012e-06,
      "loss": 0.749,
      "step": 10000
    },
    {
      "epoch": 2.844201095072175,
      "eval_f1_macro": 0.8072475173475012,
      "eval_loss": 0.3716264069080353,
      "eval_runtime": 585.8677,
      "eval_samples_per_second": 341.374,
      "eval_steps_per_second": 2.668,
      "step": 10000
    },
    {
      "epoch": 2.872644528194553,
      "grad_norm": 11.263333320617676,
      "learning_rate": 9.459601811861373e-07,
      "loss": 0.7668,
      "step": 10100
    },
    {
      "epoch": 2.901087961316931,
      "grad_norm": 10.427441596984863,
      "learning_rate": 7.352786263562625e-07,
      "loss": 0.7412,
      "step": 10200
    },
    {
      "epoch": 2.9295313944393087,
      "grad_norm": 10.786481857299805,
      "learning_rate": 5.245970715263879e-07,
      "loss": 0.7728,
      "step": 10300
    },
    {
      "epoch": 2.957974827561687,
      "grad_norm": 9.896296501159668,
      "learning_rate": 3.1391551669651327e-07,
      "loss": 0.7315,
      "step": 10400
    },
    {
      "epoch": 2.9864182606840646,
      "grad_norm": 9.595512390136719,
      "learning_rate": 1.032339618666386e-07,
      "loss": 0.7413,
      "step": 10500
    }
  ],
  "logging_steps": 100,
  "max_steps": 10548,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.16464960792e+17,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
