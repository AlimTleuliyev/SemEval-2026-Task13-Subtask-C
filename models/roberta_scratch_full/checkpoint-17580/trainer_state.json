{
  "best_global_step": 16000,
  "best_metric": 0.7464748808173549,
  "best_model_checkpoint": "./models/roberta_scratch_full/checkpoint-16000",
  "epoch": 5.0,
  "eval_steps": 1000,
  "global_step": 17580,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00028443433122377873,
      "grad_norm": 9.496243476867676,
      "learning_rate": 0.0,
      "loss": 1.357,
      "step": 1
    },
    {
      "epoch": 0.014221716561188936,
      "grad_norm": 2.186899423599243,
      "learning_rate": 1.3936291240045508e-06,
      "loss": 1.229,
      "step": 50
    },
    {
      "epoch": 0.028443433122377872,
      "grad_norm": 1.588896632194519,
      "learning_rate": 2.815699658703072e-06,
      "loss": 1.1466,
      "step": 100
    },
    {
      "epoch": 0.04266514968356681,
      "grad_norm": 1.489472508430481,
      "learning_rate": 4.237770193401593e-06,
      "loss": 1.128,
      "step": 150
    },
    {
      "epoch": 0.056886866244755745,
      "grad_norm": 12.422619819641113,
      "learning_rate": 5.659840728100114e-06,
      "loss": 1.0816,
      "step": 200
    },
    {
      "epoch": 0.07110858280594468,
      "grad_norm": 23.944225311279297,
      "learning_rate": 7.081911262798635e-06,
      "loss": 1.0284,
      "step": 250
    },
    {
      "epoch": 0.08533029936713361,
      "grad_norm": 33.59757995605469,
      "learning_rate": 8.503981797497158e-06,
      "loss": 1.0413,
      "step": 300
    },
    {
      "epoch": 0.09955201592832255,
      "grad_norm": 19.146095275878906,
      "learning_rate": 9.926052332195678e-06,
      "loss": 1.0539,
      "step": 350
    },
    {
      "epoch": 0.11377373248951149,
      "grad_norm": 2.0245144367218018,
      "learning_rate": 1.1348122866894199e-05,
      "loss": 1.004,
      "step": 400
    },
    {
      "epoch": 0.12799544905070043,
      "grad_norm": 20.634538650512695,
      "learning_rate": 1.277019340159272e-05,
      "loss": 0.9493,
      "step": 450
    },
    {
      "epoch": 0.14221716561188935,
      "grad_norm": 26.052425384521484,
      "learning_rate": 1.4192263936291241e-05,
      "loss": 0.9313,
      "step": 500
    },
    {
      "epoch": 0.1564388821730783,
      "grad_norm": 27.19122314453125,
      "learning_rate": 1.561433447098976e-05,
      "loss": 0.9138,
      "step": 550
    },
    {
      "epoch": 0.17066059873426723,
      "grad_norm": 35.16135025024414,
      "learning_rate": 1.7036405005688282e-05,
      "loss": 0.8964,
      "step": 600
    },
    {
      "epoch": 0.18488231529545615,
      "grad_norm": 15.529702186584473,
      "learning_rate": 1.8458475540386805e-05,
      "loss": 0.8413,
      "step": 650
    },
    {
      "epoch": 0.1991040318566451,
      "grad_norm": 5.309675693511963,
      "learning_rate": 1.9880546075085323e-05,
      "loss": 0.8214,
      "step": 700
    },
    {
      "epoch": 0.21332574841783403,
      "grad_norm": 18.60980796813965,
      "learning_rate": 2.1302616609783846e-05,
      "loss": 0.79,
      "step": 750
    },
    {
      "epoch": 0.22754746497902298,
      "grad_norm": 11.102580070495605,
      "learning_rate": 2.2724687144482368e-05,
      "loss": 0.7976,
      "step": 800
    },
    {
      "epoch": 0.2417691815402119,
      "grad_norm": 11.873358726501465,
      "learning_rate": 2.414675767918089e-05,
      "loss": 0.7617,
      "step": 850
    },
    {
      "epoch": 0.25599089810140085,
      "grad_norm": 7.02114725112915,
      "learning_rate": 2.556882821387941e-05,
      "loss": 0.7685,
      "step": 900
    },
    {
      "epoch": 0.2702126146625898,
      "grad_norm": 3.07535457611084,
      "learning_rate": 2.699089874857793e-05,
      "loss": 0.7186,
      "step": 950
    },
    {
      "epoch": 0.2844343312237787,
      "grad_norm": 10.434076309204102,
      "learning_rate": 2.8412969283276453e-05,
      "loss": 0.7249,
      "step": 1000
    },
    {
      "epoch": 0.2844343312237787,
      "eval_f1_macro": 0.5396630427244409,
      "eval_loss": 0.6730431914329529,
      "eval_runtime": 217.946,
      "eval_samples_per_second": 917.659,
      "eval_steps_per_second": 7.172,
      "step": 1000
    },
    {
      "epoch": 0.2986560477849676,
      "grad_norm": 4.798405170440674,
      "learning_rate": 2.9835039817974975e-05,
      "loss": 0.7018,
      "step": 1050
    },
    {
      "epoch": 0.3128777643461566,
      "grad_norm": 9.975968360900879,
      "learning_rate": 3.1257110352673494e-05,
      "loss": 0.7226,
      "step": 1100
    },
    {
      "epoch": 0.32709948090734553,
      "grad_norm": 2.4938104152679443,
      "learning_rate": 3.267918088737201e-05,
      "loss": 0.6796,
      "step": 1150
    },
    {
      "epoch": 0.34132119746853445,
      "grad_norm": 5.454225063323975,
      "learning_rate": 3.410125142207053e-05,
      "loss": 0.6471,
      "step": 1200
    },
    {
      "epoch": 0.3555429140297234,
      "grad_norm": 5.892391681671143,
      "learning_rate": 3.552332195676906e-05,
      "loss": 0.6398,
      "step": 1250
    },
    {
      "epoch": 0.3697646305909123,
      "grad_norm": 10.41336727142334,
      "learning_rate": 3.6945392491467576e-05,
      "loss": 0.6595,
      "step": 1300
    },
    {
      "epoch": 0.3839863471521013,
      "grad_norm": 12.029805183410645,
      "learning_rate": 3.83674630261661e-05,
      "loss": 0.6321,
      "step": 1350
    },
    {
      "epoch": 0.3982080637132902,
      "grad_norm": 7.037963390350342,
      "learning_rate": 3.978953356086462e-05,
      "loss": 0.6368,
      "step": 1400
    },
    {
      "epoch": 0.41242978027447913,
      "grad_norm": 3.460862159729004,
      "learning_rate": 4.1211604095563146e-05,
      "loss": 0.6335,
      "step": 1450
    },
    {
      "epoch": 0.42665149683566805,
      "grad_norm": 5.841879367828369,
      "learning_rate": 4.263367463026166e-05,
      "loss": 0.6137,
      "step": 1500
    },
    {
      "epoch": 0.440873213396857,
      "grad_norm": 7.602756023406982,
      "learning_rate": 4.4055745164960184e-05,
      "loss": 0.6183,
      "step": 1550
    },
    {
      "epoch": 0.45509492995804596,
      "grad_norm": 14.186407089233398,
      "learning_rate": 4.54778156996587e-05,
      "loss": 0.5819,
      "step": 1600
    },
    {
      "epoch": 0.4693166465192349,
      "grad_norm": 4.971169948577881,
      "learning_rate": 4.689988623435723e-05,
      "loss": 0.5837,
      "step": 1650
    },
    {
      "epoch": 0.4835383630804238,
      "grad_norm": 4.861956596374512,
      "learning_rate": 4.832195676905575e-05,
      "loss": 0.6011,
      "step": 1700
    },
    {
      "epoch": 0.49776007964161273,
      "grad_norm": 3.373775005340576,
      "learning_rate": 4.974402730375427e-05,
      "loss": 0.5837,
      "step": 1750
    },
    {
      "epoch": 0.5119817962028017,
      "grad_norm": 6.132805824279785,
      "learning_rate": 4.9870433573505246e-05,
      "loss": 0.5731,
      "step": 1800
    },
    {
      "epoch": 0.5262035127639906,
      "grad_norm": 5.172885417938232,
      "learning_rate": 4.971242573631653e-05,
      "loss": 0.5803,
      "step": 1850
    },
    {
      "epoch": 0.5404252293251796,
      "grad_norm": 2.919459581375122,
      "learning_rate": 4.95544178991278e-05,
      "loss": 0.5674,
      "step": 1900
    },
    {
      "epoch": 0.5546469458863685,
      "grad_norm": 7.142757892608643,
      "learning_rate": 4.9396410061939075e-05,
      "loss": 0.5684,
      "step": 1950
    },
    {
      "epoch": 0.5688686624475574,
      "grad_norm": 7.053536415100098,
      "learning_rate": 4.923840222475035e-05,
      "loss": 0.565,
      "step": 2000
    },
    {
      "epoch": 0.5688686624475574,
      "eval_f1_macro": 0.6246862312218523,
      "eval_loss": 0.5518750548362732,
      "eval_runtime": 217.7841,
      "eval_samples_per_second": 918.341,
      "eval_steps_per_second": 7.177,
      "step": 2000
    },
    {
      "epoch": 0.5830903790087464,
      "grad_norm": 3.3853864669799805,
      "learning_rate": 4.908039438756162e-05,
      "loss": 0.5611,
      "step": 2050
    },
    {
      "epoch": 0.5973120955699353,
      "grad_norm": 5.071041107177734,
      "learning_rate": 4.89223865503729e-05,
      "loss": 0.5542,
      "step": 2100
    },
    {
      "epoch": 0.6115338121311242,
      "grad_norm": 4.364541530609131,
      "learning_rate": 4.876437871318418e-05,
      "loss": 0.5572,
      "step": 2150
    },
    {
      "epoch": 0.6257555286923132,
      "grad_norm": 3.2559847831726074,
      "learning_rate": 4.860637087599545e-05,
      "loss": 0.5511,
      "step": 2200
    },
    {
      "epoch": 0.6399772452535021,
      "grad_norm": 4.193438529968262,
      "learning_rate": 4.844836303880673e-05,
      "loss": 0.5532,
      "step": 2250
    },
    {
      "epoch": 0.6541989618146911,
      "grad_norm": 6.20283317565918,
      "learning_rate": 4.8290355201618003e-05,
      "loss": 0.5334,
      "step": 2300
    },
    {
      "epoch": 0.6684206783758799,
      "grad_norm": 2.4448890686035156,
      "learning_rate": 4.813234736442927e-05,
      "loss": 0.5362,
      "step": 2350
    },
    {
      "epoch": 0.6826423949370689,
      "grad_norm": 2.2765865325927734,
      "learning_rate": 4.797433952724055e-05,
      "loss": 0.5351,
      "step": 2400
    },
    {
      "epoch": 0.6968641114982579,
      "grad_norm": 2.612462282180786,
      "learning_rate": 4.781633169005183e-05,
      "loss": 0.5382,
      "step": 2450
    },
    {
      "epoch": 0.7110858280594468,
      "grad_norm": 5.821557998657227,
      "learning_rate": 4.76583238528631e-05,
      "loss": 0.5448,
      "step": 2500
    },
    {
      "epoch": 0.7253075446206357,
      "grad_norm": 6.247180461883545,
      "learning_rate": 4.750031601567438e-05,
      "loss": 0.5367,
      "step": 2550
    },
    {
      "epoch": 0.7395292611818246,
      "grad_norm": 3.9776198863983154,
      "learning_rate": 4.7342308178485655e-05,
      "loss": 0.5259,
      "step": 2600
    },
    {
      "epoch": 0.7537509777430136,
      "grad_norm": 3.212765693664551,
      "learning_rate": 4.718430034129693e-05,
      "loss": 0.5279,
      "step": 2650
    },
    {
      "epoch": 0.7679726943042026,
      "grad_norm": 2.1307942867279053,
      "learning_rate": 4.70262925041082e-05,
      "loss": 0.5129,
      "step": 2700
    },
    {
      "epoch": 0.7821944108653914,
      "grad_norm": 2.2054073810577393,
      "learning_rate": 4.6868284666919485e-05,
      "loss": 0.5167,
      "step": 2750
    },
    {
      "epoch": 0.7964161274265804,
      "grad_norm": 3.423241376876831,
      "learning_rate": 4.671027682973076e-05,
      "loss": 0.5129,
      "step": 2800
    },
    {
      "epoch": 0.8106378439877693,
      "grad_norm": 3.3427906036376953,
      "learning_rate": 4.655226899254203e-05,
      "loss": 0.5234,
      "step": 2850
    },
    {
      "epoch": 0.8248595605489583,
      "grad_norm": 5.018310546875,
      "learning_rate": 4.639426115535331e-05,
      "loss": 0.5225,
      "step": 2900
    },
    {
      "epoch": 0.8390812771101472,
      "grad_norm": 3.1931538581848145,
      "learning_rate": 4.6236253318164584e-05,
      "loss": 0.5143,
      "step": 2950
    },
    {
      "epoch": 0.8533029936713361,
      "grad_norm": 3.5321342945098877,
      "learning_rate": 4.607824548097586e-05,
      "loss": 0.5098,
      "step": 3000
    },
    {
      "epoch": 0.8533029936713361,
      "eval_f1_macro": 0.6747364646618623,
      "eval_loss": 0.5005384087562561,
      "eval_runtime": 217.7067,
      "eval_samples_per_second": 918.667,
      "eval_steps_per_second": 7.179,
      "step": 3000
    },
    {
      "epoch": 0.8675247102325251,
      "grad_norm": 3.572270154953003,
      "learning_rate": 4.5920237643787137e-05,
      "loss": 0.516,
      "step": 3050
    },
    {
      "epoch": 0.881746426793714,
      "grad_norm": 4.108578681945801,
      "learning_rate": 4.576222980659841e-05,
      "loss": 0.505,
      "step": 3100
    },
    {
      "epoch": 0.8959681433549029,
      "grad_norm": 3.0246284008026123,
      "learning_rate": 4.560422196940968e-05,
      "loss": 0.5099,
      "step": 3150
    },
    {
      "epoch": 0.9101898599160919,
      "grad_norm": 3.077254056930542,
      "learning_rate": 4.544621413222096e-05,
      "loss": 0.5284,
      "step": 3200
    },
    {
      "epoch": 0.9244115764772808,
      "grad_norm": 4.015327453613281,
      "learning_rate": 4.5288206295032236e-05,
      "loss": 0.5097,
      "step": 3250
    },
    {
      "epoch": 0.9386332930384698,
      "grad_norm": 3.953294038772583,
      "learning_rate": 4.513019845784351e-05,
      "loss": 0.499,
      "step": 3300
    },
    {
      "epoch": 0.9528550095996586,
      "grad_norm": 3.4417779445648193,
      "learning_rate": 4.497219062065479e-05,
      "loss": 0.4996,
      "step": 3350
    },
    {
      "epoch": 0.9670767261608476,
      "grad_norm": 4.2227959632873535,
      "learning_rate": 4.4814182783466065e-05,
      "loss": 0.5082,
      "step": 3400
    },
    {
      "epoch": 0.9812984427220366,
      "grad_norm": 2.226804733276367,
      "learning_rate": 4.4656174946277335e-05,
      "loss": 0.5117,
      "step": 3450
    },
    {
      "epoch": 0.9955201592832255,
      "grad_norm": 2.277315378189087,
      "learning_rate": 4.449816710908861e-05,
      "loss": 0.488,
      "step": 3500
    },
    {
      "epoch": 1.0096707672616085,
      "grad_norm": 2.408296585083008,
      "learning_rate": 4.434015927189989e-05,
      "loss": 0.4746,
      "step": 3550
    },
    {
      "epoch": 1.0238924838227974,
      "grad_norm": 4.279455184936523,
      "learning_rate": 4.4182151434711164e-05,
      "loss": 0.4762,
      "step": 3600
    },
    {
      "epoch": 1.0381142003839863,
      "grad_norm": 3.322779893875122,
      "learning_rate": 4.402414359752244e-05,
      "loss": 0.4813,
      "step": 3650
    },
    {
      "epoch": 1.0523359169451754,
      "grad_norm": 9.172932624816895,
      "learning_rate": 4.386613576033372e-05,
      "loss": 0.478,
      "step": 3700
    },
    {
      "epoch": 1.0665576335063642,
      "grad_norm": 3.6563737392425537,
      "learning_rate": 4.370812792314499e-05,
      "loss": 0.4723,
      "step": 3750
    },
    {
      "epoch": 1.080779350067553,
      "grad_norm": 1.9683550596237183,
      "learning_rate": 4.355012008595626e-05,
      "loss": 0.4722,
      "step": 3800
    },
    {
      "epoch": 1.0950010666287422,
      "grad_norm": 4.29252290725708,
      "learning_rate": 4.339211224876754e-05,
      "loss": 0.4719,
      "step": 3850
    },
    {
      "epoch": 1.109222783189931,
      "grad_norm": 2.274475574493408,
      "learning_rate": 4.3234104411578816e-05,
      "loss": 0.4714,
      "step": 3900
    },
    {
      "epoch": 1.12344449975112,
      "grad_norm": 3.9285495281219482,
      "learning_rate": 4.307609657439009e-05,
      "loss": 0.4695,
      "step": 3950
    },
    {
      "epoch": 1.1376662163123088,
      "grad_norm": 2.449500560760498,
      "learning_rate": 4.291808873720137e-05,
      "loss": 0.464,
      "step": 4000
    },
    {
      "epoch": 1.1376662163123088,
      "eval_f1_macro": 0.6994450339730967,
      "eval_loss": 0.47442901134490967,
      "eval_runtime": 217.6707,
      "eval_samples_per_second": 918.819,
      "eval_steps_per_second": 7.181,
      "step": 4000
    },
    {
      "epoch": 1.1518879328734979,
      "grad_norm": 2.8096489906311035,
      "learning_rate": 4.2760080900012645e-05,
      "loss": 0.4769,
      "step": 4050
    },
    {
      "epoch": 1.1661096494346868,
      "grad_norm": 2.785937547683716,
      "learning_rate": 4.2602073062823915e-05,
      "loss": 0.473,
      "step": 4100
    },
    {
      "epoch": 1.1803313659958756,
      "grad_norm": 3.828176498413086,
      "learning_rate": 4.244406522563519e-05,
      "loss": 0.4689,
      "step": 4150
    },
    {
      "epoch": 1.1945530825570647,
      "grad_norm": 2.2374792098999023,
      "learning_rate": 4.228605738844647e-05,
      "loss": 0.4677,
      "step": 4200
    },
    {
      "epoch": 1.2087747991182536,
      "grad_norm": 2.224384069442749,
      "learning_rate": 4.2128049551257744e-05,
      "loss": 0.4694,
      "step": 4250
    },
    {
      "epoch": 1.2229965156794425,
      "grad_norm": 1.9722193479537964,
      "learning_rate": 4.197004171406902e-05,
      "loss": 0.4636,
      "step": 4300
    },
    {
      "epoch": 1.2372182322406315,
      "grad_norm": 2.3561549186706543,
      "learning_rate": 4.18120338768803e-05,
      "loss": 0.4683,
      "step": 4350
    },
    {
      "epoch": 1.2514399488018204,
      "grad_norm": 2.8875553607940674,
      "learning_rate": 4.1654026039691567e-05,
      "loss": 0.4621,
      "step": 4400
    },
    {
      "epoch": 1.2656616653630093,
      "grad_norm": 4.434679985046387,
      "learning_rate": 4.149601820250284e-05,
      "loss": 0.4763,
      "step": 4450
    },
    {
      "epoch": 1.2798833819241984,
      "grad_norm": 1.8655694723129272,
      "learning_rate": 4.133801036531412e-05,
      "loss": 0.4685,
      "step": 4500
    },
    {
      "epoch": 1.2941050984853872,
      "grad_norm": 2.7072720527648926,
      "learning_rate": 4.1180002528125396e-05,
      "loss": 0.4509,
      "step": 4550
    },
    {
      "epoch": 1.308326815046576,
      "grad_norm": 2.2312121391296387,
      "learning_rate": 4.102199469093667e-05,
      "loss": 0.4541,
      "step": 4600
    },
    {
      "epoch": 1.322548531607765,
      "grad_norm": 3.1351969242095947,
      "learning_rate": 4.086398685374795e-05,
      "loss": 0.4673,
      "step": 4650
    },
    {
      "epoch": 1.336770248168954,
      "grad_norm": 3.5545263290405273,
      "learning_rate": 4.0705979016559225e-05,
      "loss": 0.4677,
      "step": 4700
    },
    {
      "epoch": 1.350991964730143,
      "grad_norm": 3.0998356342315674,
      "learning_rate": 4.0547971179370495e-05,
      "loss": 0.4622,
      "step": 4750
    },
    {
      "epoch": 1.3652136812913318,
      "grad_norm": 2.038752317428589,
      "learning_rate": 4.038996334218177e-05,
      "loss": 0.4579,
      "step": 4800
    },
    {
      "epoch": 1.3794353978525207,
      "grad_norm": 5.6229634284973145,
      "learning_rate": 4.0231955504993055e-05,
      "loss": 0.4579,
      "step": 4850
    },
    {
      "epoch": 1.3936571144137098,
      "grad_norm": 3.3512325286865234,
      "learning_rate": 4.0073947667804324e-05,
      "loss": 0.4592,
      "step": 4900
    },
    {
      "epoch": 1.4078788309748986,
      "grad_norm": 3.3985776901245117,
      "learning_rate": 3.99159398306156e-05,
      "loss": 0.4551,
      "step": 4950
    },
    {
      "epoch": 1.4221005475360875,
      "grad_norm": 2.2053678035736084,
      "learning_rate": 3.975793199342688e-05,
      "loss": 0.4543,
      "step": 5000
    },
    {
      "epoch": 1.4221005475360875,
      "eval_f1_macro": 0.6981820753268548,
      "eval_loss": 0.46926456689834595,
      "eval_runtime": 217.8467,
      "eval_samples_per_second": 918.077,
      "eval_steps_per_second": 7.175,
      "step": 5000
    },
    {
      "epoch": 1.4363222640972766,
      "grad_norm": 3.611823797225952,
      "learning_rate": 3.959992415623815e-05,
      "loss": 0.4713,
      "step": 5050
    },
    {
      "epoch": 1.4505439806584655,
      "grad_norm": 4.487391471862793,
      "learning_rate": 3.944191631904943e-05,
      "loss": 0.455,
      "step": 5100
    },
    {
      "epoch": 1.4647656972196543,
      "grad_norm": 2.817826986312866,
      "learning_rate": 3.9283908481860706e-05,
      "loss": 0.4603,
      "step": 5150
    },
    {
      "epoch": 1.4789874137808434,
      "grad_norm": 3.2785918712615967,
      "learning_rate": 3.9125900644671976e-05,
      "loss": 0.4665,
      "step": 5200
    },
    {
      "epoch": 1.4932091303420323,
      "grad_norm": 4.054325103759766,
      "learning_rate": 3.896789280748325e-05,
      "loss": 0.4586,
      "step": 5250
    },
    {
      "epoch": 1.5074308469032212,
      "grad_norm": 2.6432149410247803,
      "learning_rate": 3.880988497029453e-05,
      "loss": 0.4596,
      "step": 5300
    },
    {
      "epoch": 1.5216525634644102,
      "grad_norm": 1.253118634223938,
      "learning_rate": 3.86518771331058e-05,
      "loss": 0.446,
      "step": 5350
    },
    {
      "epoch": 1.5358742800255991,
      "grad_norm": 2.8269336223602295,
      "learning_rate": 3.849386929591708e-05,
      "loss": 0.4602,
      "step": 5400
    },
    {
      "epoch": 1.550095996586788,
      "grad_norm": 3.7779929637908936,
      "learning_rate": 3.833586145872836e-05,
      "loss": 0.442,
      "step": 5450
    },
    {
      "epoch": 1.564317713147977,
      "grad_norm": 2.6657025814056396,
      "learning_rate": 3.817785362153963e-05,
      "loss": 0.4489,
      "step": 5500
    },
    {
      "epoch": 1.578539429709166,
      "grad_norm": 2.120091438293457,
      "learning_rate": 3.8019845784350904e-05,
      "loss": 0.4485,
      "step": 5550
    },
    {
      "epoch": 1.5927611462703548,
      "grad_norm": 3.2975289821624756,
      "learning_rate": 3.786183794716218e-05,
      "loss": 0.4457,
      "step": 5600
    },
    {
      "epoch": 1.606982862831544,
      "grad_norm": 3.8551695346832275,
      "learning_rate": 3.770383010997346e-05,
      "loss": 0.4424,
      "step": 5650
    },
    {
      "epoch": 1.6212045793927325,
      "grad_norm": 1.8866050243377686,
      "learning_rate": 3.7545822272784734e-05,
      "loss": 0.4615,
      "step": 5700
    },
    {
      "epoch": 1.6354262959539216,
      "grad_norm": 1.8557040691375732,
      "learning_rate": 3.738781443559601e-05,
      "loss": 0.4491,
      "step": 5750
    },
    {
      "epoch": 1.6496480125151107,
      "grad_norm": 2.2152695655822754,
      "learning_rate": 3.722980659840729e-05,
      "loss": 0.4539,
      "step": 5800
    },
    {
      "epoch": 1.6638697290762994,
      "grad_norm": 2.204071283340454,
      "learning_rate": 3.7071798761218556e-05,
      "loss": 0.4443,
      "step": 5850
    },
    {
      "epoch": 1.6780914456374885,
      "grad_norm": 3.7650485038757324,
      "learning_rate": 3.691379092402983e-05,
      "loss": 0.4388,
      "step": 5900
    },
    {
      "epoch": 1.6923131621986773,
      "grad_norm": 2.3453757762908936,
      "learning_rate": 3.675578308684111e-05,
      "loss": 0.4487,
      "step": 5950
    },
    {
      "epoch": 1.7065348787598662,
      "grad_norm": 2.706528425216675,
      "learning_rate": 3.6597775249652386e-05,
      "loss": 0.4451,
      "step": 6000
    },
    {
      "epoch": 1.7065348787598662,
      "eval_f1_macro": 0.7122213064196582,
      "eval_loss": 0.45071491599082947,
      "eval_runtime": 217.7459,
      "eval_samples_per_second": 918.502,
      "eval_steps_per_second": 7.178,
      "step": 6000
    },
    {
      "epoch": 1.7207565953210553,
      "grad_norm": 2.0503010749816895,
      "learning_rate": 3.643976741246366e-05,
      "loss": 0.4469,
      "step": 6050
    },
    {
      "epoch": 1.7349783118822442,
      "grad_norm": 4.673399925231934,
      "learning_rate": 3.628175957527494e-05,
      "loss": 0.443,
      "step": 6100
    },
    {
      "epoch": 1.749200028443433,
      "grad_norm": 2.156498908996582,
      "learning_rate": 3.612375173808621e-05,
      "loss": 0.4444,
      "step": 6150
    },
    {
      "epoch": 1.7634217450046221,
      "grad_norm": 3.8739216327667236,
      "learning_rate": 3.5965743900897485e-05,
      "loss": 0.4395,
      "step": 6200
    },
    {
      "epoch": 1.777643461565811,
      "grad_norm": 2.8578333854675293,
      "learning_rate": 3.580773606370876e-05,
      "loss": 0.4476,
      "step": 6250
    },
    {
      "epoch": 1.7918651781269999,
      "grad_norm": 2.4437472820281982,
      "learning_rate": 3.564972822652004e-05,
      "loss": 0.4537,
      "step": 6300
    },
    {
      "epoch": 1.806086894688189,
      "grad_norm": 2.528301954269409,
      "learning_rate": 3.5491720389331314e-05,
      "loss": 0.4448,
      "step": 6350
    },
    {
      "epoch": 1.8203086112493778,
      "grad_norm": 3.700038194656372,
      "learning_rate": 3.533371255214259e-05,
      "loss": 0.4498,
      "step": 6400
    },
    {
      "epoch": 1.8345303278105667,
      "grad_norm": 3.160607099533081,
      "learning_rate": 3.517570471495386e-05,
      "loss": 0.4362,
      "step": 6450
    },
    {
      "epoch": 1.8487520443717558,
      "grad_norm": 2.1345937252044678,
      "learning_rate": 3.5017696877765136e-05,
      "loss": 0.4346,
      "step": 6500
    },
    {
      "epoch": 1.8629737609329446,
      "grad_norm": 3.4931111335754395,
      "learning_rate": 3.485968904057641e-05,
      "loss": 0.437,
      "step": 6550
    },
    {
      "epoch": 1.8771954774941335,
      "grad_norm": 3.3142783641815186,
      "learning_rate": 3.470168120338769e-05,
      "loss": 0.4405,
      "step": 6600
    },
    {
      "epoch": 1.8914171940553226,
      "grad_norm": 2.176537036895752,
      "learning_rate": 3.4543673366198966e-05,
      "loss": 0.432,
      "step": 6650
    },
    {
      "epoch": 1.9056389106165113,
      "grad_norm": 1.9922327995300293,
      "learning_rate": 3.438566552901024e-05,
      "loss": 0.4442,
      "step": 6700
    },
    {
      "epoch": 1.9198606271777003,
      "grad_norm": 2.230361223220825,
      "learning_rate": 3.422765769182152e-05,
      "loss": 0.4403,
      "step": 6750
    },
    {
      "epoch": 1.9340823437388894,
      "grad_norm": 3.55780291557312,
      "learning_rate": 3.406964985463279e-05,
      "loss": 0.4376,
      "step": 6800
    },
    {
      "epoch": 1.948304060300078,
      "grad_norm": 2.907254934310913,
      "learning_rate": 3.3911642017444065e-05,
      "loss": 0.4448,
      "step": 6850
    },
    {
      "epoch": 1.9625257768612672,
      "grad_norm": 4.8038330078125,
      "learning_rate": 3.375363418025535e-05,
      "loss": 0.4364,
      "step": 6900
    },
    {
      "epoch": 1.976747493422456,
      "grad_norm": 2.345228433609009,
      "learning_rate": 3.359562634306662e-05,
      "loss": 0.4154,
      "step": 6950
    },
    {
      "epoch": 1.990969209983645,
      "grad_norm": 2.3504860401153564,
      "learning_rate": 3.3437618505877894e-05,
      "loss": 0.4357,
      "step": 7000
    },
    {
      "epoch": 1.990969209983645,
      "eval_f1_macro": 0.7050252825376807,
      "eval_loss": 0.43641579151153564,
      "eval_runtime": 217.7502,
      "eval_samples_per_second": 918.484,
      "eval_steps_per_second": 7.178,
      "step": 7000
    },
    {
      "epoch": 2.005119817962028,
      "grad_norm": 3.0673487186431885,
      "learning_rate": 3.327961066868917e-05,
      "loss": 0.4271,
      "step": 7050
    },
    {
      "epoch": 2.019341534523217,
      "grad_norm": 2.259624481201172,
      "learning_rate": 3.312160283150044e-05,
      "loss": 0.3957,
      "step": 7100
    },
    {
      "epoch": 2.0335632510844057,
      "grad_norm": 5.253225326538086,
      "learning_rate": 3.296359499431172e-05,
      "loss": 0.3978,
      "step": 7150
    },
    {
      "epoch": 2.047784967645595,
      "grad_norm": 4.8005547523498535,
      "learning_rate": 3.2805587157123e-05,
      "loss": 0.4027,
      "step": 7200
    },
    {
      "epoch": 2.062006684206784,
      "grad_norm": 3.033036470413208,
      "learning_rate": 3.264757931993427e-05,
      "loss": 0.4036,
      "step": 7250
    },
    {
      "epoch": 2.0762284007679725,
      "grad_norm": 3.8097662925720215,
      "learning_rate": 3.2489571482745546e-05,
      "loss": 0.406,
      "step": 7300
    },
    {
      "epoch": 2.0904501173291616,
      "grad_norm": 3.9849042892456055,
      "learning_rate": 3.233156364555682e-05,
      "loss": 0.4013,
      "step": 7350
    },
    {
      "epoch": 2.1046718338903507,
      "grad_norm": 2.644815683364868,
      "learning_rate": 3.217355580836809e-05,
      "loss": 0.3966,
      "step": 7400
    },
    {
      "epoch": 2.1188935504515394,
      "grad_norm": 2.712855577468872,
      "learning_rate": 3.201554797117937e-05,
      "loss": 0.3955,
      "step": 7450
    },
    {
      "epoch": 2.1331152670127285,
      "grad_norm": 3.8808281421661377,
      "learning_rate": 3.185754013399065e-05,
      "loss": 0.4106,
      "step": 7500
    },
    {
      "epoch": 2.1473369835739176,
      "grad_norm": 2.6882216930389404,
      "learning_rate": 3.169953229680192e-05,
      "loss": 0.4049,
      "step": 7550
    },
    {
      "epoch": 2.161558700135106,
      "grad_norm": 2.1347410678863525,
      "learning_rate": 3.15415244596132e-05,
      "loss": 0.4003,
      "step": 7600
    },
    {
      "epoch": 2.1757804166962953,
      "grad_norm": 2.954904317855835,
      "learning_rate": 3.1383516622424474e-05,
      "loss": 0.4021,
      "step": 7650
    },
    {
      "epoch": 2.1900021332574844,
      "grad_norm": 1.849124550819397,
      "learning_rate": 3.122550878523575e-05,
      "loss": 0.3963,
      "step": 7700
    },
    {
      "epoch": 2.204223849818673,
      "grad_norm": 3.8001790046691895,
      "learning_rate": 3.106750094804702e-05,
      "loss": 0.4046,
      "step": 7750
    },
    {
      "epoch": 2.218445566379862,
      "grad_norm": 3.225342273712158,
      "learning_rate": 3.0909493110858304e-05,
      "loss": 0.4065,
      "step": 7800
    },
    {
      "epoch": 2.232667282941051,
      "grad_norm": 3.7164394855499268,
      "learning_rate": 3.075148527366958e-05,
      "loss": 0.4171,
      "step": 7850
    },
    {
      "epoch": 2.24688899950224,
      "grad_norm": 2.7809791564941406,
      "learning_rate": 3.059347743648085e-05,
      "loss": 0.4018,
      "step": 7900
    },
    {
      "epoch": 2.261110716063429,
      "grad_norm": 3.082474708557129,
      "learning_rate": 3.0435469599292126e-05,
      "loss": 0.3927,
      "step": 7950
    },
    {
      "epoch": 2.2753324326246176,
      "grad_norm": 3.424501419067383,
      "learning_rate": 3.0277461762103403e-05,
      "loss": 0.4107,
      "step": 8000
    },
    {
      "epoch": 2.2753324326246176,
      "eval_f1_macro": 0.7266560279220606,
      "eval_loss": 0.4359687566757202,
      "eval_runtime": 217.7702,
      "eval_samples_per_second": 918.399,
      "eval_steps_per_second": 7.177,
      "step": 8000
    },
    {
      "epoch": 2.2895541491858067,
      "grad_norm": 2.5529625415802,
      "learning_rate": 3.0119453924914676e-05,
      "loss": 0.4036,
      "step": 8050
    },
    {
      "epoch": 2.3037758657469958,
      "grad_norm": 3.533071994781494,
      "learning_rate": 2.9961446087725952e-05,
      "loss": 0.3886,
      "step": 8100
    },
    {
      "epoch": 2.3179975823081844,
      "grad_norm": 1.746243953704834,
      "learning_rate": 2.980343825053723e-05,
      "loss": 0.3904,
      "step": 8150
    },
    {
      "epoch": 2.3322192988693735,
      "grad_norm": 3.6127419471740723,
      "learning_rate": 2.96454304133485e-05,
      "loss": 0.3999,
      "step": 8200
    },
    {
      "epoch": 2.3464410154305626,
      "grad_norm": 3.2908735275268555,
      "learning_rate": 2.9487422576159778e-05,
      "loss": 0.3898,
      "step": 8250
    },
    {
      "epoch": 2.3606627319917513,
      "grad_norm": 2.258908748626709,
      "learning_rate": 2.9329414738971054e-05,
      "loss": 0.3945,
      "step": 8300
    },
    {
      "epoch": 2.3748844485529403,
      "grad_norm": 1.8462496995925903,
      "learning_rate": 2.9171406901782328e-05,
      "loss": 0.3959,
      "step": 8350
    },
    {
      "epoch": 2.3891061651141294,
      "grad_norm": 3.9153025150299072,
      "learning_rate": 2.9013399064593604e-05,
      "loss": 0.3959,
      "step": 8400
    },
    {
      "epoch": 2.403327881675318,
      "grad_norm": 4.309543609619141,
      "learning_rate": 2.885539122740488e-05,
      "loss": 0.4018,
      "step": 8450
    },
    {
      "epoch": 2.417549598236507,
      "grad_norm": 2.863239049911499,
      "learning_rate": 2.8697383390216153e-05,
      "loss": 0.3955,
      "step": 8500
    },
    {
      "epoch": 2.4317713147976963,
      "grad_norm": 2.7571182250976562,
      "learning_rate": 2.853937555302743e-05,
      "loss": 0.3993,
      "step": 8550
    },
    {
      "epoch": 2.445993031358885,
      "grad_norm": 3.254640817642212,
      "learning_rate": 2.838136771583871e-05,
      "loss": 0.3961,
      "step": 8600
    },
    {
      "epoch": 2.460214747920074,
      "grad_norm": 1.7465347051620483,
      "learning_rate": 2.822335987864998e-05,
      "loss": 0.3888,
      "step": 8650
    },
    {
      "epoch": 2.474436464481263,
      "grad_norm": 2.2688732147216797,
      "learning_rate": 2.8065352041461256e-05,
      "loss": 0.3952,
      "step": 8700
    },
    {
      "epoch": 2.4886581810424517,
      "grad_norm": 2.9353315830230713,
      "learning_rate": 2.7907344204272536e-05,
      "loss": 0.3875,
      "step": 8750
    },
    {
      "epoch": 2.502879897603641,
      "grad_norm": 3.471059799194336,
      "learning_rate": 2.7749336367083812e-05,
      "loss": 0.3988,
      "step": 8800
    },
    {
      "epoch": 2.5171016141648295,
      "grad_norm": 2.076113700866699,
      "learning_rate": 2.7591328529895082e-05,
      "loss": 0.3971,
      "step": 8850
    },
    {
      "epoch": 2.5313233307260186,
      "grad_norm": 2.2607030868530273,
      "learning_rate": 2.743332069270636e-05,
      "loss": 0.3991,
      "step": 8900
    },
    {
      "epoch": 2.5455450472872077,
      "grad_norm": 2.786007881164551,
      "learning_rate": 2.7275312855517638e-05,
      "loss": 0.4044,
      "step": 8950
    },
    {
      "epoch": 2.5597667638483967,
      "grad_norm": 2.2129552364349365,
      "learning_rate": 2.7117305018328908e-05,
      "loss": 0.3829,
      "step": 9000
    },
    {
      "epoch": 2.5597667638483967,
      "eval_f1_macro": 0.729848919497831,
      "eval_loss": 0.43484586477279663,
      "eval_runtime": 217.6321,
      "eval_samples_per_second": 918.982,
      "eval_steps_per_second": 7.182,
      "step": 9000
    },
    {
      "epoch": 2.5739884804095854,
      "grad_norm": 3.4721500873565674,
      "learning_rate": 2.6959297181140188e-05,
      "loss": 0.3905,
      "step": 9050
    },
    {
      "epoch": 2.5882101969707745,
      "grad_norm": 2.771880865097046,
      "learning_rate": 2.6801289343951464e-05,
      "loss": 0.4067,
      "step": 9100
    },
    {
      "epoch": 2.602431913531963,
      "grad_norm": 3.363785982131958,
      "learning_rate": 2.6643281506762734e-05,
      "loss": 0.3948,
      "step": 9150
    },
    {
      "epoch": 2.616653630093152,
      "grad_norm": 2.708627462387085,
      "learning_rate": 2.6485273669574013e-05,
      "loss": 0.4086,
      "step": 9200
    },
    {
      "epoch": 2.6308753466543413,
      "grad_norm": 3.2734603881835938,
      "learning_rate": 2.632726583238529e-05,
      "loss": 0.4161,
      "step": 9250
    },
    {
      "epoch": 2.64509706321553,
      "grad_norm": 3.0122554302215576,
      "learning_rate": 2.616925799519656e-05,
      "loss": 0.402,
      "step": 9300
    },
    {
      "epoch": 2.659318779776719,
      "grad_norm": 3.4353907108306885,
      "learning_rate": 2.601125015800784e-05,
      "loss": 0.3966,
      "step": 9350
    },
    {
      "epoch": 2.673540496337908,
      "grad_norm": 2.8296940326690674,
      "learning_rate": 2.5853242320819116e-05,
      "loss": 0.3866,
      "step": 9400
    },
    {
      "epoch": 2.687762212899097,
      "grad_norm": 5.175149917602539,
      "learning_rate": 2.5695234483630386e-05,
      "loss": 0.39,
      "step": 9450
    },
    {
      "epoch": 2.701983929460286,
      "grad_norm": 2.696613073348999,
      "learning_rate": 2.5537226646441665e-05,
      "loss": 0.3974,
      "step": 9500
    },
    {
      "epoch": 2.716205646021475,
      "grad_norm": 3.095259428024292,
      "learning_rate": 2.5379218809252942e-05,
      "loss": 0.3816,
      "step": 9550
    },
    {
      "epoch": 2.7304273625826636,
      "grad_norm": 2.55179500579834,
      "learning_rate": 2.522121097206421e-05,
      "loss": 0.3933,
      "step": 9600
    },
    {
      "epoch": 2.7446490791438527,
      "grad_norm": 2.8990979194641113,
      "learning_rate": 2.506320313487549e-05,
      "loss": 0.3979,
      "step": 9650
    },
    {
      "epoch": 2.7588707957050413,
      "grad_norm": 2.5196619033813477,
      "learning_rate": 2.4905195297686768e-05,
      "loss": 0.384,
      "step": 9700
    },
    {
      "epoch": 2.7730925122662304,
      "grad_norm": 2.7591238021850586,
      "learning_rate": 2.474718746049804e-05,
      "loss": 0.398,
      "step": 9750
    },
    {
      "epoch": 2.7873142288274195,
      "grad_norm": 2.267770528793335,
      "learning_rate": 2.4589179623309317e-05,
      "loss": 0.389,
      "step": 9800
    },
    {
      "epoch": 2.8015359453886086,
      "grad_norm": 2.3014869689941406,
      "learning_rate": 2.4431171786120594e-05,
      "loss": 0.3954,
      "step": 9850
    },
    {
      "epoch": 2.8157576619497973,
      "grad_norm": 1.9061205387115479,
      "learning_rate": 2.4273163948931867e-05,
      "loss": 0.3887,
      "step": 9900
    },
    {
      "epoch": 2.8299793785109864,
      "grad_norm": 2.9336724281311035,
      "learning_rate": 2.4115156111743143e-05,
      "loss": 0.4041,
      "step": 9950
    },
    {
      "epoch": 2.844201095072175,
      "grad_norm": 3.3048062324523926,
      "learning_rate": 2.395714827455442e-05,
      "loss": 0.3879,
      "step": 10000
    },
    {
      "epoch": 2.844201095072175,
      "eval_f1_macro": 0.7297752040149736,
      "eval_loss": 0.42296290397644043,
      "eval_runtime": 217.8757,
      "eval_samples_per_second": 917.954,
      "eval_steps_per_second": 7.174,
      "step": 10000
    },
    {
      "epoch": 2.858422811633364,
      "grad_norm": 5.537769794464111,
      "learning_rate": 2.3799140437365693e-05,
      "loss": 0.3991,
      "step": 10050
    },
    {
      "epoch": 2.872644528194553,
      "grad_norm": 2.889890670776367,
      "learning_rate": 2.3641132600176972e-05,
      "loss": 0.4063,
      "step": 10100
    },
    {
      "epoch": 2.8868662447557423,
      "grad_norm": 2.4932751655578613,
      "learning_rate": 2.3483124762988246e-05,
      "loss": 0.3842,
      "step": 10150
    },
    {
      "epoch": 2.901087961316931,
      "grad_norm": 2.507049560546875,
      "learning_rate": 2.332511692579952e-05,
      "loss": 0.3927,
      "step": 10200
    },
    {
      "epoch": 2.91530967787812,
      "grad_norm": 3.4117789268493652,
      "learning_rate": 2.31671090886108e-05,
      "loss": 0.388,
      "step": 10250
    },
    {
      "epoch": 2.9295313944393087,
      "grad_norm": 3.7186148166656494,
      "learning_rate": 2.300910125142207e-05,
      "loss": 0.3895,
      "step": 10300
    },
    {
      "epoch": 2.9437531110004977,
      "grad_norm": 2.8538806438446045,
      "learning_rate": 2.2851093414233345e-05,
      "loss": 0.3966,
      "step": 10350
    },
    {
      "epoch": 2.957974827561687,
      "grad_norm": 3.7867493629455566,
      "learning_rate": 2.2693085577044624e-05,
      "loss": 0.3824,
      "step": 10400
    },
    {
      "epoch": 2.9721965441228755,
      "grad_norm": 1.8734040260314941,
      "learning_rate": 2.2535077739855897e-05,
      "loss": 0.3825,
      "step": 10450
    },
    {
      "epoch": 2.9864182606840646,
      "grad_norm": 3.9216339588165283,
      "learning_rate": 2.237706990266717e-05,
      "loss": 0.3836,
      "step": 10500
    },
    {
      "epoch": 3.0005688686624477,
      "grad_norm": 1.7975070476531982,
      "learning_rate": 2.221906206547845e-05,
      "loss": 0.393,
      "step": 10550
    },
    {
      "epoch": 3.0147905852236363,
      "grad_norm": 2.179159164428711,
      "learning_rate": 2.2061054228289723e-05,
      "loss": 0.356,
      "step": 10600
    },
    {
      "epoch": 3.0290123017848254,
      "grad_norm": 3.74552059173584,
      "learning_rate": 2.1903046391101e-05,
      "loss": 0.349,
      "step": 10650
    },
    {
      "epoch": 3.0432340183460145,
      "grad_norm": 2.994903564453125,
      "learning_rate": 2.1745038553912276e-05,
      "loss": 0.3578,
      "step": 10700
    },
    {
      "epoch": 3.057455734907203,
      "grad_norm": 3.2505133152008057,
      "learning_rate": 2.158703071672355e-05,
      "loss": 0.3578,
      "step": 10750
    },
    {
      "epoch": 3.071677451468392,
      "grad_norm": 3.1789047718048096,
      "learning_rate": 2.1429022879534826e-05,
      "loss": 0.3546,
      "step": 10800
    },
    {
      "epoch": 3.0858991680295813,
      "grad_norm": 3.4664907455444336,
      "learning_rate": 2.1271015042346102e-05,
      "loss": 0.3575,
      "step": 10850
    },
    {
      "epoch": 3.10012088459077,
      "grad_norm": 3.64560866355896,
      "learning_rate": 2.1113007205157375e-05,
      "loss": 0.3595,
      "step": 10900
    },
    {
      "epoch": 3.114342601151959,
      "grad_norm": 2.274756908416748,
      "learning_rate": 2.095499936796865e-05,
      "loss": 0.3476,
      "step": 10950
    },
    {
      "epoch": 3.128564317713148,
      "grad_norm": 3.801558494567871,
      "learning_rate": 2.0796991530779928e-05,
      "loss": 0.3471,
      "step": 11000
    },
    {
      "epoch": 3.128564317713148,
      "eval_f1_macro": 0.7344440601724769,
      "eval_loss": 0.42699792981147766,
      "eval_runtime": 217.85,
      "eval_samples_per_second": 918.063,
      "eval_steps_per_second": 7.175,
      "step": 11000
    },
    {
      "epoch": 3.142786034274337,
      "grad_norm": 3.6276047229766846,
      "learning_rate": 2.06389836935912e-05,
      "loss": 0.3615,
      "step": 11050
    },
    {
      "epoch": 3.157007750835526,
      "grad_norm": 6.961971759796143,
      "learning_rate": 2.0480975856402478e-05,
      "loss": 0.3665,
      "step": 11100
    },
    {
      "epoch": 3.171229467396715,
      "grad_norm": 4.117957592010498,
      "learning_rate": 2.0322968019213754e-05,
      "loss": 0.3512,
      "step": 11150
    },
    {
      "epoch": 3.1854511839579036,
      "grad_norm": 1.8868896961212158,
      "learning_rate": 2.016496018202503e-05,
      "loss": 0.3607,
      "step": 11200
    },
    {
      "epoch": 3.1996729005190927,
      "grad_norm": 4.213456153869629,
      "learning_rate": 2.0006952344836304e-05,
      "loss": 0.3593,
      "step": 11250
    },
    {
      "epoch": 3.213894617080282,
      "grad_norm": 2.3972461223602295,
      "learning_rate": 1.984894450764758e-05,
      "loss": 0.361,
      "step": 11300
    },
    {
      "epoch": 3.2281163336414704,
      "grad_norm": 3.0621540546417236,
      "learning_rate": 1.9690936670458856e-05,
      "loss": 0.3468,
      "step": 11350
    },
    {
      "epoch": 3.2423380502026595,
      "grad_norm": 3.204841136932373,
      "learning_rate": 1.953292883327013e-05,
      "loss": 0.3532,
      "step": 11400
    },
    {
      "epoch": 3.256559766763848,
      "grad_norm": 2.6192538738250732,
      "learning_rate": 1.9374920996081406e-05,
      "loss": 0.3425,
      "step": 11450
    },
    {
      "epoch": 3.2707814833250373,
      "grad_norm": 2.6068649291992188,
      "learning_rate": 1.9216913158892682e-05,
      "loss": 0.3455,
      "step": 11500
    },
    {
      "epoch": 3.2850031998862264,
      "grad_norm": 3.1839406490325928,
      "learning_rate": 1.9058905321703955e-05,
      "loss": 0.3548,
      "step": 11550
    },
    {
      "epoch": 3.2992249164474154,
      "grad_norm": 3.257725477218628,
      "learning_rate": 1.8900897484515235e-05,
      "loss": 0.358,
      "step": 11600
    },
    {
      "epoch": 3.313446633008604,
      "grad_norm": 2.1040990352630615,
      "learning_rate": 1.8742889647326508e-05,
      "loss": 0.3544,
      "step": 11650
    },
    {
      "epoch": 3.327668349569793,
      "grad_norm": 2.3803939819335938,
      "learning_rate": 1.8584881810137785e-05,
      "loss": 0.3469,
      "step": 11700
    },
    {
      "epoch": 3.341890066130982,
      "grad_norm": 2.214477062225342,
      "learning_rate": 1.842687397294906e-05,
      "loss": 0.3496,
      "step": 11750
    },
    {
      "epoch": 3.356111782692171,
      "grad_norm": 2.691689968109131,
      "learning_rate": 1.8268866135760334e-05,
      "loss": 0.3521,
      "step": 11800
    },
    {
      "epoch": 3.37033349925336,
      "grad_norm": 4.742248058319092,
      "learning_rate": 1.811085829857161e-05,
      "loss": 0.3476,
      "step": 11850
    },
    {
      "epoch": 3.3845552158145487,
      "grad_norm": 1.8185182809829712,
      "learning_rate": 1.7952850461382887e-05,
      "loss": 0.3573,
      "step": 11900
    },
    {
      "epoch": 3.3987769323757377,
      "grad_norm": 2.871880531311035,
      "learning_rate": 1.779484262419416e-05,
      "loss": 0.347,
      "step": 11950
    },
    {
      "epoch": 3.412998648936927,
      "grad_norm": 2.780319929122925,
      "learning_rate": 1.7636834787005437e-05,
      "loss": 0.3569,
      "step": 12000
    },
    {
      "epoch": 3.412998648936927,
      "eval_f1_macro": 0.733367745573622,
      "eval_loss": 0.42388585209846497,
      "eval_runtime": 217.8186,
      "eval_samples_per_second": 918.195,
      "eval_steps_per_second": 7.176,
      "step": 12000
    },
    {
      "epoch": 3.4272203654981155,
      "grad_norm": 2.8057546615600586,
      "learning_rate": 1.7478826949816713e-05,
      "loss": 0.3519,
      "step": 12050
    },
    {
      "epoch": 3.4414420820593046,
      "grad_norm": 2.6182119846343994,
      "learning_rate": 1.7320819112627986e-05,
      "loss": 0.3607,
      "step": 12100
    },
    {
      "epoch": 3.4556637986204937,
      "grad_norm": 3.0986571311950684,
      "learning_rate": 1.7162811275439263e-05,
      "loss": 0.347,
      "step": 12150
    },
    {
      "epoch": 3.4698855151816823,
      "grad_norm": 2.423046112060547,
      "learning_rate": 1.700480343825054e-05,
      "loss": 0.3427,
      "step": 12200
    },
    {
      "epoch": 3.4841072317428714,
      "grad_norm": 3.12381649017334,
      "learning_rate": 1.6846795601061812e-05,
      "loss": 0.3498,
      "step": 12250
    },
    {
      "epoch": 3.4983289483040605,
      "grad_norm": 3.383586883544922,
      "learning_rate": 1.668878776387309e-05,
      "loss": 0.3628,
      "step": 12300
    },
    {
      "epoch": 3.512550664865249,
      "grad_norm": 4.930322170257568,
      "learning_rate": 1.6530779926684365e-05,
      "loss": 0.3435,
      "step": 12350
    },
    {
      "epoch": 3.5267723814264382,
      "grad_norm": 4.101044178009033,
      "learning_rate": 1.6372772089495638e-05,
      "loss": 0.3503,
      "step": 12400
    },
    {
      "epoch": 3.5409940979876273,
      "grad_norm": 2.5030605792999268,
      "learning_rate": 1.6214764252306914e-05,
      "loss": 0.3464,
      "step": 12450
    },
    {
      "epoch": 3.555215814548816,
      "grad_norm": 4.084738731384277,
      "learning_rate": 1.605675641511819e-05,
      "loss": 0.3546,
      "step": 12500
    },
    {
      "epoch": 3.569437531110005,
      "grad_norm": 2.9014086723327637,
      "learning_rate": 1.5898748577929464e-05,
      "loss": 0.3481,
      "step": 12550
    },
    {
      "epoch": 3.5836592476711937,
      "grad_norm": 2.260066032409668,
      "learning_rate": 1.574074074074074e-05,
      "loss": 0.3454,
      "step": 12600
    },
    {
      "epoch": 3.597880964232383,
      "grad_norm": 2.7753217220306396,
      "learning_rate": 1.5582732903552017e-05,
      "loss": 0.3666,
      "step": 12650
    },
    {
      "epoch": 3.612102680793572,
      "grad_norm": 2.8645718097686768,
      "learning_rate": 1.5424725066363293e-05,
      "loss": 0.3527,
      "step": 12700
    },
    {
      "epoch": 3.626324397354761,
      "grad_norm": 2.311333656311035,
      "learning_rate": 1.526671722917457e-05,
      "loss": 0.3494,
      "step": 12750
    },
    {
      "epoch": 3.6405461139159496,
      "grad_norm": 4.267210483551025,
      "learning_rate": 1.5108709391985843e-05,
      "loss": 0.3511,
      "step": 12800
    },
    {
      "epoch": 3.6547678304771387,
      "grad_norm": 3.21209716796875,
      "learning_rate": 1.495070155479712e-05,
      "loss": 0.3493,
      "step": 12850
    },
    {
      "epoch": 3.6689895470383274,
      "grad_norm": 3.7145509719848633,
      "learning_rate": 1.4792693717608394e-05,
      "loss": 0.3485,
      "step": 12900
    },
    {
      "epoch": 3.6832112635995164,
      "grad_norm": 2.750441551208496,
      "learning_rate": 1.4634685880419669e-05,
      "loss": 0.3462,
      "step": 12950
    },
    {
      "epoch": 3.6974329801607055,
      "grad_norm": 1.9281073808670044,
      "learning_rate": 1.4476678043230945e-05,
      "loss": 0.3403,
      "step": 13000
    },
    {
      "epoch": 3.6974329801607055,
      "eval_f1_macro": 0.7376792157992025,
      "eval_loss": 0.4283038377761841,
      "eval_runtime": 217.7531,
      "eval_samples_per_second": 918.472,
      "eval_steps_per_second": 7.178,
      "step": 13000
    },
    {
      "epoch": 3.711654696721894,
      "grad_norm": 2.043513059616089,
      "learning_rate": 1.431867020604222e-05,
      "loss": 0.36,
      "step": 13050
    },
    {
      "epoch": 3.7258764132830833,
      "grad_norm": 2.66221022605896,
      "learning_rate": 1.4160662368853495e-05,
      "loss": 0.3424,
      "step": 13100
    },
    {
      "epoch": 3.7400981298442724,
      "grad_norm": 1.9298269748687744,
      "learning_rate": 1.4002654531664771e-05,
      "loss": 0.3471,
      "step": 13150
    },
    {
      "epoch": 3.754319846405461,
      "grad_norm": 3.1351072788238525,
      "learning_rate": 1.3844646694476046e-05,
      "loss": 0.3434,
      "step": 13200
    },
    {
      "epoch": 3.76854156296665,
      "grad_norm": 2.6597073078155518,
      "learning_rate": 1.3686638857287324e-05,
      "loss": 0.3536,
      "step": 13250
    },
    {
      "epoch": 3.782763279527839,
      "grad_norm": 2.914156436920166,
      "learning_rate": 1.3528631020098597e-05,
      "loss": 0.3462,
      "step": 13300
    },
    {
      "epoch": 3.796984996089028,
      "grad_norm": 1.7852338552474976,
      "learning_rate": 1.3370623182909872e-05,
      "loss": 0.3363,
      "step": 13350
    },
    {
      "epoch": 3.811206712650217,
      "grad_norm": 2.1629936695098877,
      "learning_rate": 1.321261534572115e-05,
      "loss": 0.3406,
      "step": 13400
    },
    {
      "epoch": 3.8254284292114056,
      "grad_norm": 2.864359140396118,
      "learning_rate": 1.3054607508532423e-05,
      "loss": 0.3433,
      "step": 13450
    },
    {
      "epoch": 3.8396501457725947,
      "grad_norm": 2.9413092136383057,
      "learning_rate": 1.2896599671343698e-05,
      "loss": 0.3505,
      "step": 13500
    },
    {
      "epoch": 3.8538718623337838,
      "grad_norm": 3.072073459625244,
      "learning_rate": 1.2738591834154976e-05,
      "loss": 0.3526,
      "step": 13550
    },
    {
      "epoch": 3.868093578894973,
      "grad_norm": 2.00875186920166,
      "learning_rate": 1.258058399696625e-05,
      "loss": 0.3468,
      "step": 13600
    },
    {
      "epoch": 3.8823152954561615,
      "grad_norm": 2.692146062850952,
      "learning_rate": 1.2422576159777525e-05,
      "loss": 0.3431,
      "step": 13650
    },
    {
      "epoch": 3.8965370120173506,
      "grad_norm": 3.6597297191619873,
      "learning_rate": 1.2264568322588802e-05,
      "loss": 0.3454,
      "step": 13700
    },
    {
      "epoch": 3.9107587285785392,
      "grad_norm": 4.412318229675293,
      "learning_rate": 1.2106560485400076e-05,
      "loss": 0.3311,
      "step": 13750
    },
    {
      "epoch": 3.9249804451397283,
      "grad_norm": 2.2757582664489746,
      "learning_rate": 1.1948552648211351e-05,
      "loss": 0.337,
      "step": 13800
    },
    {
      "epoch": 3.9392021617009174,
      "grad_norm": 2.5272436141967773,
      "learning_rate": 1.1790544811022628e-05,
      "loss": 0.3347,
      "step": 13850
    },
    {
      "epoch": 3.9534238782621065,
      "grad_norm": 3.9319419860839844,
      "learning_rate": 1.1632536973833902e-05,
      "loss": 0.3359,
      "step": 13900
    },
    {
      "epoch": 3.967645594823295,
      "grad_norm": 2.9195213317871094,
      "learning_rate": 1.1474529136645177e-05,
      "loss": 0.3449,
      "step": 13950
    },
    {
      "epoch": 3.9818673113844842,
      "grad_norm": 2.201308488845825,
      "learning_rate": 1.1316521299456454e-05,
      "loss": 0.3472,
      "step": 14000
    },
    {
      "epoch": 3.9818673113844842,
      "eval_f1_macro": 0.7401614519441583,
      "eval_loss": 0.4177379310131073,
      "eval_runtime": 217.8609,
      "eval_samples_per_second": 918.017,
      "eval_steps_per_second": 7.174,
      "step": 14000
    },
    {
      "epoch": 3.996089027945673,
      "grad_norm": 5.33363676071167,
      "learning_rate": 1.115851346226773e-05,
      "loss": 0.3501,
      "step": 14050
    },
    {
      "epoch": 4.010239635924056,
      "grad_norm": 3.271888017654419,
      "learning_rate": 1.1000505625079005e-05,
      "loss": 0.3094,
      "step": 14100
    },
    {
      "epoch": 4.024461352485245,
      "grad_norm": 4.679869174957275,
      "learning_rate": 1.084249778789028e-05,
      "loss": 0.3113,
      "step": 14150
    },
    {
      "epoch": 4.038683069046434,
      "grad_norm": 2.7509984970092773,
      "learning_rate": 1.0684489950701556e-05,
      "loss": 0.3276,
      "step": 14200
    },
    {
      "epoch": 4.052904785607623,
      "grad_norm": 2.7572150230407715,
      "learning_rate": 1.052648211351283e-05,
      "loss": 0.3169,
      "step": 14250
    },
    {
      "epoch": 4.067126502168811,
      "grad_norm": 3.38393497467041,
      "learning_rate": 1.0368474276324105e-05,
      "loss": 0.3128,
      "step": 14300
    },
    {
      "epoch": 4.0813482187300005,
      "grad_norm": 4.156773090362549,
      "learning_rate": 1.0210466439135382e-05,
      "loss": 0.3118,
      "step": 14350
    },
    {
      "epoch": 4.09556993529119,
      "grad_norm": 3.298166513442993,
      "learning_rate": 1.0052458601946657e-05,
      "loss": 0.3114,
      "step": 14400
    },
    {
      "epoch": 4.109791651852379,
      "grad_norm": 2.8893773555755615,
      "learning_rate": 9.894450764757933e-06,
      "loss": 0.3053,
      "step": 14450
    },
    {
      "epoch": 4.124013368413568,
      "grad_norm": 3.5057389736175537,
      "learning_rate": 9.736442927569208e-06,
      "loss": 0.3076,
      "step": 14500
    },
    {
      "epoch": 4.138235084974756,
      "grad_norm": 4.191507816314697,
      "learning_rate": 9.578435090380483e-06,
      "loss": 0.3094,
      "step": 14550
    },
    {
      "epoch": 4.152456801535945,
      "grad_norm": 3.2427268028259277,
      "learning_rate": 9.420427253191759e-06,
      "loss": 0.3063,
      "step": 14600
    },
    {
      "epoch": 4.166678518097134,
      "grad_norm": 3.5420114994049072,
      "learning_rate": 9.262419416003036e-06,
      "loss": 0.3078,
      "step": 14650
    },
    {
      "epoch": 4.180900234658323,
      "grad_norm": 2.9037954807281494,
      "learning_rate": 9.104411578814309e-06,
      "loss": 0.3112,
      "step": 14700
    },
    {
      "epoch": 4.195121951219512,
      "grad_norm": 3.3201451301574707,
      "learning_rate": 8.946403741625585e-06,
      "loss": 0.3055,
      "step": 14750
    },
    {
      "epoch": 4.2093436677807015,
      "grad_norm": 3.8708159923553467,
      "learning_rate": 8.788395904436861e-06,
      "loss": 0.3133,
      "step": 14800
    },
    {
      "epoch": 4.22356538434189,
      "grad_norm": 3.0663022994995117,
      "learning_rate": 8.630388067248136e-06,
      "loss": 0.3162,
      "step": 14850
    },
    {
      "epoch": 4.237787100903079,
      "grad_norm": 2.26932954788208,
      "learning_rate": 8.472380230059411e-06,
      "loss": 0.315,
      "step": 14900
    },
    {
      "epoch": 4.252008817464268,
      "grad_norm": 2.6882827281951904,
      "learning_rate": 8.314372392870687e-06,
      "loss": 0.3233,
      "step": 14950
    },
    {
      "epoch": 4.266230534025457,
      "grad_norm": 2.8196768760681152,
      "learning_rate": 8.156364555681962e-06,
      "loss": 0.3177,
      "step": 15000
    },
    {
      "epoch": 4.266230534025457,
      "eval_f1_macro": 0.7447868451223617,
      "eval_loss": 0.42672818899154663,
      "eval_runtime": 217.78,
      "eval_samples_per_second": 918.358,
      "eval_steps_per_second": 7.177,
      "step": 15000
    },
    {
      "epoch": 4.280452250586646,
      "grad_norm": 3.1970198154449463,
      "learning_rate": 7.998356718493237e-06,
      "loss": 0.2997,
      "step": 15050
    },
    {
      "epoch": 4.294673967147835,
      "grad_norm": 3.389308452606201,
      "learning_rate": 7.840348881304513e-06,
      "loss": 0.3152,
      "step": 15100
    },
    {
      "epoch": 4.308895683709023,
      "grad_norm": 4.074422836303711,
      "learning_rate": 7.682341044115788e-06,
      "loss": 0.3114,
      "step": 15150
    },
    {
      "epoch": 4.323117400270212,
      "grad_norm": 2.491828441619873,
      "learning_rate": 7.5243332069270645e-06,
      "loss": 0.3139,
      "step": 15200
    },
    {
      "epoch": 4.3373391168314015,
      "grad_norm": 3.254405975341797,
      "learning_rate": 7.366325369738339e-06,
      "loss": 0.3123,
      "step": 15250
    },
    {
      "epoch": 4.351560833392591,
      "grad_norm": 3.1160755157470703,
      "learning_rate": 7.208317532549615e-06,
      "loss": 0.3184,
      "step": 15300
    },
    {
      "epoch": 4.36578254995378,
      "grad_norm": 2.5844767093658447,
      "learning_rate": 7.0503096953608904e-06,
      "loss": 0.3037,
      "step": 15350
    },
    {
      "epoch": 4.380004266514969,
      "grad_norm": 2.887317657470703,
      "learning_rate": 6.892301858172166e-06,
      "loss": 0.3123,
      "step": 15400
    },
    {
      "epoch": 4.394225983076157,
      "grad_norm": 2.6473805904388428,
      "learning_rate": 6.734294020983441e-06,
      "loss": 0.3057,
      "step": 15450
    },
    {
      "epoch": 4.408447699637346,
      "grad_norm": 2.636345148086548,
      "learning_rate": 6.576286183794716e-06,
      "loss": 0.3157,
      "step": 15500
    },
    {
      "epoch": 4.422669416198535,
      "grad_norm": 2.682399272918701,
      "learning_rate": 6.418278346605992e-06,
      "loss": 0.3189,
      "step": 15550
    },
    {
      "epoch": 4.436891132759724,
      "grad_norm": 2.4584755897521973,
      "learning_rate": 6.260270509417267e-06,
      "loss": 0.3124,
      "step": 15600
    },
    {
      "epoch": 4.451112849320913,
      "grad_norm": 2.6070609092712402,
      "learning_rate": 6.102262672228542e-06,
      "loss": 0.3099,
      "step": 15650
    },
    {
      "epoch": 4.465334565882102,
      "grad_norm": 3.2055771350860596,
      "learning_rate": 5.944254835039819e-06,
      "loss": 0.3197,
      "step": 15700
    },
    {
      "epoch": 4.479556282443291,
      "grad_norm": 3.0447473526000977,
      "learning_rate": 5.7862469978510935e-06,
      "loss": 0.3063,
      "step": 15750
    },
    {
      "epoch": 4.49377799900448,
      "grad_norm": 2.810499906539917,
      "learning_rate": 5.628239160662369e-06,
      "loss": 0.3134,
      "step": 15800
    },
    {
      "epoch": 4.507999715565669,
      "grad_norm": 3.594423770904541,
      "learning_rate": 5.470231323473645e-06,
      "loss": 0.3095,
      "step": 15850
    },
    {
      "epoch": 4.522221432126858,
      "grad_norm": 3.3908493518829346,
      "learning_rate": 5.31222348628492e-06,
      "loss": 0.3152,
      "step": 15900
    },
    {
      "epoch": 4.536443148688047,
      "grad_norm": 4.3185811042785645,
      "learning_rate": 5.154215649096195e-06,
      "loss": 0.305,
      "step": 15950
    },
    {
      "epoch": 4.550664865249235,
      "grad_norm": 6.682112693786621,
      "learning_rate": 4.9962078119074715e-06,
      "loss": 0.3215,
      "step": 16000
    },
    {
      "epoch": 4.550664865249235,
      "eval_f1_macro": 0.7464748808173549,
      "eval_loss": 0.42270609736442566,
      "eval_runtime": 217.878,
      "eval_samples_per_second": 917.945,
      "eval_steps_per_second": 7.174,
      "step": 16000
    },
    {
      "epoch": 4.564886581810424,
      "grad_norm": 2.9487013816833496,
      "learning_rate": 4.838199974718746e-06,
      "loss": 0.3079,
      "step": 16050
    },
    {
      "epoch": 4.579108298371613,
      "grad_norm": 2.9546263217926025,
      "learning_rate": 4.680192137530022e-06,
      "loss": 0.3106,
      "step": 16100
    },
    {
      "epoch": 4.5933300149328025,
      "grad_norm": 3.3899481296539307,
      "learning_rate": 4.522184300341297e-06,
      "loss": 0.3007,
      "step": 16150
    },
    {
      "epoch": 4.6075517314939916,
      "grad_norm": 2.4560980796813965,
      "learning_rate": 4.364176463152573e-06,
      "loss": 0.3113,
      "step": 16200
    },
    {
      "epoch": 4.621773448055181,
      "grad_norm": 2.759338855743408,
      "learning_rate": 4.206168625963848e-06,
      "loss": 0.3098,
      "step": 16250
    },
    {
      "epoch": 4.635995164616369,
      "grad_norm": 4.089550495147705,
      "learning_rate": 4.048160788775123e-06,
      "loss": 0.3052,
      "step": 16300
    },
    {
      "epoch": 4.650216881177558,
      "grad_norm": 3.738056182861328,
      "learning_rate": 3.890152951586399e-06,
      "loss": 0.3115,
      "step": 16350
    },
    {
      "epoch": 4.664438597738747,
      "grad_norm": 3.243563413619995,
      "learning_rate": 3.732145114397674e-06,
      "loss": 0.3149,
      "step": 16400
    },
    {
      "epoch": 4.678660314299936,
      "grad_norm": 6.139377117156982,
      "learning_rate": 3.5741372772089497e-06,
      "loss": 0.3096,
      "step": 16450
    },
    {
      "epoch": 4.692882030861125,
      "grad_norm": 3.700098752975464,
      "learning_rate": 3.416129440020225e-06,
      "loss": 0.3025,
      "step": 16500
    },
    {
      "epoch": 4.707103747422314,
      "grad_norm": 4.176173686981201,
      "learning_rate": 3.258121602831501e-06,
      "loss": 0.3017,
      "step": 16550
    },
    {
      "epoch": 4.7213254639835025,
      "grad_norm": 3.4877824783325195,
      "learning_rate": 3.100113765642776e-06,
      "loss": 0.304,
      "step": 16600
    },
    {
      "epoch": 4.735547180544692,
      "grad_norm": 1.8330806493759155,
      "learning_rate": 2.9421059284540512e-06,
      "loss": 0.2994,
      "step": 16650
    },
    {
      "epoch": 4.749768897105881,
      "grad_norm": 3.48187255859375,
      "learning_rate": 2.784098091265327e-06,
      "loss": 0.3108,
      "step": 16700
    },
    {
      "epoch": 4.76399061366707,
      "grad_norm": 2.7187416553497314,
      "learning_rate": 2.6260902540766024e-06,
      "loss": 0.3097,
      "step": 16750
    },
    {
      "epoch": 4.778212330228259,
      "grad_norm": 3.7663609981536865,
      "learning_rate": 2.4680824168878776e-06,
      "loss": 0.3109,
      "step": 16800
    },
    {
      "epoch": 4.792434046789447,
      "grad_norm": 3.183300256729126,
      "learning_rate": 2.310074579699153e-06,
      "loss": 0.3061,
      "step": 16850
    },
    {
      "epoch": 4.806655763350636,
      "grad_norm": 2.992485761642456,
      "learning_rate": 2.152066742510429e-06,
      "loss": 0.3085,
      "step": 16900
    },
    {
      "epoch": 4.820877479911825,
      "grad_norm": 3.4258265495300293,
      "learning_rate": 1.994058905321704e-06,
      "loss": 0.3175,
      "step": 16950
    },
    {
      "epoch": 4.835099196473014,
      "grad_norm": 3.2154922485351562,
      "learning_rate": 1.8360510681329796e-06,
      "loss": 0.3007,
      "step": 17000
    },
    {
      "epoch": 4.835099196473014,
      "eval_f1_macro": 0.7460529943115465,
      "eval_loss": 0.4270068407058716,
      "eval_runtime": 217.7625,
      "eval_samples_per_second": 918.432,
      "eval_steps_per_second": 7.178,
      "step": 17000
    },
    {
      "epoch": 4.849320913034203,
      "grad_norm": 2.8879716396331787,
      "learning_rate": 1.678043230944255e-06,
      "loss": 0.3175,
      "step": 17050
    },
    {
      "epoch": 4.8635426295953925,
      "grad_norm": 3.266913890838623,
      "learning_rate": 1.5200353937555303e-06,
      "loss": 0.3037,
      "step": 17100
    },
    {
      "epoch": 4.877764346156581,
      "grad_norm": 3.0975871086120605,
      "learning_rate": 1.3620275565668057e-06,
      "loss": 0.3052,
      "step": 17150
    },
    {
      "epoch": 4.89198606271777,
      "grad_norm": 2.196207284927368,
      "learning_rate": 1.2040197193780813e-06,
      "loss": 0.3003,
      "step": 17200
    },
    {
      "epoch": 4.906207779278959,
      "grad_norm": 3.452392816543579,
      "learning_rate": 1.0460118821893567e-06,
      "loss": 0.2973,
      "step": 17250
    },
    {
      "epoch": 4.920429495840148,
      "grad_norm": 2.7669284343719482,
      "learning_rate": 8.880040450006322e-07,
      "loss": 0.2955,
      "step": 17300
    },
    {
      "epoch": 4.934651212401337,
      "grad_norm": 3.300600290298462,
      "learning_rate": 7.299962078119076e-07,
      "loss": 0.3047,
      "step": 17350
    },
    {
      "epoch": 4.948872928962526,
      "grad_norm": 3.160604476928711,
      "learning_rate": 5.719883706231829e-07,
      "loss": 0.3086,
      "step": 17400
    },
    {
      "epoch": 4.963094645523714,
      "grad_norm": 2.8959410190582275,
      "learning_rate": 4.139805334344583e-07,
      "loss": 0.3097,
      "step": 17450
    },
    {
      "epoch": 4.9773163620849035,
      "grad_norm": 2.3296525478363037,
      "learning_rate": 2.559726962457338e-07,
      "loss": 0.305,
      "step": 17500
    },
    {
      "epoch": 4.991538078646093,
      "grad_norm": 3.0269556045532227,
      "learning_rate": 9.796485905700923e-08,
      "loss": 0.2999,
      "step": 17550
    }
  ],
  "logging_steps": 50,
  "max_steps": 17580,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.17939592836e+18,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
