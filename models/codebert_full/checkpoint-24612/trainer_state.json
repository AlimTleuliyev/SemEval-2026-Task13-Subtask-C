{
  "best_global_step": 18000,
  "best_metric": 0.8443488931940012,
  "best_model_checkpoint": "./models/codebert_full/checkpoint-18000",
  "epoch": 7.0,
  "eval_steps": 1000,
  "global_step": 24612,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00028443433122377873,
      "grad_norm": 5.767112731933594,
      "learning_rate": 0.0,
      "loss": 1.4306,
      "step": 1
    },
    {
      "epoch": 0.014221716561188936,
      "grad_norm": 6.009387493133545,
      "learning_rate": 3.980503655564582e-07,
      "loss": 1.4229,
      "step": 50
    },
    {
      "epoch": 0.028443433122377872,
      "grad_norm": 6.757211208343506,
      "learning_rate": 8.042242079610074e-07,
      "loss": 1.3488,
      "step": 100
    },
    {
      "epoch": 0.04266514968356681,
      "grad_norm": 2.6991381645202637,
      "learning_rate": 1.2103980503655566e-06,
      "loss": 1.2102,
      "step": 150
    },
    {
      "epoch": 0.056886866244755745,
      "grad_norm": 1.730493426322937,
      "learning_rate": 1.6165718927701056e-06,
      "loss": 1.1188,
      "step": 200
    },
    {
      "epoch": 0.07110858280594468,
      "grad_norm": 2.7802343368530273,
      "learning_rate": 2.022745735174655e-06,
      "loss": 1.0086,
      "step": 250
    },
    {
      "epoch": 0.08533029936713361,
      "grad_norm": 2.0947437286376953,
      "learning_rate": 2.428919577579204e-06,
      "loss": 0.9051,
      "step": 300
    },
    {
      "epoch": 0.09955201592832255,
      "grad_norm": 2.116118907928467,
      "learning_rate": 2.835093419983753e-06,
      "loss": 0.8351,
      "step": 350
    },
    {
      "epoch": 0.11377373248951149,
      "grad_norm": 6.6702141761779785,
      "learning_rate": 3.241267262388302e-06,
      "loss": 0.7856,
      "step": 400
    },
    {
      "epoch": 0.12799544905070043,
      "grad_norm": 3.134584665298462,
      "learning_rate": 3.6474411047928517e-06,
      "loss": 0.7379,
      "step": 450
    },
    {
      "epoch": 0.14221716561188935,
      "grad_norm": 6.5692973136901855,
      "learning_rate": 4.053614947197401e-06,
      "loss": 0.6982,
      "step": 500
    },
    {
      "epoch": 0.1564388821730783,
      "grad_norm": 3.8968684673309326,
      "learning_rate": 4.45978878960195e-06,
      "loss": 0.6804,
      "step": 550
    },
    {
      "epoch": 0.17066059873426723,
      "grad_norm": 6.6276984214782715,
      "learning_rate": 4.865962632006499e-06,
      "loss": 0.6411,
      "step": 600
    },
    {
      "epoch": 0.18488231529545615,
      "grad_norm": 8.736214637756348,
      "learning_rate": 5.272136474411048e-06,
      "loss": 0.5922,
      "step": 650
    },
    {
      "epoch": 0.1991040318566451,
      "grad_norm": 3.7245147228240967,
      "learning_rate": 5.678310316815597e-06,
      "loss": 0.5731,
      "step": 700
    },
    {
      "epoch": 0.21332574841783403,
      "grad_norm": 3.702232599258423,
      "learning_rate": 6.084484159220146e-06,
      "loss": 0.5525,
      "step": 750
    },
    {
      "epoch": 0.22754746497902298,
      "grad_norm": 10.522618293762207,
      "learning_rate": 6.490658001624695e-06,
      "loss": 0.5298,
      "step": 800
    },
    {
      "epoch": 0.2417691815402119,
      "grad_norm": 4.03914213180542,
      "learning_rate": 6.896831844029245e-06,
      "loss": 0.5277,
      "step": 850
    },
    {
      "epoch": 0.25599089810140085,
      "grad_norm": 5.215831756591797,
      "learning_rate": 7.303005686433794e-06,
      "loss": 0.5168,
      "step": 900
    },
    {
      "epoch": 0.2702126146625898,
      "grad_norm": 5.095738410949707,
      "learning_rate": 7.709179528838342e-06,
      "loss": 0.4861,
      "step": 950
    },
    {
      "epoch": 0.2844343312237787,
      "grad_norm": 6.703710079193115,
      "learning_rate": 8.115353371242892e-06,
      "loss": 0.4818,
      "step": 1000
    },
    {
      "epoch": 0.2844343312237787,
      "eval_f1_macro": 0.7337910770061812,
      "eval_loss": 0.46479812264442444,
      "eval_runtime": 217.9721,
      "eval_samples_per_second": 917.549,
      "eval_steps_per_second": 7.171,
      "step": 1000
    },
    {
      "epoch": 0.2986560477849676,
      "grad_norm": 4.840384483337402,
      "learning_rate": 8.52152721364744e-06,
      "loss": 0.4842,
      "step": 1050
    },
    {
      "epoch": 0.3128777643461566,
      "grad_norm": 4.268726825714111,
      "learning_rate": 8.92770105605199e-06,
      "loss": 0.4866,
      "step": 1100
    },
    {
      "epoch": 0.32709948090734553,
      "grad_norm": 6.2078938484191895,
      "learning_rate": 9.33387489845654e-06,
      "loss": 0.4549,
      "step": 1150
    },
    {
      "epoch": 0.34132119746853445,
      "grad_norm": 6.199721813201904,
      "learning_rate": 9.740048740861089e-06,
      "loss": 0.4417,
      "step": 1200
    },
    {
      "epoch": 0.3555429140297234,
      "grad_norm": 8.57396411895752,
      "learning_rate": 1.0146222583265639e-05,
      "loss": 0.4512,
      "step": 1250
    },
    {
      "epoch": 0.3697646305909123,
      "grad_norm": 6.207873344421387,
      "learning_rate": 1.0552396425670189e-05,
      "loss": 0.4558,
      "step": 1300
    },
    {
      "epoch": 0.3839863471521013,
      "grad_norm": 10.26534652709961,
      "learning_rate": 1.0958570268074737e-05,
      "loss": 0.4451,
      "step": 1350
    },
    {
      "epoch": 0.3982080637132902,
      "grad_norm": 8.44089126586914,
      "learning_rate": 1.1364744110479287e-05,
      "loss": 0.4291,
      "step": 1400
    },
    {
      "epoch": 0.41242978027447913,
      "grad_norm": 9.602057456970215,
      "learning_rate": 1.1770917952883835e-05,
      "loss": 0.436,
      "step": 1450
    },
    {
      "epoch": 0.42665149683566805,
      "grad_norm": 6.565223693847656,
      "learning_rate": 1.2177091795288385e-05,
      "loss": 0.4232,
      "step": 1500
    },
    {
      "epoch": 0.440873213396857,
      "grad_norm": 8.115138053894043,
      "learning_rate": 1.2583265637692935e-05,
      "loss": 0.4185,
      "step": 1550
    },
    {
      "epoch": 0.45509492995804596,
      "grad_norm": 8.165863037109375,
      "learning_rate": 1.2989439480097483e-05,
      "loss": 0.4166,
      "step": 1600
    },
    {
      "epoch": 0.4693166465192349,
      "grad_norm": 3.3671576976776123,
      "learning_rate": 1.3395613322502033e-05,
      "loss": 0.404,
      "step": 1650
    },
    {
      "epoch": 0.4835383630804238,
      "grad_norm": 3.861163854598999,
      "learning_rate": 1.3801787164906581e-05,
      "loss": 0.412,
      "step": 1700
    },
    {
      "epoch": 0.49776007964161273,
      "grad_norm": 5.238404273986816,
      "learning_rate": 1.4207961007311131e-05,
      "loss": 0.4048,
      "step": 1750
    },
    {
      "epoch": 0.5119817962028017,
      "grad_norm": 8.845303535461426,
      "learning_rate": 1.461413484971568e-05,
      "loss": 0.4101,
      "step": 1800
    },
    {
      "epoch": 0.5262035127639906,
      "grad_norm": 6.91595458984375,
      "learning_rate": 1.502030869212023e-05,
      "loss": 0.4034,
      "step": 1850
    },
    {
      "epoch": 0.5404252293251796,
      "grad_norm": 8.987468719482422,
      "learning_rate": 1.542648253452478e-05,
      "loss": 0.3941,
      "step": 1900
    },
    {
      "epoch": 0.5546469458863685,
      "grad_norm": 3.694305181503296,
      "learning_rate": 1.5832656376929327e-05,
      "loss": 0.3847,
      "step": 1950
    },
    {
      "epoch": 0.5688686624475574,
      "grad_norm": 5.393595218658447,
      "learning_rate": 1.6238830219333876e-05,
      "loss": 0.3882,
      "step": 2000
    },
    {
      "epoch": 0.5688686624475574,
      "eval_f1_macro": 0.7673971651862895,
      "eval_loss": 0.37844914197921753,
      "eval_runtime": 217.8517,
      "eval_samples_per_second": 918.056,
      "eval_steps_per_second": 7.175,
      "step": 2000
    },
    {
      "epoch": 0.5830903790087464,
      "grad_norm": 5.730745792388916,
      "learning_rate": 1.6645004061738427e-05,
      "loss": 0.38,
      "step": 2050
    },
    {
      "epoch": 0.5973120955699353,
      "grad_norm": 4.425944805145264,
      "learning_rate": 1.7051177904142976e-05,
      "loss": 0.365,
      "step": 2100
    },
    {
      "epoch": 0.6115338121311242,
      "grad_norm": 3.724714756011963,
      "learning_rate": 1.7457351746547524e-05,
      "loss": 0.3775,
      "step": 2150
    },
    {
      "epoch": 0.6257555286923132,
      "grad_norm": 5.094087600708008,
      "learning_rate": 1.7863525588952072e-05,
      "loss": 0.3657,
      "step": 2200
    },
    {
      "epoch": 0.6399772452535021,
      "grad_norm": 4.269923210144043,
      "learning_rate": 1.8269699431356624e-05,
      "loss": 0.3731,
      "step": 2250
    },
    {
      "epoch": 0.6541989618146911,
      "grad_norm": 4.676023483276367,
      "learning_rate": 1.8675873273761172e-05,
      "loss": 0.3646,
      "step": 2300
    },
    {
      "epoch": 0.6684206783758799,
      "grad_norm": 3.9843947887420654,
      "learning_rate": 1.908204711616572e-05,
      "loss": 0.3587,
      "step": 2350
    },
    {
      "epoch": 0.6826423949370689,
      "grad_norm": 2.65728497505188,
      "learning_rate": 1.948822095857027e-05,
      "loss": 0.3643,
      "step": 2400
    },
    {
      "epoch": 0.6968641114982579,
      "grad_norm": 4.30926513671875,
      "learning_rate": 1.989439480097482e-05,
      "loss": 0.3584,
      "step": 2450
    },
    {
      "epoch": 0.7110858280594468,
      "grad_norm": 6.623894214630127,
      "learning_rate": 1.9966591422121896e-05,
      "loss": 0.3704,
      "step": 2500
    },
    {
      "epoch": 0.7253075446206357,
      "grad_norm": 4.719824314117432,
      "learning_rate": 1.9921444695259594e-05,
      "loss": 0.355,
      "step": 2550
    },
    {
      "epoch": 0.7395292611818246,
      "grad_norm": 3.8764917850494385,
      "learning_rate": 1.9876297968397295e-05,
      "loss": 0.3414,
      "step": 2600
    },
    {
      "epoch": 0.7537509777430136,
      "grad_norm": 4.270401954650879,
      "learning_rate": 1.983115124153499e-05,
      "loss": 0.3481,
      "step": 2650
    },
    {
      "epoch": 0.7679726943042026,
      "grad_norm": 4.041802883148193,
      "learning_rate": 1.9786004514672686e-05,
      "loss": 0.3373,
      "step": 2700
    },
    {
      "epoch": 0.7821944108653914,
      "grad_norm": 3.6510238647460938,
      "learning_rate": 1.9740857787810387e-05,
      "loss": 0.3359,
      "step": 2750
    },
    {
      "epoch": 0.7964161274265804,
      "grad_norm": 4.377945423126221,
      "learning_rate": 1.9695711060948085e-05,
      "loss": 0.3321,
      "step": 2800
    },
    {
      "epoch": 0.8106378439877693,
      "grad_norm": 3.283217430114746,
      "learning_rate": 1.965056433408578e-05,
      "loss": 0.3338,
      "step": 2850
    },
    {
      "epoch": 0.8248595605489583,
      "grad_norm": 4.912013053894043,
      "learning_rate": 1.9605417607223476e-05,
      "loss": 0.34,
      "step": 2900
    },
    {
      "epoch": 0.8390812771101472,
      "grad_norm": 3.289323329925537,
      "learning_rate": 1.9560270880361177e-05,
      "loss": 0.3378,
      "step": 2950
    },
    {
      "epoch": 0.8533029936713361,
      "grad_norm": 2.460805654525757,
      "learning_rate": 1.951512415349887e-05,
      "loss": 0.3328,
      "step": 3000
    },
    {
      "epoch": 0.8533029936713361,
      "eval_f1_macro": 0.790720013980507,
      "eval_loss": 0.34172606468200684,
      "eval_runtime": 217.9431,
      "eval_samples_per_second": 917.671,
      "eval_steps_per_second": 7.172,
      "step": 3000
    },
    {
      "epoch": 0.8675247102325251,
      "grad_norm": 3.5158040523529053,
      "learning_rate": 1.946997742663657e-05,
      "loss": 0.3324,
      "step": 3050
    },
    {
      "epoch": 0.881746426793714,
      "grad_norm": 3.4847190380096436,
      "learning_rate": 1.942483069977427e-05,
      "loss": 0.3205,
      "step": 3100
    },
    {
      "epoch": 0.8959681433549029,
      "grad_norm": 3.1341333389282227,
      "learning_rate": 1.9379683972911964e-05,
      "loss": 0.3336,
      "step": 3150
    },
    {
      "epoch": 0.9101898599160919,
      "grad_norm": 2.9280378818511963,
      "learning_rate": 1.933453724604966e-05,
      "loss": 0.3429,
      "step": 3200
    },
    {
      "epoch": 0.9244115764772808,
      "grad_norm": 5.124032974243164,
      "learning_rate": 1.9289390519187362e-05,
      "loss": 0.3277,
      "step": 3250
    },
    {
      "epoch": 0.9386332930384698,
      "grad_norm": 4.773360252380371,
      "learning_rate": 1.9244243792325056e-05,
      "loss": 0.3223,
      "step": 3300
    },
    {
      "epoch": 0.9528550095996586,
      "grad_norm": 3.323556900024414,
      "learning_rate": 1.9199097065462754e-05,
      "loss": 0.3196,
      "step": 3350
    },
    {
      "epoch": 0.9670767261608476,
      "grad_norm": 3.4027509689331055,
      "learning_rate": 1.9153950338600455e-05,
      "loss": 0.329,
      "step": 3400
    },
    {
      "epoch": 0.9812984427220366,
      "grad_norm": 2.9159512519836426,
      "learning_rate": 1.9108803611738152e-05,
      "loss": 0.3176,
      "step": 3450
    },
    {
      "epoch": 0.9955201592832255,
      "grad_norm": 4.16328239440918,
      "learning_rate": 1.9063656884875846e-05,
      "loss": 0.3095,
      "step": 3500
    },
    {
      "epoch": 1.0096707672616085,
      "grad_norm": 3.297980308532715,
      "learning_rate": 1.9018510158013544e-05,
      "loss": 0.2967,
      "step": 3550
    },
    {
      "epoch": 1.0238924838227974,
      "grad_norm": 4.1153564453125,
      "learning_rate": 1.8973363431151245e-05,
      "loss": 0.2932,
      "step": 3600
    },
    {
      "epoch": 1.0381142003839863,
      "grad_norm": 3.130363941192627,
      "learning_rate": 1.892821670428894e-05,
      "loss": 0.306,
      "step": 3650
    },
    {
      "epoch": 1.0523359169451754,
      "grad_norm": 4.375884532928467,
      "learning_rate": 1.8883069977426636e-05,
      "loss": 0.2999,
      "step": 3700
    },
    {
      "epoch": 1.0665576335063642,
      "grad_norm": 3.860649585723877,
      "learning_rate": 1.8837923250564337e-05,
      "loss": 0.3019,
      "step": 3750
    },
    {
      "epoch": 1.080779350067553,
      "grad_norm": 3.861119508743286,
      "learning_rate": 1.879277652370203e-05,
      "loss": 0.2956,
      "step": 3800
    },
    {
      "epoch": 1.0950010666287422,
      "grad_norm": 5.409212589263916,
      "learning_rate": 1.874762979683973e-05,
      "loss": 0.2984,
      "step": 3850
    },
    {
      "epoch": 1.109222783189931,
      "grad_norm": 2.1494081020355225,
      "learning_rate": 1.870248306997743e-05,
      "loss": 0.3002,
      "step": 3900
    },
    {
      "epoch": 1.12344449975112,
      "grad_norm": 3.9969887733459473,
      "learning_rate": 1.8657336343115127e-05,
      "loss": 0.2944,
      "step": 3950
    },
    {
      "epoch": 1.1376662163123088,
      "grad_norm": 2.9382665157318115,
      "learning_rate": 1.861218961625282e-05,
      "loss": 0.2955,
      "step": 4000
    },
    {
      "epoch": 1.1376662163123088,
      "eval_f1_macro": 0.8151848917262123,
      "eval_loss": 0.305245578289032,
      "eval_runtime": 217.9922,
      "eval_samples_per_second": 917.464,
      "eval_steps_per_second": 7.17,
      "step": 4000
    },
    {
      "epoch": 1.1518879328734979,
      "grad_norm": 4.229671478271484,
      "learning_rate": 1.8567042889390522e-05,
      "loss": 0.3017,
      "step": 4050
    },
    {
      "epoch": 1.1661096494346868,
      "grad_norm": 2.712491035461426,
      "learning_rate": 1.852189616252822e-05,
      "loss": 0.2998,
      "step": 4100
    },
    {
      "epoch": 1.1803313659958756,
      "grad_norm": 3.4087228775024414,
      "learning_rate": 1.8476749435665914e-05,
      "loss": 0.2918,
      "step": 4150
    },
    {
      "epoch": 1.1945530825570647,
      "grad_norm": 2.2585289478302,
      "learning_rate": 1.8431602708803615e-05,
      "loss": 0.2908,
      "step": 4200
    },
    {
      "epoch": 1.2087747991182536,
      "grad_norm": 2.6904783248901367,
      "learning_rate": 1.8386455981941312e-05,
      "loss": 0.2967,
      "step": 4250
    },
    {
      "epoch": 1.2229965156794425,
      "grad_norm": 2.859236240386963,
      "learning_rate": 1.8341309255079006e-05,
      "loss": 0.2925,
      "step": 4300
    },
    {
      "epoch": 1.2372182322406315,
      "grad_norm": 4.372508525848389,
      "learning_rate": 1.8296162528216704e-05,
      "loss": 0.2962,
      "step": 4350
    },
    {
      "epoch": 1.2514399488018204,
      "grad_norm": 3.896580934524536,
      "learning_rate": 1.8251015801354405e-05,
      "loss": 0.291,
      "step": 4400
    },
    {
      "epoch": 1.2656616653630093,
      "grad_norm": 4.167984962463379,
      "learning_rate": 1.8205869074492102e-05,
      "loss": 0.2918,
      "step": 4450
    },
    {
      "epoch": 1.2798833819241984,
      "grad_norm": 2.49076247215271,
      "learning_rate": 1.8160722347629796e-05,
      "loss": 0.2929,
      "step": 4500
    },
    {
      "epoch": 1.2941050984853872,
      "grad_norm": 2.1682803630828857,
      "learning_rate": 1.8115575620767497e-05,
      "loss": 0.28,
      "step": 4550
    },
    {
      "epoch": 1.308326815046576,
      "grad_norm": 2.9872243404388428,
      "learning_rate": 1.8070428893905195e-05,
      "loss": 0.282,
      "step": 4600
    },
    {
      "epoch": 1.322548531607765,
      "grad_norm": 2.500737190246582,
      "learning_rate": 1.802528216704289e-05,
      "loss": 0.2939,
      "step": 4650
    },
    {
      "epoch": 1.336770248168954,
      "grad_norm": 2.7746500968933105,
      "learning_rate": 1.798013544018059e-05,
      "loss": 0.2876,
      "step": 4700
    },
    {
      "epoch": 1.350991964730143,
      "grad_norm": 2.800449848175049,
      "learning_rate": 1.7934988713318287e-05,
      "loss": 0.2872,
      "step": 4750
    },
    {
      "epoch": 1.3652136812913318,
      "grad_norm": 2.4195258617401123,
      "learning_rate": 1.788984198645598e-05,
      "loss": 0.2839,
      "step": 4800
    },
    {
      "epoch": 1.3794353978525207,
      "grad_norm": 3.3817033767700195,
      "learning_rate": 1.7844695259593682e-05,
      "loss": 0.2737,
      "step": 4850
    },
    {
      "epoch": 1.3936571144137098,
      "grad_norm": 3.3899664878845215,
      "learning_rate": 1.779954853273138e-05,
      "loss": 0.2739,
      "step": 4900
    },
    {
      "epoch": 1.4078788309748986,
      "grad_norm": 4.791003704071045,
      "learning_rate": 1.7754401805869077e-05,
      "loss": 0.2863,
      "step": 4950
    },
    {
      "epoch": 1.4221005475360875,
      "grad_norm": 2.956049680709839,
      "learning_rate": 1.770925507900677e-05,
      "loss": 0.2744,
      "step": 5000
    },
    {
      "epoch": 1.4221005475360875,
      "eval_f1_macro": 0.8103842443258247,
      "eval_loss": 0.30798453092575073,
      "eval_runtime": 218.1235,
      "eval_samples_per_second": 916.912,
      "eval_steps_per_second": 7.166,
      "step": 5000
    },
    {
      "epoch": 1.4363222640972766,
      "grad_norm": 3.071239471435547,
      "learning_rate": 1.7664108352144472e-05,
      "loss": 0.2861,
      "step": 5050
    },
    {
      "epoch": 1.4505439806584655,
      "grad_norm": 2.7186291217803955,
      "learning_rate": 1.761896162528217e-05,
      "loss": 0.2744,
      "step": 5100
    },
    {
      "epoch": 1.4647656972196543,
      "grad_norm": 3.943495512008667,
      "learning_rate": 1.7573814898419864e-05,
      "loss": 0.2888,
      "step": 5150
    },
    {
      "epoch": 1.4789874137808434,
      "grad_norm": 3.214477300643921,
      "learning_rate": 1.7528668171557565e-05,
      "loss": 0.283,
      "step": 5200
    },
    {
      "epoch": 1.4932091303420323,
      "grad_norm": 3.4574086666107178,
      "learning_rate": 1.7483521444695262e-05,
      "loss": 0.2803,
      "step": 5250
    },
    {
      "epoch": 1.5074308469032212,
      "grad_norm": 3.4621193408966064,
      "learning_rate": 1.7438374717832956e-05,
      "loss": 0.2799,
      "step": 5300
    },
    {
      "epoch": 1.5216525634644102,
      "grad_norm": 2.7767386436462402,
      "learning_rate": 1.7393227990970657e-05,
      "loss": 0.2745,
      "step": 5350
    },
    {
      "epoch": 1.5358742800255991,
      "grad_norm": 3.442692279815674,
      "learning_rate": 1.7348081264108355e-05,
      "loss": 0.2812,
      "step": 5400
    },
    {
      "epoch": 1.550095996586788,
      "grad_norm": 4.357296943664551,
      "learning_rate": 1.730293453724605e-05,
      "loss": 0.2764,
      "step": 5450
    },
    {
      "epoch": 1.564317713147977,
      "grad_norm": 2.7915384769439697,
      "learning_rate": 1.725778781038375e-05,
      "loss": 0.2698,
      "step": 5500
    },
    {
      "epoch": 1.578539429709166,
      "grad_norm": 3.9685258865356445,
      "learning_rate": 1.7212641083521447e-05,
      "loss": 0.2774,
      "step": 5550
    },
    {
      "epoch": 1.5927611462703548,
      "grad_norm": 2.5138940811157227,
      "learning_rate": 1.7167494356659145e-05,
      "loss": 0.271,
      "step": 5600
    },
    {
      "epoch": 1.606982862831544,
      "grad_norm": 3.2971882820129395,
      "learning_rate": 1.712234762979684e-05,
      "loss": 0.2705,
      "step": 5650
    },
    {
      "epoch": 1.6212045793927325,
      "grad_norm": 3.161799430847168,
      "learning_rate": 1.707720090293454e-05,
      "loss": 0.2832,
      "step": 5700
    },
    {
      "epoch": 1.6354262959539216,
      "grad_norm": 3.8969295024871826,
      "learning_rate": 1.7032054176072237e-05,
      "loss": 0.2784,
      "step": 5750
    },
    {
      "epoch": 1.6496480125151107,
      "grad_norm": 2.461130142211914,
      "learning_rate": 1.698690744920993e-05,
      "loss": 0.2811,
      "step": 5800
    },
    {
      "epoch": 1.6638697290762994,
      "grad_norm": 3.4463860988616943,
      "learning_rate": 1.6941760722347632e-05,
      "loss": 0.2745,
      "step": 5850
    },
    {
      "epoch": 1.6780914456374885,
      "grad_norm": 3.077951192855835,
      "learning_rate": 1.689661399548533e-05,
      "loss": 0.2648,
      "step": 5900
    },
    {
      "epoch": 1.6923131621986773,
      "grad_norm": 2.8273115158081055,
      "learning_rate": 1.6851467268623024e-05,
      "loss": 0.2712,
      "step": 5950
    },
    {
      "epoch": 1.7065348787598662,
      "grad_norm": 2.4086527824401855,
      "learning_rate": 1.6806320541760725e-05,
      "loss": 0.2761,
      "step": 6000
    },
    {
      "epoch": 1.7065348787598662,
      "eval_f1_macro": 0.8162809354741694,
      "eval_loss": 0.311934232711792,
      "eval_runtime": 217.8907,
      "eval_samples_per_second": 917.891,
      "eval_steps_per_second": 7.173,
      "step": 6000
    },
    {
      "epoch": 1.7207565953210553,
      "grad_norm": 1.980441927909851,
      "learning_rate": 1.6761173814898422e-05,
      "loss": 0.2719,
      "step": 6050
    },
    {
      "epoch": 1.7349783118822442,
      "grad_norm": 3.1439108848571777,
      "learning_rate": 1.671602708803612e-05,
      "loss": 0.2743,
      "step": 6100
    },
    {
      "epoch": 1.749200028443433,
      "grad_norm": 1.7566804885864258,
      "learning_rate": 1.6670880361173817e-05,
      "loss": 0.2671,
      "step": 6150
    },
    {
      "epoch": 1.7634217450046221,
      "grad_norm": 2.9844329357147217,
      "learning_rate": 1.6625733634311515e-05,
      "loss": 0.2652,
      "step": 6200
    },
    {
      "epoch": 1.777643461565811,
      "grad_norm": 2.8521997928619385,
      "learning_rate": 1.6580586907449212e-05,
      "loss": 0.2696,
      "step": 6250
    },
    {
      "epoch": 1.7918651781269999,
      "grad_norm": 4.654716968536377,
      "learning_rate": 1.6535440180586906e-05,
      "loss": 0.2802,
      "step": 6300
    },
    {
      "epoch": 1.806086894688189,
      "grad_norm": 4.356995582580566,
      "learning_rate": 1.6490293453724607e-05,
      "loss": 0.2694,
      "step": 6350
    },
    {
      "epoch": 1.8203086112493778,
      "grad_norm": 2.752964735031128,
      "learning_rate": 1.6445146726862305e-05,
      "loss": 0.2779,
      "step": 6400
    },
    {
      "epoch": 1.8345303278105667,
      "grad_norm": 3.6450631618499756,
      "learning_rate": 1.64e-05,
      "loss": 0.2648,
      "step": 6450
    },
    {
      "epoch": 1.8487520443717558,
      "grad_norm": 2.907701015472412,
      "learning_rate": 1.63548532731377e-05,
      "loss": 0.2659,
      "step": 6500
    },
    {
      "epoch": 1.8629737609329446,
      "grad_norm": 2.252427101135254,
      "learning_rate": 1.6309706546275397e-05,
      "loss": 0.2683,
      "step": 6550
    },
    {
      "epoch": 1.8771954774941335,
      "grad_norm": 2.605229616165161,
      "learning_rate": 1.6264559819413095e-05,
      "loss": 0.2702,
      "step": 6600
    },
    {
      "epoch": 1.8914171940553226,
      "grad_norm": 2.90617299079895,
      "learning_rate": 1.6219413092550792e-05,
      "loss": 0.2725,
      "step": 6650
    },
    {
      "epoch": 1.9056389106165113,
      "grad_norm": 2.885417938232422,
      "learning_rate": 1.617426636568849e-05,
      "loss": 0.2651,
      "step": 6700
    },
    {
      "epoch": 1.9198606271777003,
      "grad_norm": 2.89164400100708,
      "learning_rate": 1.6129119638826187e-05,
      "loss": 0.2692,
      "step": 6750
    },
    {
      "epoch": 1.9340823437388894,
      "grad_norm": 2.235246419906616,
      "learning_rate": 1.6083972911963885e-05,
      "loss": 0.2647,
      "step": 6800
    },
    {
      "epoch": 1.948304060300078,
      "grad_norm": 2.4855692386627197,
      "learning_rate": 1.6038826185101582e-05,
      "loss": 0.2741,
      "step": 6850
    },
    {
      "epoch": 1.9625257768612672,
      "grad_norm": 3.3395774364471436,
      "learning_rate": 1.599367945823928e-05,
      "loss": 0.2628,
      "step": 6900
    },
    {
      "epoch": 1.976747493422456,
      "grad_norm": 2.0468344688415527,
      "learning_rate": 1.5948532731376977e-05,
      "loss": 0.2549,
      "step": 6950
    },
    {
      "epoch": 1.990969209983645,
      "grad_norm": 3.396099090576172,
      "learning_rate": 1.5903386004514675e-05,
      "loss": 0.2656,
      "step": 7000
    },
    {
      "epoch": 1.990969209983645,
      "eval_f1_macro": 0.8199839326765416,
      "eval_loss": 0.2985665202140808,
      "eval_runtime": 217.9262,
      "eval_samples_per_second": 917.742,
      "eval_steps_per_second": 7.172,
      "step": 7000
    },
    {
      "epoch": 2.005119817962028,
      "grad_norm": 2.47910475730896,
      "learning_rate": 1.5858239277652372e-05,
      "loss": 0.2638,
      "step": 7050
    },
    {
      "epoch": 2.019341534523217,
      "grad_norm": 2.6201303005218506,
      "learning_rate": 1.581309255079007e-05,
      "loss": 0.2473,
      "step": 7100
    },
    {
      "epoch": 2.0335632510844057,
      "grad_norm": 2.906261444091797,
      "learning_rate": 1.5767945823927767e-05,
      "loss": 0.2348,
      "step": 7150
    },
    {
      "epoch": 2.047784967645595,
      "grad_norm": 3.616793394088745,
      "learning_rate": 1.5722799097065465e-05,
      "loss": 0.2474,
      "step": 7200
    },
    {
      "epoch": 2.062006684206784,
      "grad_norm": 3.426687002182007,
      "learning_rate": 1.5677652370203162e-05,
      "loss": 0.2479,
      "step": 7250
    },
    {
      "epoch": 2.0762284007679725,
      "grad_norm": 2.6693148612976074,
      "learning_rate": 1.563250564334086e-05,
      "loss": 0.2423,
      "step": 7300
    },
    {
      "epoch": 2.0904501173291616,
      "grad_norm": 3.1761748790740967,
      "learning_rate": 1.5587358916478557e-05,
      "loss": 0.2423,
      "step": 7350
    },
    {
      "epoch": 2.1046718338903507,
      "grad_norm": 2.8782620429992676,
      "learning_rate": 1.5542212189616255e-05,
      "loss": 0.2406,
      "step": 7400
    },
    {
      "epoch": 2.1188935504515394,
      "grad_norm": 2.3562614917755127,
      "learning_rate": 1.5497065462753952e-05,
      "loss": 0.2436,
      "step": 7450
    },
    {
      "epoch": 2.1331152670127285,
      "grad_norm": 2.816882371902466,
      "learning_rate": 1.545191873589165e-05,
      "loss": 0.2444,
      "step": 7500
    },
    {
      "epoch": 2.1473369835739176,
      "grad_norm": 2.5306432247161865,
      "learning_rate": 1.5406772009029347e-05,
      "loss": 0.2427,
      "step": 7550
    },
    {
      "epoch": 2.161558700135106,
      "grad_norm": 2.2227742671966553,
      "learning_rate": 1.5361625282167045e-05,
      "loss": 0.2386,
      "step": 7600
    },
    {
      "epoch": 2.1757804166962953,
      "grad_norm": 2.2870070934295654,
      "learning_rate": 1.5316478555304742e-05,
      "loss": 0.237,
      "step": 7650
    },
    {
      "epoch": 2.1900021332574844,
      "grad_norm": 2.9039413928985596,
      "learning_rate": 1.527133182844244e-05,
      "loss": 0.2338,
      "step": 7700
    },
    {
      "epoch": 2.204223849818673,
      "grad_norm": 2.9576447010040283,
      "learning_rate": 1.5226185101580137e-05,
      "loss": 0.2437,
      "step": 7750
    },
    {
      "epoch": 2.218445566379862,
      "grad_norm": 2.5234694480895996,
      "learning_rate": 1.5181038374717833e-05,
      "loss": 0.2408,
      "step": 7800
    },
    {
      "epoch": 2.232667282941051,
      "grad_norm": 4.056820392608643,
      "learning_rate": 1.5135891647855532e-05,
      "loss": 0.2541,
      "step": 7850
    },
    {
      "epoch": 2.24688899950224,
      "grad_norm": 2.636319875717163,
      "learning_rate": 1.509074492099323e-05,
      "loss": 0.2306,
      "step": 7900
    },
    {
      "epoch": 2.261110716063429,
      "grad_norm": 3.064018487930298,
      "learning_rate": 1.5045598194130925e-05,
      "loss": 0.2451,
      "step": 7950
    },
    {
      "epoch": 2.2753324326246176,
      "grad_norm": 2.721606731414795,
      "learning_rate": 1.5000451467268625e-05,
      "loss": 0.2538,
      "step": 8000
    },
    {
      "epoch": 2.2753324326246176,
      "eval_f1_macro": 0.8297316443292377,
      "eval_loss": 0.2888402044773102,
      "eval_runtime": 217.9753,
      "eval_samples_per_second": 917.535,
      "eval_steps_per_second": 7.171,
      "step": 8000
    },
    {
      "epoch": 2.2895541491858067,
      "grad_norm": 3.1753182411193848,
      "learning_rate": 1.4955304740406322e-05,
      "loss": 0.247,
      "step": 8050
    },
    {
      "epoch": 2.3037758657469958,
      "grad_norm": 2.8663177490234375,
      "learning_rate": 1.4910158013544018e-05,
      "loss": 0.2288,
      "step": 8100
    },
    {
      "epoch": 2.3179975823081844,
      "grad_norm": 3.4231927394866943,
      "learning_rate": 1.4865011286681717e-05,
      "loss": 0.2311,
      "step": 8150
    },
    {
      "epoch": 2.3322192988693735,
      "grad_norm": 2.785086154937744,
      "learning_rate": 1.4819864559819415e-05,
      "loss": 0.2429,
      "step": 8200
    },
    {
      "epoch": 2.3464410154305626,
      "grad_norm": 2.767112970352173,
      "learning_rate": 1.4774717832957112e-05,
      "loss": 0.2336,
      "step": 8250
    },
    {
      "epoch": 2.3606627319917513,
      "grad_norm": 3.1516451835632324,
      "learning_rate": 1.4729571106094808e-05,
      "loss": 0.2334,
      "step": 8300
    },
    {
      "epoch": 2.3748844485529403,
      "grad_norm": 3.365387439727783,
      "learning_rate": 1.4684424379232507e-05,
      "loss": 0.2369,
      "step": 8350
    },
    {
      "epoch": 2.3891061651141294,
      "grad_norm": 2.9137918949127197,
      "learning_rate": 1.4639277652370205e-05,
      "loss": 0.2367,
      "step": 8400
    },
    {
      "epoch": 2.403327881675318,
      "grad_norm": 3.8746893405914307,
      "learning_rate": 1.45941309255079e-05,
      "loss": 0.2388,
      "step": 8450
    },
    {
      "epoch": 2.417549598236507,
      "grad_norm": 3.493560552597046,
      "learning_rate": 1.45489841986456e-05,
      "loss": 0.2335,
      "step": 8500
    },
    {
      "epoch": 2.4317713147976963,
      "grad_norm": 2.853355646133423,
      "learning_rate": 1.4503837471783297e-05,
      "loss": 0.248,
      "step": 8550
    },
    {
      "epoch": 2.445993031358885,
      "grad_norm": 2.689448118209839,
      "learning_rate": 1.4458690744920993e-05,
      "loss": 0.2386,
      "step": 8600
    },
    {
      "epoch": 2.460214747920074,
      "grad_norm": 2.915584087371826,
      "learning_rate": 1.4413544018058692e-05,
      "loss": 0.2369,
      "step": 8650
    },
    {
      "epoch": 2.474436464481263,
      "grad_norm": 2.670520782470703,
      "learning_rate": 1.436839729119639e-05,
      "loss": 0.2445,
      "step": 8700
    },
    {
      "epoch": 2.4886581810424517,
      "grad_norm": 3.938718557357788,
      "learning_rate": 1.4323250564334089e-05,
      "loss": 0.2335,
      "step": 8750
    },
    {
      "epoch": 2.502879897603641,
      "grad_norm": 3.0387446880340576,
      "learning_rate": 1.4278103837471785e-05,
      "loss": 0.2382,
      "step": 8800
    },
    {
      "epoch": 2.5171016141648295,
      "grad_norm": 2.453392505645752,
      "learning_rate": 1.4232957110609482e-05,
      "loss": 0.2392,
      "step": 8850
    },
    {
      "epoch": 2.5313233307260186,
      "grad_norm": 3.1640844345092773,
      "learning_rate": 1.418781038374718e-05,
      "loss": 0.2331,
      "step": 8900
    },
    {
      "epoch": 2.5455450472872077,
      "grad_norm": 2.5829310417175293,
      "learning_rate": 1.4142663656884877e-05,
      "loss": 0.242,
      "step": 8950
    },
    {
      "epoch": 2.5597667638483967,
      "grad_norm": 1.9499431848526,
      "learning_rate": 1.4097516930022575e-05,
      "loss": 0.2358,
      "step": 9000
    },
    {
      "epoch": 2.5597667638483967,
      "eval_f1_macro": 0.8348358778138506,
      "eval_loss": 0.28161171078681946,
      "eval_runtime": 218.0914,
      "eval_samples_per_second": 917.047,
      "eval_steps_per_second": 7.167,
      "step": 9000
    },
    {
      "epoch": 2.5739884804095854,
      "grad_norm": 3.0590054988861084,
      "learning_rate": 1.4052370203160272e-05,
      "loss": 0.2369,
      "step": 9050
    },
    {
      "epoch": 2.5882101969707745,
      "grad_norm": 3.2731406688690186,
      "learning_rate": 1.4007223476297968e-05,
      "loss": 0.242,
      "step": 9100
    },
    {
      "epoch": 2.602431913531963,
      "grad_norm": 2.892728567123413,
      "learning_rate": 1.3962076749435667e-05,
      "loss": 0.2401,
      "step": 9150
    },
    {
      "epoch": 2.616653630093152,
      "grad_norm": 3.7544262409210205,
      "learning_rate": 1.3916930022573365e-05,
      "loss": 0.2454,
      "step": 9200
    },
    {
      "epoch": 2.6308753466543413,
      "grad_norm": 2.15031361579895,
      "learning_rate": 1.3871783295711064e-05,
      "loss": 0.2536,
      "step": 9250
    },
    {
      "epoch": 2.64509706321553,
      "grad_norm": 2.8682055473327637,
      "learning_rate": 1.382663656884876e-05,
      "loss": 0.2414,
      "step": 9300
    },
    {
      "epoch": 2.659318779776719,
      "grad_norm": 2.924104928970337,
      "learning_rate": 1.3781489841986457e-05,
      "loss": 0.2443,
      "step": 9350
    },
    {
      "epoch": 2.673540496337908,
      "grad_norm": 3.0326156616210938,
      "learning_rate": 1.3736343115124156e-05,
      "loss": 0.2361,
      "step": 9400
    },
    {
      "epoch": 2.687762212899097,
      "grad_norm": 5.385464668273926,
      "learning_rate": 1.3691196388261852e-05,
      "loss": 0.2319,
      "step": 9450
    },
    {
      "epoch": 2.701983929460286,
      "grad_norm": 2.435497760772705,
      "learning_rate": 1.364604966139955e-05,
      "loss": 0.2462,
      "step": 9500
    },
    {
      "epoch": 2.716205646021475,
      "grad_norm": 2.964747190475464,
      "learning_rate": 1.3600902934537247e-05,
      "loss": 0.2292,
      "step": 9550
    },
    {
      "epoch": 2.7304273625826636,
      "grad_norm": 3.589632511138916,
      "learning_rate": 1.3555756207674945e-05,
      "loss": 0.2317,
      "step": 9600
    },
    {
      "epoch": 2.7446490791438527,
      "grad_norm": 2.925520420074463,
      "learning_rate": 1.3510609480812642e-05,
      "loss": 0.2437,
      "step": 9650
    },
    {
      "epoch": 2.7588707957050413,
      "grad_norm": 2.680050849914551,
      "learning_rate": 1.346546275395034e-05,
      "loss": 0.2314,
      "step": 9700
    },
    {
      "epoch": 2.7730925122662304,
      "grad_norm": 2.6507325172424316,
      "learning_rate": 1.3420316027088035e-05,
      "loss": 0.2476,
      "step": 9750
    },
    {
      "epoch": 2.7873142288274195,
      "grad_norm": 2.2603089809417725,
      "learning_rate": 1.3375169300225735e-05,
      "loss": 0.2357,
      "step": 9800
    },
    {
      "epoch": 2.8015359453886086,
      "grad_norm": 2.9264228343963623,
      "learning_rate": 1.3330022573363432e-05,
      "loss": 0.2388,
      "step": 9850
    },
    {
      "epoch": 2.8157576619497973,
      "grad_norm": 2.640376567840576,
      "learning_rate": 1.3284875846501131e-05,
      "loss": 0.2435,
      "step": 9900
    },
    {
      "epoch": 2.8299793785109864,
      "grad_norm": 3.8941965103149414,
      "learning_rate": 1.3239729119638827e-05,
      "loss": 0.2414,
      "step": 9950
    },
    {
      "epoch": 2.844201095072175,
      "grad_norm": 3.036593198776245,
      "learning_rate": 1.3194582392776525e-05,
      "loss": 0.2341,
      "step": 10000
    },
    {
      "epoch": 2.844201095072175,
      "eval_f1_macro": 0.8391584801381406,
      "eval_loss": 0.2663625478744507,
      "eval_runtime": 217.9533,
      "eval_samples_per_second": 917.628,
      "eval_steps_per_second": 7.171,
      "step": 10000
    },
    {
      "epoch": 2.858422811633364,
      "grad_norm": 3.7180721759796143,
      "learning_rate": 1.3149435665914224e-05,
      "loss": 0.2408,
      "step": 10050
    },
    {
      "epoch": 2.872644528194553,
      "grad_norm": 3.1735198497772217,
      "learning_rate": 1.310428893905192e-05,
      "loss": 0.2455,
      "step": 10100
    },
    {
      "epoch": 2.8868662447557423,
      "grad_norm": 3.094204902648926,
      "learning_rate": 1.3059142212189617e-05,
      "loss": 0.2295,
      "step": 10150
    },
    {
      "epoch": 2.901087961316931,
      "grad_norm": 3.5291519165039062,
      "learning_rate": 1.3013995485327315e-05,
      "loss": 0.2411,
      "step": 10200
    },
    {
      "epoch": 2.91530967787812,
      "grad_norm": 3.157031536102295,
      "learning_rate": 1.2968848758465012e-05,
      "loss": 0.2286,
      "step": 10250
    },
    {
      "epoch": 2.9295313944393087,
      "grad_norm": 2.580836534500122,
      "learning_rate": 1.292370203160271e-05,
      "loss": 0.2437,
      "step": 10300
    },
    {
      "epoch": 2.9437531110004977,
      "grad_norm": 3.9570014476776123,
      "learning_rate": 1.2878555304740407e-05,
      "loss": 0.2336,
      "step": 10350
    },
    {
      "epoch": 2.957974827561687,
      "grad_norm": 3.5282962322235107,
      "learning_rate": 1.2833408577878106e-05,
      "loss": 0.2282,
      "step": 10400
    },
    {
      "epoch": 2.9721965441228755,
      "grad_norm": 2.4319071769714355,
      "learning_rate": 1.2788261851015802e-05,
      "loss": 0.2322,
      "step": 10450
    },
    {
      "epoch": 2.9864182606840646,
      "grad_norm": 2.6012046337127686,
      "learning_rate": 1.27431151241535e-05,
      "loss": 0.2351,
      "step": 10500
    },
    {
      "epoch": 3.0005688686624477,
      "grad_norm": 3.0908329486846924,
      "learning_rate": 1.2697968397291199e-05,
      "loss": 0.2324,
      "step": 10550
    },
    {
      "epoch": 3.0147905852236363,
      "grad_norm": 3.2306535243988037,
      "learning_rate": 1.2652821670428895e-05,
      "loss": 0.2193,
      "step": 10600
    },
    {
      "epoch": 3.0290123017848254,
      "grad_norm": 2.6925573348999023,
      "learning_rate": 1.2607674943566592e-05,
      "loss": 0.2125,
      "step": 10650
    },
    {
      "epoch": 3.0432340183460145,
      "grad_norm": 4.260341167449951,
      "learning_rate": 1.2562528216704291e-05,
      "loss": 0.2103,
      "step": 10700
    },
    {
      "epoch": 3.057455734907203,
      "grad_norm": 3.797926187515259,
      "learning_rate": 1.2517381489841987e-05,
      "loss": 0.2096,
      "step": 10750
    },
    {
      "epoch": 3.071677451468392,
      "grad_norm": 3.925220251083374,
      "learning_rate": 1.2472234762979685e-05,
      "loss": 0.2125,
      "step": 10800
    },
    {
      "epoch": 3.0858991680295813,
      "grad_norm": 3.6528642177581787,
      "learning_rate": 1.2427088036117384e-05,
      "loss": 0.2173,
      "step": 10850
    },
    {
      "epoch": 3.10012088459077,
      "grad_norm": 3.0743210315704346,
      "learning_rate": 1.2381941309255081e-05,
      "loss": 0.2204,
      "step": 10900
    },
    {
      "epoch": 3.114342601151959,
      "grad_norm": 3.8922171592712402,
      "learning_rate": 1.2336794582392777e-05,
      "loss": 0.2093,
      "step": 10950
    },
    {
      "epoch": 3.128564317713148,
      "grad_norm": 3.81675124168396,
      "learning_rate": 1.2291647855530475e-05,
      "loss": 0.2123,
      "step": 11000
    },
    {
      "epoch": 3.128564317713148,
      "eval_f1_macro": 0.830283101903567,
      "eval_loss": 0.29489392042160034,
      "eval_runtime": 218.0215,
      "eval_samples_per_second": 917.341,
      "eval_steps_per_second": 7.169,
      "step": 11000
    },
    {
      "epoch": 3.142786034274337,
      "grad_norm": 2.2148914337158203,
      "learning_rate": 1.2246501128668174e-05,
      "loss": 0.2095,
      "step": 11050
    },
    {
      "epoch": 3.157007750835526,
      "grad_norm": 4.072431564331055,
      "learning_rate": 1.220135440180587e-05,
      "loss": 0.2211,
      "step": 11100
    },
    {
      "epoch": 3.171229467396715,
      "grad_norm": 3.665724992752075,
      "learning_rate": 1.2156207674943567e-05,
      "loss": 0.2041,
      "step": 11150
    },
    {
      "epoch": 3.1854511839579036,
      "grad_norm": 2.7664780616760254,
      "learning_rate": 1.2111060948081266e-05,
      "loss": 0.2226,
      "step": 11200
    },
    {
      "epoch": 3.1996729005190927,
      "grad_norm": 3.6129908561706543,
      "learning_rate": 1.2065914221218962e-05,
      "loss": 0.2201,
      "step": 11250
    },
    {
      "epoch": 3.213894617080282,
      "grad_norm": 3.3812296390533447,
      "learning_rate": 1.202076749435666e-05,
      "loss": 0.2179,
      "step": 11300
    },
    {
      "epoch": 3.2281163336414704,
      "grad_norm": 3.476102113723755,
      "learning_rate": 1.1975620767494359e-05,
      "loss": 0.2183,
      "step": 11350
    },
    {
      "epoch": 3.2423380502026595,
      "grad_norm": 2.832679510116577,
      "learning_rate": 1.1930474040632055e-05,
      "loss": 0.2165,
      "step": 11400
    },
    {
      "epoch": 3.256559766763848,
      "grad_norm": 2.483846426010132,
      "learning_rate": 1.1885327313769752e-05,
      "loss": 0.205,
      "step": 11450
    },
    {
      "epoch": 3.2707814833250373,
      "grad_norm": 5.382601261138916,
      "learning_rate": 1.1840180586907451e-05,
      "loss": 0.212,
      "step": 11500
    },
    {
      "epoch": 3.2850031998862264,
      "grad_norm": 3.141078472137451,
      "learning_rate": 1.1795033860045149e-05,
      "loss": 0.2151,
      "step": 11550
    },
    {
      "epoch": 3.2992249164474154,
      "grad_norm": 2.875063180923462,
      "learning_rate": 1.1749887133182845e-05,
      "loss": 0.2096,
      "step": 11600
    },
    {
      "epoch": 3.313446633008604,
      "grad_norm": 2.541478395462036,
      "learning_rate": 1.1704740406320542e-05,
      "loss": 0.2184,
      "step": 11650
    },
    {
      "epoch": 3.327668349569793,
      "grad_norm": 2.659566879272461,
      "learning_rate": 1.1659593679458241e-05,
      "loss": 0.2166,
      "step": 11700
    },
    {
      "epoch": 3.341890066130982,
      "grad_norm": 2.221243143081665,
      "learning_rate": 1.1614446952595937e-05,
      "loss": 0.2152,
      "step": 11750
    },
    {
      "epoch": 3.356111782692171,
      "grad_norm": 4.74997091293335,
      "learning_rate": 1.1569300225733635e-05,
      "loss": 0.2154,
      "step": 11800
    },
    {
      "epoch": 3.37033349925336,
      "grad_norm": 3.5048787593841553,
      "learning_rate": 1.1524153498871334e-05,
      "loss": 0.2084,
      "step": 11850
    },
    {
      "epoch": 3.3845552158145487,
      "grad_norm": 3.257707118988037,
      "learning_rate": 1.147900677200903e-05,
      "loss": 0.2148,
      "step": 11900
    },
    {
      "epoch": 3.3987769323757377,
      "grad_norm": 3.0986335277557373,
      "learning_rate": 1.1433860045146727e-05,
      "loss": 0.214,
      "step": 11950
    },
    {
      "epoch": 3.412998648936927,
      "grad_norm": 3.5063514709472656,
      "learning_rate": 1.1388713318284426e-05,
      "loss": 0.2219,
      "step": 12000
    },
    {
      "epoch": 3.412998648936927,
      "eval_f1_macro": 0.8408241926437022,
      "eval_loss": 0.2741829752922058,
      "eval_runtime": 218.0873,
      "eval_samples_per_second": 917.064,
      "eval_steps_per_second": 7.167,
      "step": 12000
    },
    {
      "epoch": 3.4272203654981155,
      "grad_norm": 3.06364107131958,
      "learning_rate": 1.1343566591422124e-05,
      "loss": 0.2124,
      "step": 12050
    },
    {
      "epoch": 3.4414420820593046,
      "grad_norm": 8.380749702453613,
      "learning_rate": 1.129841986455982e-05,
      "loss": 0.2064,
      "step": 12100
    },
    {
      "epoch": 3.4556637986204937,
      "grad_norm": 3.115405559539795,
      "learning_rate": 1.1253273137697519e-05,
      "loss": 0.1992,
      "step": 12150
    },
    {
      "epoch": 3.4698855151816823,
      "grad_norm": 2.8828935623168945,
      "learning_rate": 1.1208126410835216e-05,
      "loss": 0.211,
      "step": 12200
    },
    {
      "epoch": 3.4841072317428714,
      "grad_norm": 3.648852586746216,
      "learning_rate": 1.1162979683972912e-05,
      "loss": 0.2055,
      "step": 12250
    },
    {
      "epoch": 3.4983289483040605,
      "grad_norm": 3.0625364780426025,
      "learning_rate": 1.111783295711061e-05,
      "loss": 0.2185,
      "step": 12300
    },
    {
      "epoch": 3.512550664865249,
      "grad_norm": 4.903135776519775,
      "learning_rate": 1.1072686230248309e-05,
      "loss": 0.2066,
      "step": 12350
    },
    {
      "epoch": 3.5267723814264382,
      "grad_norm": 3.9743824005126953,
      "learning_rate": 1.1027539503386004e-05,
      "loss": 0.2175,
      "step": 12400
    },
    {
      "epoch": 3.5409940979876273,
      "grad_norm": 3.5226337909698486,
      "learning_rate": 1.0982392776523702e-05,
      "loss": 0.2093,
      "step": 12450
    },
    {
      "epoch": 3.555215814548816,
      "grad_norm": 3.6144144535064697,
      "learning_rate": 1.0937246049661401e-05,
      "loss": 0.221,
      "step": 12500
    },
    {
      "epoch": 3.569437531110005,
      "grad_norm": 3.728797674179077,
      "learning_rate": 1.0892099322799099e-05,
      "loss": 0.2132,
      "step": 12550
    },
    {
      "epoch": 3.5836592476711937,
      "grad_norm": 2.994102954864502,
      "learning_rate": 1.0846952595936794e-05,
      "loss": 0.2009,
      "step": 12600
    },
    {
      "epoch": 3.597880964232383,
      "grad_norm": 2.7955565452575684,
      "learning_rate": 1.0801805869074494e-05,
      "loss": 0.2161,
      "step": 12650
    },
    {
      "epoch": 3.612102680793572,
      "grad_norm": 3.0637705326080322,
      "learning_rate": 1.0756659142212191e-05,
      "loss": 0.2157,
      "step": 12700
    },
    {
      "epoch": 3.626324397354761,
      "grad_norm": 2.9101765155792236,
      "learning_rate": 1.0711512415349887e-05,
      "loss": 0.2123,
      "step": 12750
    },
    {
      "epoch": 3.6405461139159496,
      "grad_norm": 4.3527445793151855,
      "learning_rate": 1.0666365688487586e-05,
      "loss": 0.2191,
      "step": 12800
    },
    {
      "epoch": 3.6547678304771387,
      "grad_norm": 2.4758191108703613,
      "learning_rate": 1.0621218961625284e-05,
      "loss": 0.2108,
      "step": 12850
    },
    {
      "epoch": 3.6689895470383274,
      "grad_norm": 3.304086685180664,
      "learning_rate": 1.057607223476298e-05,
      "loss": 0.207,
      "step": 12900
    },
    {
      "epoch": 3.6832112635995164,
      "grad_norm": 2.3426098823547363,
      "learning_rate": 1.0530925507900679e-05,
      "loss": 0.2104,
      "step": 12950
    },
    {
      "epoch": 3.6974329801607055,
      "grad_norm": 3.6614291667938232,
      "learning_rate": 1.0485778781038376e-05,
      "loss": 0.2055,
      "step": 13000
    },
    {
      "epoch": 3.6974329801607055,
      "eval_f1_macro": 0.8316096209968833,
      "eval_loss": 0.30003252625465393,
      "eval_runtime": 218.0265,
      "eval_samples_per_second": 917.32,
      "eval_steps_per_second": 7.169,
      "step": 13000
    },
    {
      "epoch": 3.711654696721894,
      "grad_norm": 2.4059743881225586,
      "learning_rate": 1.0440632054176074e-05,
      "loss": 0.226,
      "step": 13050
    },
    {
      "epoch": 3.7258764132830833,
      "grad_norm": 2.552032470703125,
      "learning_rate": 1.039548532731377e-05,
      "loss": 0.213,
      "step": 13100
    },
    {
      "epoch": 3.7400981298442724,
      "grad_norm": 2.320686101913452,
      "learning_rate": 1.0350338600451469e-05,
      "loss": 0.2112,
      "step": 13150
    },
    {
      "epoch": 3.754319846405461,
      "grad_norm": 2.74792742729187,
      "learning_rate": 1.0305191873589166e-05,
      "loss": 0.208,
      "step": 13200
    },
    {
      "epoch": 3.76854156296665,
      "grad_norm": 3.812765598297119,
      "learning_rate": 1.0260045146726862e-05,
      "loss": 0.2076,
      "step": 13250
    },
    {
      "epoch": 3.782763279527839,
      "grad_norm": 2.489713191986084,
      "learning_rate": 1.0214898419864561e-05,
      "loss": 0.2125,
      "step": 13300
    },
    {
      "epoch": 3.796984996089028,
      "grad_norm": 2.5565185546875,
      "learning_rate": 1.0169751693002259e-05,
      "loss": 0.206,
      "step": 13350
    },
    {
      "epoch": 3.811206712650217,
      "grad_norm": 3.9055278301239014,
      "learning_rate": 1.0124604966139954e-05,
      "loss": 0.2147,
      "step": 13400
    },
    {
      "epoch": 3.8254284292114056,
      "grad_norm": 3.066721200942993,
      "learning_rate": 1.0079458239277654e-05,
      "loss": 0.2097,
      "step": 13450
    },
    {
      "epoch": 3.8396501457725947,
      "grad_norm": 2.826639175415039,
      "learning_rate": 1.0034311512415351e-05,
      "loss": 0.213,
      "step": 13500
    },
    {
      "epoch": 3.8538718623337838,
      "grad_norm": 2.372081995010376,
      "learning_rate": 9.989164785553049e-06,
      "loss": 0.2167,
      "step": 13550
    },
    {
      "epoch": 3.868093578894973,
      "grad_norm": 2.1676547527313232,
      "learning_rate": 9.944018058690746e-06,
      "loss": 0.2084,
      "step": 13600
    },
    {
      "epoch": 3.8823152954561615,
      "grad_norm": 2.342560052871704,
      "learning_rate": 9.898871331828444e-06,
      "loss": 0.2061,
      "step": 13650
    },
    {
      "epoch": 3.8965370120173506,
      "grad_norm": 3.581909418106079,
      "learning_rate": 9.853724604966141e-06,
      "loss": 0.2059,
      "step": 13700
    },
    {
      "epoch": 3.9107587285785392,
      "grad_norm": 3.6617562770843506,
      "learning_rate": 9.808577878103839e-06,
      "loss": 0.2082,
      "step": 13750
    },
    {
      "epoch": 3.9249804451397283,
      "grad_norm": 3.2724671363830566,
      "learning_rate": 9.763431151241536e-06,
      "loss": 0.208,
      "step": 13800
    },
    {
      "epoch": 3.9392021617009174,
      "grad_norm": 3.721395969390869,
      "learning_rate": 9.718284424379234e-06,
      "loss": 0.2057,
      "step": 13850
    },
    {
      "epoch": 3.9534238782621065,
      "grad_norm": 3.4008820056915283,
      "learning_rate": 9.673137697516931e-06,
      "loss": 0.2025,
      "step": 13900
    },
    {
      "epoch": 3.967645594823295,
      "grad_norm": 2.8925986289978027,
      "learning_rate": 9.627990970654629e-06,
      "loss": 0.21,
      "step": 13950
    },
    {
      "epoch": 3.9818673113844842,
      "grad_norm": 3.264054536819458,
      "learning_rate": 9.582844243792326e-06,
      "loss": 0.2133,
      "step": 14000
    },
    {
      "epoch": 3.9818673113844842,
      "eval_f1_macro": 0.8342255467413469,
      "eval_loss": 0.2816358804702759,
      "eval_runtime": 217.9426,
      "eval_samples_per_second": 917.673,
      "eval_steps_per_second": 7.172,
      "step": 14000
    },
    {
      "epoch": 3.996089027945673,
      "grad_norm": 3.255805492401123,
      "learning_rate": 9.537697516930024e-06,
      "loss": 0.2085,
      "step": 14050
    },
    {
      "epoch": 4.010239635924056,
      "grad_norm": 2.892794609069824,
      "learning_rate": 9.492550790067721e-06,
      "loss": 0.188,
      "step": 14100
    },
    {
      "epoch": 4.024461352485245,
      "grad_norm": 2.962752342224121,
      "learning_rate": 9.447404063205419e-06,
      "loss": 0.1904,
      "step": 14150
    },
    {
      "epoch": 4.038683069046434,
      "grad_norm": 2.2758448123931885,
      "learning_rate": 9.402257336343116e-06,
      "loss": 0.1986,
      "step": 14200
    },
    {
      "epoch": 4.052904785607623,
      "grad_norm": 3.2419750690460205,
      "learning_rate": 9.357110609480814e-06,
      "loss": 0.1956,
      "step": 14250
    },
    {
      "epoch": 4.067126502168811,
      "grad_norm": 3.0838098526000977,
      "learning_rate": 9.311963882618511e-06,
      "loss": 0.1903,
      "step": 14300
    },
    {
      "epoch": 4.0813482187300005,
      "grad_norm": 3.9433443546295166,
      "learning_rate": 9.266817155756209e-06,
      "loss": 0.1906,
      "step": 14350
    },
    {
      "epoch": 4.09556993529119,
      "grad_norm": 2.987553834915161,
      "learning_rate": 9.221670428893906e-06,
      "loss": 0.1897,
      "step": 14400
    },
    {
      "epoch": 4.109791651852379,
      "grad_norm": 2.9111084938049316,
      "learning_rate": 9.176523702031604e-06,
      "loss": 0.1896,
      "step": 14450
    },
    {
      "epoch": 4.124013368413568,
      "grad_norm": 3.288834571838379,
      "learning_rate": 9.131376975169301e-06,
      "loss": 0.1848,
      "step": 14500
    },
    {
      "epoch": 4.138235084974756,
      "grad_norm": 3.6969573497772217,
      "learning_rate": 9.086230248306999e-06,
      "loss": 0.1884,
      "step": 14550
    },
    {
      "epoch": 4.152456801535945,
      "grad_norm": 3.648275852203369,
      "learning_rate": 9.041083521444696e-06,
      "loss": 0.1869,
      "step": 14600
    },
    {
      "epoch": 4.166678518097134,
      "grad_norm": 3.203768730163574,
      "learning_rate": 8.995936794582394e-06,
      "loss": 0.1828,
      "step": 14650
    },
    {
      "epoch": 4.180900234658323,
      "grad_norm": 3.638401746749878,
      "learning_rate": 8.950790067720091e-06,
      "loss": 0.1848,
      "step": 14700
    },
    {
      "epoch": 4.195121951219512,
      "grad_norm": 3.9101617336273193,
      "learning_rate": 8.905643340857789e-06,
      "loss": 0.1873,
      "step": 14750
    },
    {
      "epoch": 4.2093436677807015,
      "grad_norm": 3.8993618488311768,
      "learning_rate": 8.860496613995486e-06,
      "loss": 0.189,
      "step": 14800
    },
    {
      "epoch": 4.22356538434189,
      "grad_norm": 3.1992154121398926,
      "learning_rate": 8.815349887133184e-06,
      "loss": 0.1908,
      "step": 14850
    },
    {
      "epoch": 4.237787100903079,
      "grad_norm": 1.8245869874954224,
      "learning_rate": 8.770203160270881e-06,
      "loss": 0.1872,
      "step": 14900
    },
    {
      "epoch": 4.252008817464268,
      "grad_norm": 2.95088529586792,
      "learning_rate": 8.725056433408579e-06,
      "loss": 0.192,
      "step": 14950
    },
    {
      "epoch": 4.266230534025457,
      "grad_norm": 2.958621025085449,
      "learning_rate": 8.679909706546276e-06,
      "loss": 0.1905,
      "step": 15000
    },
    {
      "epoch": 4.266230534025457,
      "eval_f1_macro": 0.8372308730780154,
      "eval_loss": 0.28810879588127136,
      "eval_runtime": 217.9851,
      "eval_samples_per_second": 917.494,
      "eval_steps_per_second": 7.17,
      "step": 15000
    },
    {
      "epoch": 4.280452250586646,
      "grad_norm": 3.217214345932007,
      "learning_rate": 8.634762979683974e-06,
      "loss": 0.1898,
      "step": 15050
    },
    {
      "epoch": 4.294673967147835,
      "grad_norm": 3.2871577739715576,
      "learning_rate": 8.589616252821671e-06,
      "loss": 0.1871,
      "step": 15100
    },
    {
      "epoch": 4.308895683709023,
      "grad_norm": 3.291879653930664,
      "learning_rate": 8.544469525959369e-06,
      "loss": 0.1909,
      "step": 15150
    },
    {
      "epoch": 4.323117400270212,
      "grad_norm": 3.477689027786255,
      "learning_rate": 8.499322799097066e-06,
      "loss": 0.191,
      "step": 15200
    },
    {
      "epoch": 4.3373391168314015,
      "grad_norm": 2.812965154647827,
      "learning_rate": 8.454176072234764e-06,
      "loss": 0.1959,
      "step": 15250
    },
    {
      "epoch": 4.351560833392591,
      "grad_norm": 2.866145372390747,
      "learning_rate": 8.409029345372461e-06,
      "loss": 0.2008,
      "step": 15300
    },
    {
      "epoch": 4.36578254995378,
      "grad_norm": 2.2643516063690186,
      "learning_rate": 8.363882618510159e-06,
      "loss": 0.183,
      "step": 15350
    },
    {
      "epoch": 4.380004266514969,
      "grad_norm": 2.425800323486328,
      "learning_rate": 8.318735891647856e-06,
      "loss": 0.187,
      "step": 15400
    },
    {
      "epoch": 4.394225983076157,
      "grad_norm": 3.3976354598999023,
      "learning_rate": 8.273589164785554e-06,
      "loss": 0.1994,
      "step": 15450
    },
    {
      "epoch": 4.408447699637346,
      "grad_norm": 3.259050130844116,
      "learning_rate": 8.228442437923251e-06,
      "loss": 0.1956,
      "step": 15500
    },
    {
      "epoch": 4.422669416198535,
      "grad_norm": 2.4994876384735107,
      "learning_rate": 8.183295711060949e-06,
      "loss": 0.1929,
      "step": 15550
    },
    {
      "epoch": 4.436891132759724,
      "grad_norm": 3.3311269283294678,
      "learning_rate": 8.138148984198646e-06,
      "loss": 0.1935,
      "step": 15600
    },
    {
      "epoch": 4.451112849320913,
      "grad_norm": 4.349649906158447,
      "learning_rate": 8.093002257336344e-06,
      "loss": 0.2017,
      "step": 15650
    },
    {
      "epoch": 4.465334565882102,
      "grad_norm": 2.681615114212036,
      "learning_rate": 8.047855530474041e-06,
      "loss": 0.1978,
      "step": 15700
    },
    {
      "epoch": 4.479556282443291,
      "grad_norm": 2.8961968421936035,
      "learning_rate": 8.002708803611739e-06,
      "loss": 0.1828,
      "step": 15750
    },
    {
      "epoch": 4.49377799900448,
      "grad_norm": 3.970378875732422,
      "learning_rate": 7.957562076749436e-06,
      "loss": 0.1881,
      "step": 15800
    },
    {
      "epoch": 4.507999715565669,
      "grad_norm": 3.9275338649749756,
      "learning_rate": 7.912415349887134e-06,
      "loss": 0.1934,
      "step": 15850
    },
    {
      "epoch": 4.522221432126858,
      "grad_norm": 4.324541091918945,
      "learning_rate": 7.867268623024831e-06,
      "loss": 0.1905,
      "step": 15900
    },
    {
      "epoch": 4.536443148688047,
      "grad_norm": 3.7046492099761963,
      "learning_rate": 7.822121896162529e-06,
      "loss": 0.1894,
      "step": 15950
    },
    {
      "epoch": 4.550664865249235,
      "grad_norm": 3.9187357425689697,
      "learning_rate": 7.776975169300226e-06,
      "loss": 0.1906,
      "step": 16000
    },
    {
      "epoch": 4.550664865249235,
      "eval_f1_macro": 0.8353309236655874,
      "eval_loss": 0.3019372522830963,
      "eval_runtime": 218.0222,
      "eval_samples_per_second": 917.338,
      "eval_steps_per_second": 7.169,
      "step": 16000
    },
    {
      "epoch": 4.564886581810424,
      "grad_norm": 2.817697763442993,
      "learning_rate": 7.731828442437924e-06,
      "loss": 0.1858,
      "step": 16050
    },
    {
      "epoch": 4.579108298371613,
      "grad_norm": 3.9191293716430664,
      "learning_rate": 7.686681715575621e-06,
      "loss": 0.1964,
      "step": 16100
    },
    {
      "epoch": 4.5933300149328025,
      "grad_norm": 2.7693519592285156,
      "learning_rate": 7.64153498871332e-06,
      "loss": 0.188,
      "step": 16150
    },
    {
      "epoch": 4.6075517314939916,
      "grad_norm": 4.8587870597839355,
      "learning_rate": 7.596388261851017e-06,
      "loss": 0.1887,
      "step": 16200
    },
    {
      "epoch": 4.621773448055181,
      "grad_norm": Infinity,
      "learning_rate": 7.5512415349887135e-06,
      "loss": 0.1919,
      "step": 16250
    },
    {
      "epoch": 4.635995164616369,
      "grad_norm": 2.9725329875946045,
      "learning_rate": 7.506094808126412e-06,
      "loss": 0.1901,
      "step": 16300
    },
    {
      "epoch": 4.650216881177558,
      "grad_norm": 4.034248352050781,
      "learning_rate": 7.4609480812641085e-06,
      "loss": 0.1934,
      "step": 16350
    },
    {
      "epoch": 4.664438597738747,
      "grad_norm": 2.3192625045776367,
      "learning_rate": 7.415801354401806e-06,
      "loss": 0.1986,
      "step": 16400
    },
    {
      "epoch": 4.678660314299936,
      "grad_norm": 5.001041412353516,
      "learning_rate": 7.370654627539504e-06,
      "loss": 0.1887,
      "step": 16450
    },
    {
      "epoch": 4.692882030861125,
      "grad_norm": 3.076477527618408,
      "learning_rate": 7.325507900677201e-06,
      "loss": 0.1853,
      "step": 16500
    },
    {
      "epoch": 4.707103747422314,
      "grad_norm": 2.9928624629974365,
      "learning_rate": 7.280361173814899e-06,
      "loss": 0.1868,
      "step": 16550
    },
    {
      "epoch": 4.7213254639835025,
      "grad_norm": 2.534738063812256,
      "learning_rate": 7.235214446952597e-06,
      "loss": 0.1927,
      "step": 16600
    },
    {
      "epoch": 4.735547180544692,
      "grad_norm": 3.687946081161499,
      "learning_rate": 7.1900677200902935e-06,
      "loss": 0.1913,
      "step": 16650
    },
    {
      "epoch": 4.749768897105881,
      "grad_norm": 2.740347385406494,
      "learning_rate": 7.144920993227992e-06,
      "loss": 0.193,
      "step": 16700
    },
    {
      "epoch": 4.76399061366707,
      "grad_norm": 3.5835976600646973,
      "learning_rate": 7.0997742663656885e-06,
      "loss": 0.1871,
      "step": 16750
    },
    {
      "epoch": 4.778212330228259,
      "grad_norm": 4.166302680969238,
      "learning_rate": 7.054627539503387e-06,
      "loss": 0.1921,
      "step": 16800
    },
    {
      "epoch": 4.792434046789447,
      "grad_norm": 4.635613918304443,
      "learning_rate": 7.009480812641084e-06,
      "loss": 0.1847,
      "step": 16850
    },
    {
      "epoch": 4.806655763350636,
      "grad_norm": 3.0316178798675537,
      "learning_rate": 6.964334085778781e-06,
      "loss": 0.1947,
      "step": 16900
    },
    {
      "epoch": 4.820877479911825,
      "grad_norm": 3.2771315574645996,
      "learning_rate": 6.919187358916479e-06,
      "loss": 0.194,
      "step": 16950
    },
    {
      "epoch": 4.835099196473014,
      "grad_norm": 3.430598020553589,
      "learning_rate": 6.874040632054176e-06,
      "loss": 0.1893,
      "step": 17000
    },
    {
      "epoch": 4.835099196473014,
      "eval_f1_macro": 0.8368518619304525,
      "eval_loss": 0.28814035654067993,
      "eval_runtime": 218.0273,
      "eval_samples_per_second": 917.317,
      "eval_steps_per_second": 7.169,
      "step": 17000
    },
    {
      "epoch": 4.849320913034203,
      "grad_norm": 3.287216901779175,
      "learning_rate": 6.828893905191874e-06,
      "loss": 0.198,
      "step": 17050
    },
    {
      "epoch": 4.8635426295953925,
      "grad_norm": 2.8891103267669678,
      "learning_rate": 6.783747178329572e-06,
      "loss": 0.1856,
      "step": 17100
    },
    {
      "epoch": 4.877764346156581,
      "grad_norm": 3.9922428131103516,
      "learning_rate": 6.7386004514672685e-06,
      "loss": 0.197,
      "step": 17150
    },
    {
      "epoch": 4.89198606271777,
      "grad_norm": 3.1599888801574707,
      "learning_rate": 6.693453724604967e-06,
      "loss": 0.1832,
      "step": 17200
    },
    {
      "epoch": 4.906207779278959,
      "grad_norm": 5.023273468017578,
      "learning_rate": 6.648306997742664e-06,
      "loss": 0.1966,
      "step": 17250
    },
    {
      "epoch": 4.920429495840148,
      "grad_norm": 4.312615871429443,
      "learning_rate": 6.603160270880362e-06,
      "loss": 0.1862,
      "step": 17300
    },
    {
      "epoch": 4.934651212401337,
      "grad_norm": 3.775996446609497,
      "learning_rate": 6.558013544018059e-06,
      "loss": 0.1853,
      "step": 17350
    },
    {
      "epoch": 4.948872928962526,
      "grad_norm": 3.6867024898529053,
      "learning_rate": 6.512866817155756e-06,
      "loss": 0.196,
      "step": 17400
    },
    {
      "epoch": 4.963094645523714,
      "grad_norm": 2.9679129123687744,
      "learning_rate": 6.467720090293454e-06,
      "loss": 0.1845,
      "step": 17450
    },
    {
      "epoch": 4.9773163620849035,
      "grad_norm": 4.289106369018555,
      "learning_rate": 6.422573363431152e-06,
      "loss": 0.1851,
      "step": 17500
    },
    {
      "epoch": 4.991538078646093,
      "grad_norm": 3.625459909439087,
      "learning_rate": 6.37742663656885e-06,
      "loss": 0.1838,
      "step": 17550
    },
    {
      "epoch": 5.005688686624476,
      "grad_norm": 2.8363962173461914,
      "learning_rate": 6.332279909706547e-06,
      "loss": 0.182,
      "step": 17600
    },
    {
      "epoch": 5.019910403185665,
      "grad_norm": 2.746411085128784,
      "learning_rate": 6.287133182844244e-06,
      "loss": 0.1739,
      "step": 17650
    },
    {
      "epoch": 5.034132119746854,
      "grad_norm": 3.254483222961426,
      "learning_rate": 6.241986455981942e-06,
      "loss": 0.1676,
      "step": 17700
    },
    {
      "epoch": 5.048353836308042,
      "grad_norm": 3.584299325942993,
      "learning_rate": 6.196839729119639e-06,
      "loss": 0.1741,
      "step": 17750
    },
    {
      "epoch": 5.062575552869231,
      "grad_norm": 2.6933116912841797,
      "learning_rate": 6.151693002257338e-06,
      "loss": 0.1757,
      "step": 17800
    },
    {
      "epoch": 5.07679726943042,
      "grad_norm": 4.438282012939453,
      "learning_rate": 6.106546275395034e-06,
      "loss": 0.1717,
      "step": 17850
    },
    {
      "epoch": 5.091018985991609,
      "grad_norm": 5.910329341888428,
      "learning_rate": 6.061399548532732e-06,
      "loss": 0.1667,
      "step": 17900
    },
    {
      "epoch": 5.105240702552798,
      "grad_norm": 3.551132917404175,
      "learning_rate": 6.016252821670429e-06,
      "loss": 0.1704,
      "step": 17950
    },
    {
      "epoch": 5.1194624191139875,
      "grad_norm": 4.038816452026367,
      "learning_rate": 5.971106094808127e-06,
      "loss": 0.1753,
      "step": 18000
    },
    {
      "epoch": 5.1194624191139875,
      "eval_f1_macro": 0.8443488931940012,
      "eval_loss": 0.27700862288475037,
      "eval_runtime": 217.8397,
      "eval_samples_per_second": 918.106,
      "eval_steps_per_second": 7.175,
      "step": 18000
    },
    {
      "epoch": 5.133684135675176,
      "grad_norm": 3.8022873401641846,
      "learning_rate": 5.925959367945825e-06,
      "loss": 0.1745,
      "step": 18050
    },
    {
      "epoch": 5.147905852236365,
      "grad_norm": 3.0771901607513428,
      "learning_rate": 5.880812641083522e-06,
      "loss": 0.1743,
      "step": 18100
    },
    {
      "epoch": 5.162127568797554,
      "grad_norm": 4.098248481750488,
      "learning_rate": 5.835665914221219e-06,
      "loss": 0.1686,
      "step": 18150
    },
    {
      "epoch": 5.176349285358743,
      "grad_norm": 3.5727450847625732,
      "learning_rate": 5.790519187358918e-06,
      "loss": 0.178,
      "step": 18200
    },
    {
      "epoch": 5.190571001919932,
      "grad_norm": 5.660904407501221,
      "learning_rate": 5.745372460496614e-06,
      "loss": 0.1768,
      "step": 18250
    },
    {
      "epoch": 5.204792718481121,
      "grad_norm": 3.7298383712768555,
      "learning_rate": 5.700225733634313e-06,
      "loss": 0.179,
      "step": 18300
    },
    {
      "epoch": 5.219014435042309,
      "grad_norm": 4.159589767456055,
      "learning_rate": 5.655079006772009e-06,
      "loss": 0.1686,
      "step": 18350
    },
    {
      "epoch": 5.233236151603498,
      "grad_norm": 3.923496723175049,
      "learning_rate": 5.609932279909707e-06,
      "loss": 0.1786,
      "step": 18400
    },
    {
      "epoch": 5.2474578681646875,
      "grad_norm": 3.200547218322754,
      "learning_rate": 5.564785553047405e-06,
      "loss": 0.1723,
      "step": 18450
    },
    {
      "epoch": 5.261679584725877,
      "grad_norm": 2.834465980529785,
      "learning_rate": 5.519638826185102e-06,
      "loss": 0.1741,
      "step": 18500
    },
    {
      "epoch": 5.275901301287066,
      "grad_norm": 3.2218453884124756,
      "learning_rate": 5.474492099322799e-06,
      "loss": 0.1751,
      "step": 18550
    },
    {
      "epoch": 5.290123017848254,
      "grad_norm": 4.535356044769287,
      "learning_rate": 5.429345372460498e-06,
      "loss": 0.1662,
      "step": 18600
    },
    {
      "epoch": 5.304344734409443,
      "grad_norm": 2.566972255706787,
      "learning_rate": 5.384198645598194e-06,
      "loss": 0.1773,
      "step": 18650
    },
    {
      "epoch": 5.318566450970632,
      "grad_norm": 3.687056303024292,
      "learning_rate": 5.339051918735893e-06,
      "loss": 0.1722,
      "step": 18700
    },
    {
      "epoch": 5.332788167531821,
      "grad_norm": 2.4019150733947754,
      "learning_rate": 5.293905191873589e-06,
      "loss": 0.1885,
      "step": 18750
    },
    {
      "epoch": 5.34700988409301,
      "grad_norm": 3.132521867752075,
      "learning_rate": 5.248758465011287e-06,
      "loss": 0.1732,
      "step": 18800
    },
    {
      "epoch": 5.361231600654199,
      "grad_norm": 3.511523962020874,
      "learning_rate": 5.203611738148985e-06,
      "loss": 0.171,
      "step": 18850
    },
    {
      "epoch": 5.3754533172153875,
      "grad_norm": 3.9591050148010254,
      "learning_rate": 5.158465011286682e-06,
      "loss": 0.1796,
      "step": 18900
    },
    {
      "epoch": 5.389675033776577,
      "grad_norm": 3.9228246212005615,
      "learning_rate": 5.11331828442438e-06,
      "loss": 0.1704,
      "step": 18950
    },
    {
      "epoch": 5.403896750337766,
      "grad_norm": 4.541815757751465,
      "learning_rate": 5.068171557562077e-06,
      "loss": 0.1779,
      "step": 19000
    },
    {
      "epoch": 5.403896750337766,
      "eval_f1_macro": 0.836110233990619,
      "eval_loss": 0.31104856729507446,
      "eval_runtime": 217.8426,
      "eval_samples_per_second": 918.094,
      "eval_steps_per_second": 7.175,
      "step": 19000
    },
    {
      "epoch": 5.418118466898955,
      "grad_norm": 4.096629619598389,
      "learning_rate": 5.023024830699774e-06,
      "loss": 0.1772,
      "step": 19050
    },
    {
      "epoch": 5.432340183460144,
      "grad_norm": 3.1502840518951416,
      "learning_rate": 4.977878103837473e-06,
      "loss": 0.1717,
      "step": 19100
    },
    {
      "epoch": 5.446561900021333,
      "grad_norm": 3.935368061065674,
      "learning_rate": 4.932731376975169e-06,
      "loss": 0.1759,
      "step": 19150
    },
    {
      "epoch": 5.460783616582521,
      "grad_norm": 3.837794303894043,
      "learning_rate": 4.887584650112867e-06,
      "loss": 0.1765,
      "step": 19200
    },
    {
      "epoch": 5.47500533314371,
      "grad_norm": 3.584901809692383,
      "learning_rate": 4.842437923250565e-06,
      "loss": 0.1792,
      "step": 19250
    },
    {
      "epoch": 5.489227049704899,
      "grad_norm": 3.4820358753204346,
      "learning_rate": 4.797291196388263e-06,
      "loss": 0.1698,
      "step": 19300
    },
    {
      "epoch": 5.5034487662660885,
      "grad_norm": 3.293713331222534,
      "learning_rate": 4.75214446952596e-06,
      "loss": 0.177,
      "step": 19350
    },
    {
      "epoch": 5.517670482827278,
      "grad_norm": 3.562366247177124,
      "learning_rate": 4.706997742663657e-06,
      "loss": 0.168,
      "step": 19400
    },
    {
      "epoch": 5.531892199388466,
      "grad_norm": 2.39019513130188,
      "learning_rate": 4.661851015801355e-06,
      "loss": 0.1668,
      "step": 19450
    },
    {
      "epoch": 5.546113915949655,
      "grad_norm": 3.0816285610198975,
      "learning_rate": 4.6167042889390526e-06,
      "loss": 0.1768,
      "step": 19500
    },
    {
      "epoch": 5.560335632510844,
      "grad_norm": 3.1494202613830566,
      "learning_rate": 4.57155756207675e-06,
      "loss": 0.1749,
      "step": 19550
    },
    {
      "epoch": 5.574557349072033,
      "grad_norm": 3.2250170707702637,
      "learning_rate": 4.5264108352144476e-06,
      "loss": 0.1701,
      "step": 19600
    },
    {
      "epoch": 5.588779065633222,
      "grad_norm": 3.451178550720215,
      "learning_rate": 4.481264108352145e-06,
      "loss": 0.1728,
      "step": 19650
    },
    {
      "epoch": 5.603000782194411,
      "grad_norm": 2.810431480407715,
      "learning_rate": 4.4361173814898426e-06,
      "loss": 0.174,
      "step": 19700
    },
    {
      "epoch": 5.617222498755599,
      "grad_norm": 2.664231538772583,
      "learning_rate": 4.39097065462754e-06,
      "loss": 0.1717,
      "step": 19750
    },
    {
      "epoch": 5.6314442153167885,
      "grad_norm": 2.878858804702759,
      "learning_rate": 4.3458239277652376e-06,
      "loss": 0.1759,
      "step": 19800
    },
    {
      "epoch": 5.645665931877978,
      "grad_norm": 2.9958882331848145,
      "learning_rate": 4.300677200902934e-06,
      "loss": 0.1715,
      "step": 19850
    },
    {
      "epoch": 5.659887648439167,
      "grad_norm": 3.395160675048828,
      "learning_rate": 4.2555304740406326e-06,
      "loss": 0.1746,
      "step": 19900
    },
    {
      "epoch": 5.674109365000356,
      "grad_norm": 2.7741870880126953,
      "learning_rate": 4.21038374717833e-06,
      "loss": 0.1774,
      "step": 19950
    },
    {
      "epoch": 5.688331081561545,
      "grad_norm": 2.8433878421783447,
      "learning_rate": 4.1652370203160276e-06,
      "loss": 0.1728,
      "step": 20000
    },
    {
      "epoch": 5.688331081561545,
      "eval_f1_macro": 0.8393678101507278,
      "eval_loss": 0.2951284646987915,
      "eval_runtime": 217.954,
      "eval_samples_per_second": 917.625,
      "eval_steps_per_second": 7.171,
      "step": 20000
    },
    {
      "epoch": 5.702552798122733,
      "grad_norm": 3.5822951793670654,
      "learning_rate": 4.120090293453725e-06,
      "loss": 0.1721,
      "step": 20050
    },
    {
      "epoch": 5.716774514683922,
      "grad_norm": 3.0777621269226074,
      "learning_rate": 4.0749435665914225e-06,
      "loss": 0.1658,
      "step": 20100
    },
    {
      "epoch": 5.730996231245111,
      "grad_norm": 3.809581995010376,
      "learning_rate": 4.02979683972912e-06,
      "loss": 0.1729,
      "step": 20150
    },
    {
      "epoch": 5.7452179478063,
      "grad_norm": 3.7974905967712402,
      "learning_rate": 3.9846501128668175e-06,
      "loss": 0.171,
      "step": 20200
    },
    {
      "epoch": 5.759439664367489,
      "grad_norm": 3.1071996688842773,
      "learning_rate": 3.939503386004515e-06,
      "loss": 0.1732,
      "step": 20250
    },
    {
      "epoch": 5.773661380928678,
      "grad_norm": 2.7197153568267822,
      "learning_rate": 3.8943566591422125e-06,
      "loss": 0.1681,
      "step": 20300
    },
    {
      "epoch": 5.787883097489867,
      "grad_norm": 3.9625203609466553,
      "learning_rate": 3.84920993227991e-06,
      "loss": 0.1703,
      "step": 20350
    },
    {
      "epoch": 5.802104814051056,
      "grad_norm": 3.6182761192321777,
      "learning_rate": 3.8040632054176075e-06,
      "loss": 0.1753,
      "step": 20400
    },
    {
      "epoch": 5.816326530612245,
      "grad_norm": 3.980893611907959,
      "learning_rate": 3.758916478555305e-06,
      "loss": 0.1661,
      "step": 20450
    },
    {
      "epoch": 5.830548247173434,
      "grad_norm": 3.0739047527313232,
      "learning_rate": 3.7137697516930025e-06,
      "loss": 0.1747,
      "step": 20500
    },
    {
      "epoch": 5.844769963734623,
      "grad_norm": 3.4066030979156494,
      "learning_rate": 3.6686230248307005e-06,
      "loss": 0.1657,
      "step": 20550
    },
    {
      "epoch": 5.858991680295812,
      "grad_norm": 3.5953032970428467,
      "learning_rate": 3.6234762979683975e-06,
      "loss": 0.1696,
      "step": 20600
    },
    {
      "epoch": 5.873213396857,
      "grad_norm": 2.5494637489318848,
      "learning_rate": 3.578329571106095e-06,
      "loss": 0.1724,
      "step": 20650
    },
    {
      "epoch": 5.8874351134181895,
      "grad_norm": 2.8456735610961914,
      "learning_rate": 3.5331828442437925e-06,
      "loss": 0.1683,
      "step": 20700
    },
    {
      "epoch": 5.901656829979379,
      "grad_norm": 2.9062724113464355,
      "learning_rate": 3.4880361173814904e-06,
      "loss": 0.1773,
      "step": 20750
    },
    {
      "epoch": 5.915878546540568,
      "grad_norm": 3.6684889793395996,
      "learning_rate": 3.442889390519188e-06,
      "loss": 0.165,
      "step": 20800
    },
    {
      "epoch": 5.930100263101757,
      "grad_norm": 3.8904430866241455,
      "learning_rate": 3.397742663656885e-06,
      "loss": 0.1738,
      "step": 20850
    },
    {
      "epoch": 5.944321979662945,
      "grad_norm": 3.032545328140259,
      "learning_rate": 3.3525959367945825e-06,
      "loss": 0.1706,
      "step": 20900
    },
    {
      "epoch": 5.958543696224134,
      "grad_norm": 4.004833698272705,
      "learning_rate": 3.3074492099322804e-06,
      "loss": 0.1757,
      "step": 20950
    },
    {
      "epoch": 5.972765412785323,
      "grad_norm": 3.2267322540283203,
      "learning_rate": 3.262302483069978e-06,
      "loss": 0.1676,
      "step": 21000
    },
    {
      "epoch": 5.972765412785323,
      "eval_f1_macro": 0.8390547788174343,
      "eval_loss": 0.2942323684692383,
      "eval_runtime": 217.9501,
      "eval_samples_per_second": 917.641,
      "eval_steps_per_second": 7.171,
      "step": 21000
    },
    {
      "epoch": 5.986987129346512,
      "grad_norm": 4.72714376449585,
      "learning_rate": 3.217155756207675e-06,
      "loss": 0.1671,
      "step": 21050
    },
    {
      "epoch": 6.001137737324895,
      "grad_norm": 4.222066402435303,
      "learning_rate": 3.1720090293453725e-06,
      "loss": 0.1689,
      "step": 21100
    },
    {
      "epoch": 6.015359453886084,
      "grad_norm": 3.668459415435791,
      "learning_rate": 3.12686230248307e-06,
      "loss": 0.1564,
      "step": 21150
    },
    {
      "epoch": 6.029581170447273,
      "grad_norm": 3.3872241973876953,
      "learning_rate": 3.081715575620768e-06,
      "loss": 0.1581,
      "step": 21200
    },
    {
      "epoch": 6.043802887008462,
      "grad_norm": 2.808481216430664,
      "learning_rate": 3.0365688487584654e-06,
      "loss": 0.1599,
      "step": 21250
    },
    {
      "epoch": 6.058024603569651,
      "grad_norm": 2.952930450439453,
      "learning_rate": 2.9914221218961625e-06,
      "loss": 0.1653,
      "step": 21300
    },
    {
      "epoch": 6.07224632013084,
      "grad_norm": 5.179711818695068,
      "learning_rate": 2.94627539503386e-06,
      "loss": 0.1516,
      "step": 21350
    },
    {
      "epoch": 6.086468036692029,
      "grad_norm": 5.036077976226807,
      "learning_rate": 2.901128668171558e-06,
      "loss": 0.1639,
      "step": 21400
    },
    {
      "epoch": 6.100689753253218,
      "grad_norm": 2.997460126876831,
      "learning_rate": 2.8559819413092554e-06,
      "loss": 0.165,
      "step": 21450
    },
    {
      "epoch": 6.114911469814406,
      "grad_norm": 2.811022996902466,
      "learning_rate": 2.810835214446953e-06,
      "loss": 0.1552,
      "step": 21500
    },
    {
      "epoch": 6.129133186375595,
      "grad_norm": 4.783929347991943,
      "learning_rate": 2.76568848758465e-06,
      "loss": 0.1579,
      "step": 21550
    },
    {
      "epoch": 6.143354902936784,
      "grad_norm": 4.392073154449463,
      "learning_rate": 2.720541760722348e-06,
      "loss": 0.1616,
      "step": 21600
    },
    {
      "epoch": 6.1575766194979735,
      "grad_norm": 4.011203765869141,
      "learning_rate": 2.6753950338600454e-06,
      "loss": 0.1646,
      "step": 21650
    },
    {
      "epoch": 6.171798336059163,
      "grad_norm": 3.1254000663757324,
      "learning_rate": 2.630248306997743e-06,
      "loss": 0.1617,
      "step": 21700
    },
    {
      "epoch": 6.186020052620352,
      "grad_norm": 3.5308494567871094,
      "learning_rate": 2.585101580135441e-06,
      "loss": 0.1474,
      "step": 21750
    },
    {
      "epoch": 6.20024176918154,
      "grad_norm": 5.427425861358643,
      "learning_rate": 2.539954853273138e-06,
      "loss": 0.1629,
      "step": 21800
    },
    {
      "epoch": 6.214463485742729,
      "grad_norm": 3.9503536224365234,
      "learning_rate": 2.4948081264108354e-06,
      "loss": 0.1641,
      "step": 21850
    },
    {
      "epoch": 6.228685202303918,
      "grad_norm": 3.7738194465637207,
      "learning_rate": 2.449661399548533e-06,
      "loss": 0.1506,
      "step": 21900
    },
    {
      "epoch": 6.242906918865107,
      "grad_norm": 4.290092945098877,
      "learning_rate": 2.4045146726862304e-06,
      "loss": 0.161,
      "step": 21950
    },
    {
      "epoch": 6.257128635426296,
      "grad_norm": 3.9158031940460205,
      "learning_rate": 2.359367945823928e-06,
      "loss": 0.1647,
      "step": 22000
    },
    {
      "epoch": 6.257128635426296,
      "eval_f1_macro": 0.8385788892169419,
      "eval_loss": 0.3063570261001587,
      "eval_runtime": 217.9458,
      "eval_samples_per_second": 917.659,
      "eval_steps_per_second": 7.172,
      "step": 22000
    },
    {
      "epoch": 6.2713503519874845,
      "grad_norm": 3.566333055496216,
      "learning_rate": 2.314221218961626e-06,
      "loss": 0.1637,
      "step": 22050
    },
    {
      "epoch": 6.285572068548674,
      "grad_norm": 3.2990610599517822,
      "learning_rate": 2.269074492099323e-06,
      "loss": 0.1585,
      "step": 22100
    },
    {
      "epoch": 6.299793785109863,
      "grad_norm": 4.256235122680664,
      "learning_rate": 2.2239277652370204e-06,
      "loss": 0.1601,
      "step": 22150
    },
    {
      "epoch": 6.314015501671052,
      "grad_norm": 2.7330563068389893,
      "learning_rate": 2.178781038374718e-06,
      "loss": 0.163,
      "step": 22200
    },
    {
      "epoch": 6.328237218232241,
      "grad_norm": 2.7908012866973877,
      "learning_rate": 2.1336343115124154e-06,
      "loss": 0.1577,
      "step": 22250
    },
    {
      "epoch": 6.34245893479343,
      "grad_norm": 2.827791213989258,
      "learning_rate": 2.088487584650113e-06,
      "loss": 0.1593,
      "step": 22300
    },
    {
      "epoch": 6.356680651354618,
      "grad_norm": 3.623044490814209,
      "learning_rate": 2.0433408577878104e-06,
      "loss": 0.1618,
      "step": 22350
    },
    {
      "epoch": 6.370902367915807,
      "grad_norm": 4.017937183380127,
      "learning_rate": 1.9981941309255083e-06,
      "loss": 0.1555,
      "step": 22400
    },
    {
      "epoch": 6.385124084476996,
      "grad_norm": 4.6455769538879395,
      "learning_rate": 1.9530474040632054e-06,
      "loss": 0.1706,
      "step": 22450
    },
    {
      "epoch": 6.399345801038185,
      "grad_norm": 3.8462281227111816,
      "learning_rate": 1.9079006772009033e-06,
      "loss": 0.1608,
      "step": 22500
    },
    {
      "epoch": 6.4135675175993745,
      "grad_norm": 3.1699962615966797,
      "learning_rate": 1.8627539503386006e-06,
      "loss": 0.1599,
      "step": 22550
    },
    {
      "epoch": 6.427789234160564,
      "grad_norm": 4.882631778717041,
      "learning_rate": 1.817607223476298e-06,
      "loss": 0.155,
      "step": 22600
    },
    {
      "epoch": 6.442010950721752,
      "grad_norm": 4.414224624633789,
      "learning_rate": 1.7724604966139956e-06,
      "loss": 0.1599,
      "step": 22650
    },
    {
      "epoch": 6.456232667282941,
      "grad_norm": 4.374213695526123,
      "learning_rate": 1.727313769751693e-06,
      "loss": 0.1479,
      "step": 22700
    },
    {
      "epoch": 6.47045438384413,
      "grad_norm": 4.230744361877441,
      "learning_rate": 1.6821670428893908e-06,
      "loss": 0.1637,
      "step": 22750
    },
    {
      "epoch": 6.484676100405319,
      "grad_norm": 3.4619269371032715,
      "learning_rate": 1.637020316027088e-06,
      "loss": 0.1502,
      "step": 22800
    },
    {
      "epoch": 6.498897816966508,
      "grad_norm": 3.547715663909912,
      "learning_rate": 1.5918735891647858e-06,
      "loss": 0.1599,
      "step": 22850
    },
    {
      "epoch": 6.513119533527696,
      "grad_norm": 3.3759255409240723,
      "learning_rate": 1.546726862302483e-06,
      "loss": 0.1618,
      "step": 22900
    },
    {
      "epoch": 6.527341250088885,
      "grad_norm": 2.919997453689575,
      "learning_rate": 1.5015801354401808e-06,
      "loss": 0.1626,
      "step": 22950
    },
    {
      "epoch": 6.5415629666500745,
      "grad_norm": 2.466320276260376,
      "learning_rate": 1.4564334085778783e-06,
      "loss": 0.156,
      "step": 23000
    },
    {
      "epoch": 6.5415629666500745,
      "eval_f1_macro": 0.8376290806421482,
      "eval_loss": 0.3144635856151581,
      "eval_runtime": 217.9346,
      "eval_samples_per_second": 917.707,
      "eval_steps_per_second": 7.172,
      "step": 23000
    },
    {
      "epoch": 6.555784683211264,
      "grad_norm": 3.6617064476013184,
      "learning_rate": 1.4112866817155758e-06,
      "loss": 0.161,
      "step": 23050
    },
    {
      "epoch": 6.570006399772453,
      "grad_norm": 3.5989019870758057,
      "learning_rate": 1.3661399548532733e-06,
      "loss": 0.1573,
      "step": 23100
    },
    {
      "epoch": 6.584228116333642,
      "grad_norm": 4.408974647521973,
      "learning_rate": 1.3209932279909708e-06,
      "loss": 0.1533,
      "step": 23150
    },
    {
      "epoch": 6.598449832894831,
      "grad_norm": 3.759028673171997,
      "learning_rate": 1.2758465011286683e-06,
      "loss": 0.1612,
      "step": 23200
    },
    {
      "epoch": 6.612671549456019,
      "grad_norm": 3.3744876384735107,
      "learning_rate": 1.2306997742663658e-06,
      "loss": 0.1635,
      "step": 23250
    },
    {
      "epoch": 6.626893266017208,
      "grad_norm": 3.5657901763916016,
      "learning_rate": 1.1855530474040633e-06,
      "loss": 0.159,
      "step": 23300
    },
    {
      "epoch": 6.641114982578397,
      "grad_norm": 3.6203854084014893,
      "learning_rate": 1.1404063205417608e-06,
      "loss": 0.1642,
      "step": 23350
    },
    {
      "epoch": 6.655336699139586,
      "grad_norm": 3.462571382522583,
      "learning_rate": 1.0952595936794583e-06,
      "loss": 0.1605,
      "step": 23400
    },
    {
      "epoch": 6.6695584157007755,
      "grad_norm": 3.5394582748413086,
      "learning_rate": 1.050112866817156e-06,
      "loss": 0.1589,
      "step": 23450
    },
    {
      "epoch": 6.683780132261964,
      "grad_norm": 3.0749130249023438,
      "learning_rate": 1.0049661399548535e-06,
      "loss": 0.1588,
      "step": 23500
    },
    {
      "epoch": 6.698001848823153,
      "grad_norm": 3.6915817260742188,
      "learning_rate": 9.59819413092551e-07,
      "loss": 0.1635,
      "step": 23550
    },
    {
      "epoch": 6.712223565384342,
      "grad_norm": 3.0237269401550293,
      "learning_rate": 9.146726862302484e-07,
      "loss": 0.1629,
      "step": 23600
    },
    {
      "epoch": 6.726445281945531,
      "grad_norm": 2.8665173053741455,
      "learning_rate": 8.695259593679459e-07,
      "loss": 0.1559,
      "step": 23650
    },
    {
      "epoch": 6.74066699850672,
      "grad_norm": 3.9085848331451416,
      "learning_rate": 8.243792325056434e-07,
      "loss": 0.1518,
      "step": 23700
    },
    {
      "epoch": 6.754888715067908,
      "grad_norm": 4.75093412399292,
      "learning_rate": 7.792325056433409e-07,
      "loss": 0.1547,
      "step": 23750
    },
    {
      "epoch": 6.769110431629097,
      "grad_norm": 3.3602614402770996,
      "learning_rate": 7.340857787810385e-07,
      "loss": 0.1568,
      "step": 23800
    },
    {
      "epoch": 6.783332148190286,
      "grad_norm": 3.035886287689209,
      "learning_rate": 6.88939051918736e-07,
      "loss": 0.1521,
      "step": 23850
    },
    {
      "epoch": 6.7975538647514755,
      "grad_norm": 3.5735504627227783,
      "learning_rate": 6.437923250564335e-07,
      "loss": 0.1511,
      "step": 23900
    },
    {
      "epoch": 6.811775581312665,
      "grad_norm": 3.7802422046661377,
      "learning_rate": 5.98645598194131e-07,
      "loss": 0.1568,
      "step": 23950
    },
    {
      "epoch": 6.825997297873854,
      "grad_norm": 3.477996826171875,
      "learning_rate": 5.534988713318286e-07,
      "loss": 0.1682,
      "step": 24000
    },
    {
      "epoch": 6.825997297873854,
      "eval_f1_macro": 0.8392584672270615,
      "eval_loss": 0.3100922405719757,
      "eval_runtime": 218.0237,
      "eval_samples_per_second": 917.331,
      "eval_steps_per_second": 7.169,
      "step": 24000
    },
    {
      "epoch": 6.840219014435043,
      "grad_norm": 4.028869152069092,
      "learning_rate": 5.08352144469526e-07,
      "loss": 0.1538,
      "step": 24050
    },
    {
      "epoch": 6.854440730996231,
      "grad_norm": 3.8874666690826416,
      "learning_rate": 4.632054176072235e-07,
      "loss": 0.1612,
      "step": 24100
    },
    {
      "epoch": 6.86866244755742,
      "grad_norm": 2.9096171855926514,
      "learning_rate": 4.1805869074492105e-07,
      "loss": 0.1636,
      "step": 24150
    },
    {
      "epoch": 6.882884164118609,
      "grad_norm": 2.4566259384155273,
      "learning_rate": 3.7291196388261854e-07,
      "loss": 0.1603,
      "step": 24200
    },
    {
      "epoch": 6.897105880679798,
      "grad_norm": 4.1904168128967285,
      "learning_rate": 3.2776523702031604e-07,
      "loss": 0.1618,
      "step": 24250
    },
    {
      "epoch": 6.911327597240987,
      "grad_norm": 3.597738742828369,
      "learning_rate": 2.8261851015801354e-07,
      "loss": 0.1503,
      "step": 24300
    },
    {
      "epoch": 6.9255493138021755,
      "grad_norm": 4.562414646148682,
      "learning_rate": 2.374717832957111e-07,
      "loss": 0.1529,
      "step": 24350
    },
    {
      "epoch": 6.939771030363365,
      "grad_norm": 3.35841703414917,
      "learning_rate": 1.923250564334086e-07,
      "loss": 0.1601,
      "step": 24400
    },
    {
      "epoch": 6.953992746924554,
      "grad_norm": 4.220426559448242,
      "learning_rate": 1.4717832957110611e-07,
      "loss": 0.1617,
      "step": 24450
    },
    {
      "epoch": 6.968214463485743,
      "grad_norm": 4.351163387298584,
      "learning_rate": 1.0203160270880361e-07,
      "loss": 0.1571,
      "step": 24500
    },
    {
      "epoch": 6.982436180046932,
      "grad_norm": 3.5998716354370117,
      "learning_rate": 5.6884875846501136e-08,
      "loss": 0.1526,
      "step": 24550
    },
    {
      "epoch": 6.996657896608121,
      "grad_norm": 4.061001300811768,
      "learning_rate": 1.1738148984198647e-08,
      "loss": 0.158,
      "step": 24600
    }
  ],
  "logging_steps": 50,
  "max_steps": 24612,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 7,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.651154299704e+18,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
