{
  "best_global_step": 6000,
  "best_metric": 0.8338754580917896,
  "best_model_checkpoint": "./models/unixcoder_focal/checkpoint-6000",
  "epoch": 4.0,
  "eval_steps": 1000,
  "global_step": 9000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00044444444444444447,
      "grad_norm": 2.8190102577209473,
      "learning_rate": 0.0,
      "loss": 0.9043,
      "step": 1
    },
    {
      "epoch": 0.022222222222222223,
      "grad_norm": 2.445587396621704,
      "learning_rate": 8.711111111111112e-07,
      "loss": 0.9091,
      "step": 50
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 1.7506753206253052,
      "learning_rate": 1.76e-06,
      "loss": 0.8723,
      "step": 100
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 3.492865562438965,
      "learning_rate": 2.648888888888889e-06,
      "loss": 0.8074,
      "step": 150
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 2.255390167236328,
      "learning_rate": 3.5377777777777783e-06,
      "loss": 0.6283,
      "step": 200
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 2.6700401306152344,
      "learning_rate": 4.426666666666667e-06,
      "loss": 0.4519,
      "step": 250
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 2.12968373298645,
      "learning_rate": 5.3155555555555564e-06,
      "loss": 0.3633,
      "step": 300
    },
    {
      "epoch": 0.15555555555555556,
      "grad_norm": 2.038336753845215,
      "learning_rate": 6.204444444444445e-06,
      "loss": 0.3331,
      "step": 350
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 2.7156248092651367,
      "learning_rate": 7.093333333333335e-06,
      "loss": 0.3068,
      "step": 400
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.8037184476852417,
      "learning_rate": 7.982222222222224e-06,
      "loss": 0.2797,
      "step": 450
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 2.294987916946411,
      "learning_rate": 8.871111111111111e-06,
      "loss": 0.2624,
      "step": 500
    },
    {
      "epoch": 0.24444444444444444,
      "grad_norm": 2.9948155879974365,
      "learning_rate": 9.760000000000001e-06,
      "loss": 0.2606,
      "step": 550
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 3.1188151836395264,
      "learning_rate": 1.064888888888889e-05,
      "loss": 0.249,
      "step": 600
    },
    {
      "epoch": 0.28888888888888886,
      "grad_norm": 1.8073042631149292,
      "learning_rate": 1.1537777777777779e-05,
      "loss": 0.2348,
      "step": 650
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 2.1670167446136475,
      "learning_rate": 1.2426666666666667e-05,
      "loss": 0.2379,
      "step": 700
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 1.49650239944458,
      "learning_rate": 1.3315555555555558e-05,
      "loss": 0.2239,
      "step": 750
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 2.0727016925811768,
      "learning_rate": 1.4204444444444445e-05,
      "loss": 0.2173,
      "step": 800
    },
    {
      "epoch": 0.37777777777777777,
      "grad_norm": 2.2985239028930664,
      "learning_rate": 1.5093333333333335e-05,
      "loss": 0.2202,
      "step": 850
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.4992456436157227,
      "learning_rate": 1.5982222222222222e-05,
      "loss": 0.2128,
      "step": 900
    },
    {
      "epoch": 0.4222222222222222,
      "grad_norm": 2.3025736808776855,
      "learning_rate": 1.687111111111111e-05,
      "loss": 0.2104,
      "step": 950
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 1.2418562173843384,
      "learning_rate": 1.7760000000000003e-05,
      "loss": 0.2041,
      "step": 1000
    },
    {
      "epoch": 0.4444444444444444,
      "eval_f1_macro": 0.7349742119784749,
      "eval_loss": 0.1910545527935028,
      "eval_runtime": 314.3776,
      "eval_samples_per_second": 636.178,
      "eval_steps_per_second": 6.362,
      "step": 1000
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 2.0910866260528564,
      "learning_rate": 1.8648888888888888e-05,
      "loss": 0.2008,
      "step": 1050
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 1.3685014247894287,
      "learning_rate": 1.953777777777778e-05,
      "loss": 0.2016,
      "step": 1100
    },
    {
      "epoch": 0.5111111111111111,
      "grad_norm": 2.1685736179351807,
      "learning_rate": 1.9952592592592596e-05,
      "loss": 0.2021,
      "step": 1150
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 1.2485216856002808,
      "learning_rate": 1.9853827160493828e-05,
      "loss": 0.1928,
      "step": 1200
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 2.4287407398223877,
      "learning_rate": 1.9755061728395063e-05,
      "loss": 0.1924,
      "step": 1250
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 1.4983994960784912,
      "learning_rate": 1.96562962962963e-05,
      "loss": 0.1917,
      "step": 1300
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.768646001815796,
      "learning_rate": 1.955753086419753e-05,
      "loss": 0.18,
      "step": 1350
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 1.4719167947769165,
      "learning_rate": 1.945876543209877e-05,
      "loss": 0.1787,
      "step": 1400
    },
    {
      "epoch": 0.6444444444444445,
      "grad_norm": 1.4998830556869507,
      "learning_rate": 1.936e-05,
      "loss": 0.1844,
      "step": 1450
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 1.201704740524292,
      "learning_rate": 1.9261234567901236e-05,
      "loss": 0.182,
      "step": 1500
    },
    {
      "epoch": 0.6888888888888889,
      "grad_norm": 1.2035436630249023,
      "learning_rate": 1.916246913580247e-05,
      "loss": 0.1797,
      "step": 1550
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 2.130305528640747,
      "learning_rate": 1.9063703703703704e-05,
      "loss": 0.1725,
      "step": 1600
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 1.710615634918213,
      "learning_rate": 1.896493827160494e-05,
      "loss": 0.173,
      "step": 1650
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 1.7834875583648682,
      "learning_rate": 1.8866172839506174e-05,
      "loss": 0.168,
      "step": 1700
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 1.2257463932037354,
      "learning_rate": 1.876740740740741e-05,
      "loss": 0.1682,
      "step": 1750
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.4195058345794678,
      "learning_rate": 1.8668641975308645e-05,
      "loss": 0.163,
      "step": 1800
    },
    {
      "epoch": 0.8222222222222222,
      "grad_norm": 1.8369940519332886,
      "learning_rate": 1.8569876543209877e-05,
      "loss": 0.1683,
      "step": 1850
    },
    {
      "epoch": 0.8444444444444444,
      "grad_norm": 1.3605576753616333,
      "learning_rate": 1.8471111111111112e-05,
      "loss": 0.1594,
      "step": 1900
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 2.3616933822631836,
      "learning_rate": 1.8372345679012348e-05,
      "loss": 0.167,
      "step": 1950
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 1.098111867904663,
      "learning_rate": 1.8273580246913583e-05,
      "loss": 0.1612,
      "step": 2000
    },
    {
      "epoch": 0.8888888888888888,
      "eval_f1_macro": 0.7852459709693723,
      "eval_loss": 0.15365907549858093,
      "eval_runtime": 314.3573,
      "eval_samples_per_second": 636.219,
      "eval_steps_per_second": 6.362,
      "step": 2000
    },
    {
      "epoch": 0.9111111111111111,
      "grad_norm": 1.9736956357955933,
      "learning_rate": 1.8174814814814815e-05,
      "loss": 0.1624,
      "step": 2050
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 0.9250233173370361,
      "learning_rate": 1.807604938271605e-05,
      "loss": 0.1561,
      "step": 2100
    },
    {
      "epoch": 0.9555555555555556,
      "grad_norm": 1.348478078842163,
      "learning_rate": 1.7977283950617286e-05,
      "loss": 0.1597,
      "step": 2150
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 0.9874544739723206,
      "learning_rate": 1.787851851851852e-05,
      "loss": 0.1588,
      "step": 2200
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.9467299580574036,
      "learning_rate": 1.7779753086419756e-05,
      "loss": 0.1536,
      "step": 2250
    },
    {
      "epoch": 1.0222222222222221,
      "grad_norm": 1.0027153491973877,
      "learning_rate": 1.768098765432099e-05,
      "loss": 0.1504,
      "step": 2300
    },
    {
      "epoch": 1.0444444444444445,
      "grad_norm": 1.0319266319274902,
      "learning_rate": 1.7582222222222224e-05,
      "loss": 0.1482,
      "step": 2350
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 1.4021705389022827,
      "learning_rate": 1.748345679012346e-05,
      "loss": 0.1459,
      "step": 2400
    },
    {
      "epoch": 1.0888888888888888,
      "grad_norm": 1.5295181274414062,
      "learning_rate": 1.738469135802469e-05,
      "loss": 0.1433,
      "step": 2450
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 1.060011625289917,
      "learning_rate": 1.728592592592593e-05,
      "loss": 0.147,
      "step": 2500
    },
    {
      "epoch": 1.1333333333333333,
      "grad_norm": 1.2688169479370117,
      "learning_rate": 1.718716049382716e-05,
      "loss": 0.1465,
      "step": 2550
    },
    {
      "epoch": 1.1555555555555554,
      "grad_norm": 1.6326900720596313,
      "learning_rate": 1.7088395061728397e-05,
      "loss": 0.1505,
      "step": 2600
    },
    {
      "epoch": 1.1777777777777778,
      "grad_norm": 1.1986823081970215,
      "learning_rate": 1.6989629629629632e-05,
      "loss": 0.1449,
      "step": 2650
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.900027871131897,
      "learning_rate": 1.6890864197530864e-05,
      "loss": 0.1477,
      "step": 2700
    },
    {
      "epoch": 1.2222222222222223,
      "grad_norm": 1.4156720638275146,
      "learning_rate": 1.67920987654321e-05,
      "loss": 0.1472,
      "step": 2750
    },
    {
      "epoch": 1.2444444444444445,
      "grad_norm": 1.553094506263733,
      "learning_rate": 1.6693333333333335e-05,
      "loss": 0.1408,
      "step": 2800
    },
    {
      "epoch": 1.2666666666666666,
      "grad_norm": 1.356988549232483,
      "learning_rate": 1.6594567901234567e-05,
      "loss": 0.1424,
      "step": 2850
    },
    {
      "epoch": 1.2888888888888888,
      "grad_norm": 0.8501070737838745,
      "learning_rate": 1.6495802469135806e-05,
      "loss": 0.1463,
      "step": 2900
    },
    {
      "epoch": 1.3111111111111111,
      "grad_norm": 1.2710407972335815,
      "learning_rate": 1.6397037037037038e-05,
      "loss": 0.1398,
      "step": 2950
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 1.3588757514953613,
      "learning_rate": 1.6298271604938273e-05,
      "loss": 0.1449,
      "step": 3000
    },
    {
      "epoch": 1.3333333333333333,
      "eval_f1_macro": 0.7942085737470024,
      "eval_loss": 0.14801011979579926,
      "eval_runtime": 314.606,
      "eval_samples_per_second": 635.716,
      "eval_steps_per_second": 6.357,
      "step": 3000
    },
    {
      "epoch": 1.3555555555555556,
      "grad_norm": 1.5123307704925537,
      "learning_rate": 1.619950617283951e-05,
      "loss": 0.1431,
      "step": 3050
    },
    {
      "epoch": 1.3777777777777778,
      "grad_norm": 1.2856124639511108,
      "learning_rate": 1.610074074074074e-05,
      "loss": 0.1366,
      "step": 3100
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.429287314414978,
      "learning_rate": 1.6001975308641976e-05,
      "loss": 0.1401,
      "step": 3150
    },
    {
      "epoch": 1.4222222222222223,
      "grad_norm": 1.023913860321045,
      "learning_rate": 1.590320987654321e-05,
      "loss": 0.1347,
      "step": 3200
    },
    {
      "epoch": 1.4444444444444444,
      "grad_norm": 1.7827749252319336,
      "learning_rate": 1.5804444444444446e-05,
      "loss": 0.1395,
      "step": 3250
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 1.2598354816436768,
      "learning_rate": 1.570567901234568e-05,
      "loss": 0.1385,
      "step": 3300
    },
    {
      "epoch": 1.488888888888889,
      "grad_norm": 0.9231231212615967,
      "learning_rate": 1.5606913580246914e-05,
      "loss": 0.1399,
      "step": 3350
    },
    {
      "epoch": 1.511111111111111,
      "grad_norm": 1.6539852619171143,
      "learning_rate": 1.550814814814815e-05,
      "loss": 0.1338,
      "step": 3400
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 1.5220742225646973,
      "learning_rate": 1.5409382716049384e-05,
      "loss": 0.1354,
      "step": 3450
    },
    {
      "epoch": 1.5555555555555556,
      "grad_norm": 1.12843656539917,
      "learning_rate": 1.531061728395062e-05,
      "loss": 0.1356,
      "step": 3500
    },
    {
      "epoch": 1.5777777777777777,
      "grad_norm": 3.33668851852417,
      "learning_rate": 1.5211851851851853e-05,
      "loss": 0.138,
      "step": 3550
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.0315321683883667,
      "learning_rate": 1.5113086419753087e-05,
      "loss": 0.1419,
      "step": 3600
    },
    {
      "epoch": 1.6222222222222222,
      "grad_norm": 1.993180274963379,
      "learning_rate": 1.5014320987654322e-05,
      "loss": 0.1403,
      "step": 3650
    },
    {
      "epoch": 1.6444444444444444,
      "grad_norm": 1.5173959732055664,
      "learning_rate": 1.4915555555555556e-05,
      "loss": 0.1413,
      "step": 3700
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 1.2570881843566895,
      "learning_rate": 1.4816790123456793e-05,
      "loss": 0.1331,
      "step": 3750
    },
    {
      "epoch": 1.6888888888888889,
      "grad_norm": 1.4301570653915405,
      "learning_rate": 1.4718024691358027e-05,
      "loss": 0.1311,
      "step": 3800
    },
    {
      "epoch": 1.7111111111111112,
      "grad_norm": 2.070322036743164,
      "learning_rate": 1.461925925925926e-05,
      "loss": 0.1341,
      "step": 3850
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 1.2848180532455444,
      "learning_rate": 1.4520493827160496e-05,
      "loss": 0.1334,
      "step": 3900
    },
    {
      "epoch": 1.7555555555555555,
      "grad_norm": 1.748063087463379,
      "learning_rate": 1.442172839506173e-05,
      "loss": 0.1332,
      "step": 3950
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 1.1069982051849365,
      "learning_rate": 1.4322962962962965e-05,
      "loss": 0.1289,
      "step": 4000
    },
    {
      "epoch": 1.7777777777777777,
      "eval_f1_macro": 0.8096740081045879,
      "eval_loss": 0.13856835663318634,
      "eval_runtime": 314.4391,
      "eval_samples_per_second": 636.053,
      "eval_steps_per_second": 6.361,
      "step": 4000
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.8927283883094788,
      "learning_rate": 1.4224197530864198e-05,
      "loss": 0.1337,
      "step": 4050
    },
    {
      "epoch": 1.8222222222222222,
      "grad_norm": 0.8523277640342712,
      "learning_rate": 1.4125432098765432e-05,
      "loss": 0.1368,
      "step": 4100
    },
    {
      "epoch": 1.8444444444444446,
      "grad_norm": 0.9201782941818237,
      "learning_rate": 1.4026666666666669e-05,
      "loss": 0.1341,
      "step": 4150
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 1.2436760663986206,
      "learning_rate": 1.3927901234567903e-05,
      "loss": 0.1371,
      "step": 4200
    },
    {
      "epoch": 1.8888888888888888,
      "grad_norm": 1.7398570775985718,
      "learning_rate": 1.3829135802469138e-05,
      "loss": 0.137,
      "step": 4250
    },
    {
      "epoch": 1.911111111111111,
      "grad_norm": 0.8642034530639648,
      "learning_rate": 1.3730370370370372e-05,
      "loss": 0.1329,
      "step": 4300
    },
    {
      "epoch": 1.9333333333333333,
      "grad_norm": 1.39412522315979,
      "learning_rate": 1.3631604938271605e-05,
      "loss": 0.1305,
      "step": 4350
    },
    {
      "epoch": 1.9555555555555557,
      "grad_norm": 1.379341721534729,
      "learning_rate": 1.353283950617284e-05,
      "loss": 0.1296,
      "step": 4400
    },
    {
      "epoch": 1.9777777777777779,
      "grad_norm": 1.0754954814910889,
      "learning_rate": 1.3434074074074074e-05,
      "loss": 0.128,
      "step": 4450
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.2626274824142456,
      "learning_rate": 1.3335308641975311e-05,
      "loss": 0.1304,
      "step": 4500
    },
    {
      "epoch": 2.022222222222222,
      "grad_norm": 1.6407485008239746,
      "learning_rate": 1.3236543209876545e-05,
      "loss": 0.1175,
      "step": 4550
    },
    {
      "epoch": 2.0444444444444443,
      "grad_norm": 0.9698444604873657,
      "learning_rate": 1.3137777777777779e-05,
      "loss": 0.121,
      "step": 4600
    },
    {
      "epoch": 2.066666666666667,
      "grad_norm": 0.9618692994117737,
      "learning_rate": 1.3039012345679014e-05,
      "loss": 0.1201,
      "step": 4650
    },
    {
      "epoch": 2.088888888888889,
      "grad_norm": 0.8770620226860046,
      "learning_rate": 1.2940246913580248e-05,
      "loss": 0.1187,
      "step": 4700
    },
    {
      "epoch": 2.111111111111111,
      "grad_norm": 1.4567632675170898,
      "learning_rate": 1.2841481481481481e-05,
      "loss": 0.1179,
      "step": 4750
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 1.481131911277771,
      "learning_rate": 1.2742716049382717e-05,
      "loss": 0.1158,
      "step": 4800
    },
    {
      "epoch": 2.1555555555555554,
      "grad_norm": 1.6114816665649414,
      "learning_rate": 1.264395061728395e-05,
      "loss": 0.1185,
      "step": 4850
    },
    {
      "epoch": 2.1777777777777776,
      "grad_norm": 1.1003496646881104,
      "learning_rate": 1.2545185185185187e-05,
      "loss": 0.1139,
      "step": 4900
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.8103179335594177,
      "learning_rate": 1.2446419753086421e-05,
      "loss": 0.113,
      "step": 4950
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 1.1862901449203491,
      "learning_rate": 1.2347654320987655e-05,
      "loss": 0.1159,
      "step": 5000
    },
    {
      "epoch": 2.2222222222222223,
      "eval_f1_macro": 0.8186895597893475,
      "eval_loss": 0.13305112719535828,
      "eval_runtime": 314.5115,
      "eval_samples_per_second": 635.907,
      "eval_steps_per_second": 6.359,
      "step": 5000
    },
    {
      "epoch": 2.2444444444444445,
      "grad_norm": 1.1776750087738037,
      "learning_rate": 1.224888888888889e-05,
      "loss": 0.1167,
      "step": 5050
    },
    {
      "epoch": 2.2666666666666666,
      "grad_norm": 1.6439239978790283,
      "learning_rate": 1.2150123456790124e-05,
      "loss": 0.1161,
      "step": 5100
    },
    {
      "epoch": 2.2888888888888888,
      "grad_norm": 1.9651880264282227,
      "learning_rate": 1.2051358024691359e-05,
      "loss": 0.1224,
      "step": 5150
    },
    {
      "epoch": 2.311111111111111,
      "grad_norm": 1.0123285055160522,
      "learning_rate": 1.1952592592592593e-05,
      "loss": 0.1142,
      "step": 5200
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 1.2060887813568115,
      "learning_rate": 1.1853827160493826e-05,
      "loss": 0.1163,
      "step": 5250
    },
    {
      "epoch": 2.3555555555555556,
      "grad_norm": 0.9960336089134216,
      "learning_rate": 1.1755061728395063e-05,
      "loss": 0.1137,
      "step": 5300
    },
    {
      "epoch": 2.3777777777777778,
      "grad_norm": 1.2642014026641846,
      "learning_rate": 1.1656296296296297e-05,
      "loss": 0.1162,
      "step": 5350
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.8115168809890747,
      "learning_rate": 1.1557530864197532e-05,
      "loss": 0.1132,
      "step": 5400
    },
    {
      "epoch": 2.422222222222222,
      "grad_norm": 1.0590620040893555,
      "learning_rate": 1.1458765432098766e-05,
      "loss": 0.1164,
      "step": 5450
    },
    {
      "epoch": 2.4444444444444446,
      "grad_norm": 1.5427649021148682,
      "learning_rate": 1.136e-05,
      "loss": 0.1184,
      "step": 5500
    },
    {
      "epoch": 2.466666666666667,
      "grad_norm": 1.5262694358825684,
      "learning_rate": 1.1261234567901235e-05,
      "loss": 0.1151,
      "step": 5550
    },
    {
      "epoch": 2.488888888888889,
      "grad_norm": 0.9985858201980591,
      "learning_rate": 1.1162469135802469e-05,
      "loss": 0.1183,
      "step": 5600
    },
    {
      "epoch": 2.511111111111111,
      "grad_norm": 0.7093135118484497,
      "learning_rate": 1.1063703703703706e-05,
      "loss": 0.1171,
      "step": 5650
    },
    {
      "epoch": 2.533333333333333,
      "grad_norm": 1.168541669845581,
      "learning_rate": 1.096493827160494e-05,
      "loss": 0.117,
      "step": 5700
    },
    {
      "epoch": 2.5555555555555554,
      "grad_norm": 1.2754790782928467,
      "learning_rate": 1.0866172839506173e-05,
      "loss": 0.1131,
      "step": 5750
    },
    {
      "epoch": 2.5777777777777775,
      "grad_norm": 1.0279916524887085,
      "learning_rate": 1.0767407407407408e-05,
      "loss": 0.117,
      "step": 5800
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.449524164199829,
      "learning_rate": 1.0668641975308642e-05,
      "loss": 0.1179,
      "step": 5850
    },
    {
      "epoch": 2.6222222222222222,
      "grad_norm": 0.9184776544570923,
      "learning_rate": 1.0569876543209879e-05,
      "loss": 0.1214,
      "step": 5900
    },
    {
      "epoch": 2.6444444444444444,
      "grad_norm": 0.9047425389289856,
      "learning_rate": 1.0471111111111113e-05,
      "loss": 0.1189,
      "step": 5950
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 1.1797508001327515,
      "learning_rate": 1.0372345679012346e-05,
      "loss": 0.1136,
      "step": 6000
    },
    {
      "epoch": 2.6666666666666665,
      "eval_f1_macro": 0.8338754580917896,
      "eval_loss": 0.13351228833198547,
      "eval_runtime": 314.5106,
      "eval_samples_per_second": 635.909,
      "eval_steps_per_second": 6.359,
      "step": 6000
    },
    {
      "epoch": 2.688888888888889,
      "grad_norm": 1.037462830543518,
      "learning_rate": 1.0273580246913582e-05,
      "loss": 0.1146,
      "step": 6050
    },
    {
      "epoch": 2.7111111111111112,
      "grad_norm": 1.1983394622802734,
      "learning_rate": 1.0174814814814815e-05,
      "loss": 0.1125,
      "step": 6100
    },
    {
      "epoch": 2.7333333333333334,
      "grad_norm": 1.2898566722869873,
      "learning_rate": 1.007604938271605e-05,
      "loss": 0.1161,
      "step": 6150
    },
    {
      "epoch": 2.7555555555555555,
      "grad_norm": 1.2543998956680298,
      "learning_rate": 9.977283950617284e-06,
      "loss": 0.1157,
      "step": 6200
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 0.9983252882957458,
      "learning_rate": 9.87851851851852e-06,
      "loss": 0.116,
      "step": 6250
    },
    {
      "epoch": 2.8,
      "grad_norm": 4.686801910400391,
      "learning_rate": 9.779753086419755e-06,
      "loss": 0.1178,
      "step": 6300
    },
    {
      "epoch": 2.822222222222222,
      "grad_norm": 1.942366600036621,
      "learning_rate": 9.680987654320989e-06,
      "loss": 0.1124,
      "step": 6350
    },
    {
      "epoch": 2.8444444444444446,
      "grad_norm": 1.2348371744155884,
      "learning_rate": 9.582222222222222e-06,
      "loss": 0.1105,
      "step": 6400
    },
    {
      "epoch": 2.8666666666666667,
      "grad_norm": 1.2265281677246094,
      "learning_rate": 9.483456790123458e-06,
      "loss": 0.1195,
      "step": 6450
    },
    {
      "epoch": 2.888888888888889,
      "grad_norm": 3.045775890350342,
      "learning_rate": 9.384691358024693e-06,
      "loss": 0.1166,
      "step": 6500
    },
    {
      "epoch": 2.911111111111111,
      "grad_norm": 1.6112399101257324,
      "learning_rate": 9.285925925925927e-06,
      "loss": 0.1149,
      "step": 6550
    },
    {
      "epoch": 2.9333333333333336,
      "grad_norm": 1.2167539596557617,
      "learning_rate": 9.18716049382716e-06,
      "loss": 0.1142,
      "step": 6600
    },
    {
      "epoch": 2.9555555555555557,
      "grad_norm": 1.21239173412323,
      "learning_rate": 9.088395061728396e-06,
      "loss": 0.1111,
      "step": 6650
    },
    {
      "epoch": 2.977777777777778,
      "grad_norm": 1.3750799894332886,
      "learning_rate": 8.989629629629631e-06,
      "loss": 0.1121,
      "step": 6700
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.241909146308899,
      "learning_rate": 8.890864197530865e-06,
      "loss": 0.1119,
      "step": 6750
    },
    {
      "epoch": 3.022222222222222,
      "grad_norm": 1.0345568656921387,
      "learning_rate": 8.7920987654321e-06,
      "loss": 0.1036,
      "step": 6800
    },
    {
      "epoch": 3.0444444444444443,
      "grad_norm": 1.0187170505523682,
      "learning_rate": 8.693333333333334e-06,
      "loss": 0.1018,
      "step": 6850
    },
    {
      "epoch": 3.066666666666667,
      "grad_norm": 1.1990585327148438,
      "learning_rate": 8.594567901234569e-06,
      "loss": 0.1036,
      "step": 6900
    },
    {
      "epoch": 3.088888888888889,
      "grad_norm": 1.697861909866333,
      "learning_rate": 8.495802469135803e-06,
      "loss": 0.1013,
      "step": 6950
    },
    {
      "epoch": 3.111111111111111,
      "grad_norm": 1.1794167757034302,
      "learning_rate": 8.397037037037038e-06,
      "loss": 0.099,
      "step": 7000
    },
    {
      "epoch": 3.111111111111111,
      "eval_f1_macro": 0.8331938592097228,
      "eval_loss": 0.13988427817821503,
      "eval_runtime": 314.3948,
      "eval_samples_per_second": 636.143,
      "eval_steps_per_second": 6.361,
      "step": 7000
    },
    {
      "epoch": 3.1333333333333333,
      "grad_norm": 1.4490439891815186,
      "learning_rate": 8.298271604938273e-06,
      "loss": 0.1043,
      "step": 7050
    },
    {
      "epoch": 3.1555555555555554,
      "grad_norm": 1.2020646333694458,
      "learning_rate": 8.199506172839507e-06,
      "loss": 0.1056,
      "step": 7100
    },
    {
      "epoch": 3.1777777777777776,
      "grad_norm": 1.7817195653915405,
      "learning_rate": 8.10074074074074e-06,
      "loss": 0.1013,
      "step": 7150
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.987635612487793,
      "learning_rate": 8.001975308641976e-06,
      "loss": 0.1055,
      "step": 7200
    },
    {
      "epoch": 3.2222222222222223,
      "grad_norm": 0.9331114292144775,
      "learning_rate": 7.903209876543211e-06,
      "loss": 0.1032,
      "step": 7250
    },
    {
      "epoch": 3.2444444444444445,
      "grad_norm": 1.5942010879516602,
      "learning_rate": 7.804444444444445e-06,
      "loss": 0.1033,
      "step": 7300
    },
    {
      "epoch": 3.2666666666666666,
      "grad_norm": 1.0312659740447998,
      "learning_rate": 7.705679012345679e-06,
      "loss": 0.0924,
      "step": 7350
    },
    {
      "epoch": 3.2888888888888888,
      "grad_norm": 1.6616997718811035,
      "learning_rate": 7.606913580246914e-06,
      "loss": 0.0996,
      "step": 7400
    },
    {
      "epoch": 3.311111111111111,
      "grad_norm": 1.433846354484558,
      "learning_rate": 7.5081481481481485e-06,
      "loss": 0.0996,
      "step": 7450
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 1.6889206171035767,
      "learning_rate": 7.409382716049384e-06,
      "loss": 0.1065,
      "step": 7500
    },
    {
      "epoch": 3.3555555555555556,
      "grad_norm": 1.6656454801559448,
      "learning_rate": 7.310617283950618e-06,
      "loss": 0.1036,
      "step": 7550
    },
    {
      "epoch": 3.3777777777777778,
      "grad_norm": 2.138197183609009,
      "learning_rate": 7.211851851851852e-06,
      "loss": 0.0958,
      "step": 7600
    },
    {
      "epoch": 3.4,
      "grad_norm": 2.0250816345214844,
      "learning_rate": 7.1130864197530865e-06,
      "loss": 0.0972,
      "step": 7650
    },
    {
      "epoch": 3.422222222222222,
      "grad_norm": 1.3854435682296753,
      "learning_rate": 7.014320987654322e-06,
      "loss": 0.0994,
      "step": 7700
    },
    {
      "epoch": 3.4444444444444446,
      "grad_norm": 1.291157603263855,
      "learning_rate": 6.915555555555556e-06,
      "loss": 0.1008,
      "step": 7750
    },
    {
      "epoch": 3.466666666666667,
      "grad_norm": 1.3295786380767822,
      "learning_rate": 6.81679012345679e-06,
      "loss": 0.0992,
      "step": 7800
    },
    {
      "epoch": 3.488888888888889,
      "grad_norm": 1.2317404747009277,
      "learning_rate": 6.718024691358025e-06,
      "loss": 0.1012,
      "step": 7850
    },
    {
      "epoch": 3.511111111111111,
      "grad_norm": 1.0013264417648315,
      "learning_rate": 6.61925925925926e-06,
      "loss": 0.1019,
      "step": 7900
    },
    {
      "epoch": 3.533333333333333,
      "grad_norm": 1.498534083366394,
      "learning_rate": 6.520493827160494e-06,
      "loss": 0.1048,
      "step": 7950
    },
    {
      "epoch": 3.5555555555555554,
      "grad_norm": 1.3996251821517944,
      "learning_rate": 6.42172839506173e-06,
      "loss": 0.1031,
      "step": 8000
    },
    {
      "epoch": 3.5555555555555554,
      "eval_f1_macro": 0.8329034624233832,
      "eval_loss": 0.131426602602005,
      "eval_runtime": 314.385,
      "eval_samples_per_second": 636.163,
      "eval_steps_per_second": 6.362,
      "step": 8000
    },
    {
      "epoch": 3.5777777777777775,
      "grad_norm": 1.4961141347885132,
      "learning_rate": 6.322962962962963e-06,
      "loss": 0.0987,
      "step": 8050
    },
    {
      "epoch": 3.6,
      "grad_norm": 1.1455546617507935,
      "learning_rate": 6.224197530864198e-06,
      "loss": 0.1029,
      "step": 8100
    },
    {
      "epoch": 3.6222222222222222,
      "grad_norm": 1.6943233013153076,
      "learning_rate": 6.125432098765432e-06,
      "loss": 0.1025,
      "step": 8150
    },
    {
      "epoch": 3.6444444444444444,
      "grad_norm": 1.4903918504714966,
      "learning_rate": 6.026666666666668e-06,
      "loss": 0.099,
      "step": 8200
    },
    {
      "epoch": 3.6666666666666665,
      "grad_norm": 1.409130573272705,
      "learning_rate": 5.927901234567902e-06,
      "loss": 0.1014,
      "step": 8250
    },
    {
      "epoch": 3.688888888888889,
      "grad_norm": 1.031203031539917,
      "learning_rate": 5.829135802469136e-06,
      "loss": 0.099,
      "step": 8300
    },
    {
      "epoch": 3.7111111111111112,
      "grad_norm": 1.1231180429458618,
      "learning_rate": 5.73037037037037e-06,
      "loss": 0.1015,
      "step": 8350
    },
    {
      "epoch": 3.7333333333333334,
      "grad_norm": 2.1531989574432373,
      "learning_rate": 5.631604938271606e-06,
      "loss": 0.1004,
      "step": 8400
    },
    {
      "epoch": 3.7555555555555555,
      "grad_norm": 1.2940444946289062,
      "learning_rate": 5.53283950617284e-06,
      "loss": 0.0968,
      "step": 8450
    },
    {
      "epoch": 3.7777777777777777,
      "grad_norm": 1.0417461395263672,
      "learning_rate": 5.434074074074075e-06,
      "loss": 0.095,
      "step": 8500
    },
    {
      "epoch": 3.8,
      "grad_norm": 1.13003671169281,
      "learning_rate": 5.335308641975308e-06,
      "loss": 0.0963,
      "step": 8550
    },
    {
      "epoch": 3.822222222222222,
      "grad_norm": 1.6442718505859375,
      "learning_rate": 5.236543209876544e-06,
      "loss": 0.1005,
      "step": 8600
    },
    {
      "epoch": 3.8444444444444446,
      "grad_norm": 1.1176351308822632,
      "learning_rate": 5.137777777777778e-06,
      "loss": 0.0994,
      "step": 8650
    },
    {
      "epoch": 3.8666666666666667,
      "grad_norm": 1.169740080833435,
      "learning_rate": 5.039012345679013e-06,
      "loss": 0.0976,
      "step": 8700
    },
    {
      "epoch": 3.888888888888889,
      "grad_norm": 0.8287581205368042,
      "learning_rate": 4.940246913580247e-06,
      "loss": 0.0966,
      "step": 8750
    },
    {
      "epoch": 3.911111111111111,
      "grad_norm": 1.3395558595657349,
      "learning_rate": 4.841481481481482e-06,
      "loss": 0.0955,
      "step": 8800
    },
    {
      "epoch": 3.9333333333333336,
      "grad_norm": 1.9291189908981323,
      "learning_rate": 4.742716049382716e-06,
      "loss": 0.0975,
      "step": 8850
    },
    {
      "epoch": 3.9555555555555557,
      "grad_norm": 1.1831459999084473,
      "learning_rate": 4.643950617283951e-06,
      "loss": 0.0918,
      "step": 8900
    },
    {
      "epoch": 3.977777777777778,
      "grad_norm": 1.6459757089614868,
      "learning_rate": 4.545185185185186e-06,
      "loss": 0.0986,
      "step": 8950
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.9582242965698242,
      "learning_rate": 4.44641975308642e-06,
      "loss": 0.1003,
      "step": 9000
    },
    {
      "epoch": 4.0,
      "eval_f1_macro": 0.8306406222912222,
      "eval_loss": 0.13158714771270752,
      "eval_runtime": 314.482,
      "eval_samples_per_second": 635.966,
      "eval_steps_per_second": 6.36,
      "step": 9000
    }
  ],
  "logging_steps": 50,
  "max_steps": 11250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3172233741056e+18,
  "train_batch_size": 50,
  "trial_name": null,
  "trial_params": null
}
