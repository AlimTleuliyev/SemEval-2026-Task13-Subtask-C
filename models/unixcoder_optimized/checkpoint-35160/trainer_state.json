{
  "best_global_step": 26000,
  "best_metric": 0.8613606554762723,
  "best_model_checkpoint": "./models/unixcoder_optimized/checkpoint-26000",
  "epoch": 10.0,
  "eval_steps": 1000,
  "global_step": 35160,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00028443433122377873,
      "grad_norm": 2.260739803314209,
      "learning_rate": 0.0,
      "loss": 1.3864,
      "step": 1
    },
    {
      "epoch": 0.014221716561188936,
      "grad_norm": 2.3790316581726074,
      "learning_rate": 2.7872582480091015e-07,
      "loss": 1.3971,
      "step": 50
    },
    {
      "epoch": 0.028443433122377872,
      "grad_norm": 2.310245990753174,
      "learning_rate": 5.631399317406143e-07,
      "loss": 1.3859,
      "step": 100
    },
    {
      "epoch": 0.04266514968356681,
      "grad_norm": 2.314784288406372,
      "learning_rate": 8.475540386803185e-07,
      "loss": 1.3608,
      "step": 150
    },
    {
      "epoch": 0.056886866244755745,
      "grad_norm": 2.8503451347351074,
      "learning_rate": 1.1319681456200227e-06,
      "loss": 1.3134,
      "step": 200
    },
    {
      "epoch": 0.07110858280594468,
      "grad_norm": 3.2490508556365967,
      "learning_rate": 1.416382252559727e-06,
      "loss": 1.2125,
      "step": 250
    },
    {
      "epoch": 0.08533029936713361,
      "grad_norm": 3.9099533557891846,
      "learning_rate": 1.7007963594994315e-06,
      "loss": 1.1093,
      "step": 300
    },
    {
      "epoch": 0.09955201592832255,
      "grad_norm": 5.730076789855957,
      "learning_rate": 1.9852104664391355e-06,
      "loss": 1.015,
      "step": 350
    },
    {
      "epoch": 0.11377373248951149,
      "grad_norm": 4.907719612121582,
      "learning_rate": 2.2696245733788397e-06,
      "loss": 0.9352,
      "step": 400
    },
    {
      "epoch": 0.12799544905070043,
      "grad_norm": 6.169214725494385,
      "learning_rate": 2.5540386803185443e-06,
      "loss": 0.8458,
      "step": 450
    },
    {
      "epoch": 0.14221716561188935,
      "grad_norm": 4.183732986450195,
      "learning_rate": 2.8384527872582484e-06,
      "loss": 0.7976,
      "step": 500
    },
    {
      "epoch": 0.1564388821730783,
      "grad_norm": 5.104010581970215,
      "learning_rate": 3.122866894197952e-06,
      "loss": 0.7636,
      "step": 550
    },
    {
      "epoch": 0.17066059873426723,
      "grad_norm": 10.534146308898926,
      "learning_rate": 3.407281001137657e-06,
      "loss": 0.7151,
      "step": 600
    },
    {
      "epoch": 0.18488231529545615,
      "grad_norm": 4.605879306793213,
      "learning_rate": 3.691695108077361e-06,
      "loss": 0.6764,
      "step": 650
    },
    {
      "epoch": 0.1991040318566451,
      "grad_norm": 3.580699920654297,
      "learning_rate": 3.976109215017065e-06,
      "loss": 0.6623,
      "step": 700
    },
    {
      "epoch": 0.21332574841783403,
      "grad_norm": 5.038264751434326,
      "learning_rate": 4.260523321956769e-06,
      "loss": 0.6424,
      "step": 750
    },
    {
      "epoch": 0.22754746497902298,
      "grad_norm": 3.7306087017059326,
      "learning_rate": 4.5449374288964735e-06,
      "loss": 0.6225,
      "step": 800
    },
    {
      "epoch": 0.2417691815402119,
      "grad_norm": 4.816781044006348,
      "learning_rate": 4.829351535836178e-06,
      "loss": 0.6307,
      "step": 850
    },
    {
      "epoch": 0.25599089810140085,
      "grad_norm": 3.819197177886963,
      "learning_rate": 5.113765642775882e-06,
      "loss": 0.6151,
      "step": 900
    },
    {
      "epoch": 0.2702126146625898,
      "grad_norm": 4.167289733886719,
      "learning_rate": 5.3981797497155865e-06,
      "loss": 0.5747,
      "step": 950
    },
    {
      "epoch": 0.2844343312237787,
      "grad_norm": 4.490437984466553,
      "learning_rate": 5.682593856655291e-06,
      "loss": 0.5783,
      "step": 1000
    },
    {
      "epoch": 0.2844343312237787,
      "eval_f1_macro": 0.7211749265553808,
      "eval_loss": 0.5389506220817566,
      "eval_runtime": 218.06,
      "eval_samples_per_second": 917.179,
      "eval_steps_per_second": 7.168,
      "step": 1000
    },
    {
      "epoch": 0.2986560477849676,
      "grad_norm": 5.7994279861450195,
      "learning_rate": 5.967007963594995e-06,
      "loss": 0.5735,
      "step": 1050
    },
    {
      "epoch": 0.3128777643461566,
      "grad_norm": 3.709273338317871,
      "learning_rate": 6.2514220705346995e-06,
      "loss": 0.563,
      "step": 1100
    },
    {
      "epoch": 0.32709948090734553,
      "grad_norm": 6.102278232574463,
      "learning_rate": 6.535836177474402e-06,
      "loss": 0.5399,
      "step": 1150
    },
    {
      "epoch": 0.34132119746853445,
      "grad_norm": 4.163242816925049,
      "learning_rate": 6.820250284414107e-06,
      "loss": 0.5378,
      "step": 1200
    },
    {
      "epoch": 0.3555429140297234,
      "grad_norm": 4.258503437042236,
      "learning_rate": 7.104664391353812e-06,
      "loss": 0.5296,
      "step": 1250
    },
    {
      "epoch": 0.3697646305909123,
      "grad_norm": 4.208327770233154,
      "learning_rate": 7.389078498293516e-06,
      "loss": 0.542,
      "step": 1300
    },
    {
      "epoch": 0.3839863471521013,
      "grad_norm": 5.575655460357666,
      "learning_rate": 7.67349260523322e-06,
      "loss": 0.5178,
      "step": 1350
    },
    {
      "epoch": 0.3982080637132902,
      "grad_norm": 3.718440055847168,
      "learning_rate": 7.957906712172925e-06,
      "loss": 0.5204,
      "step": 1400
    },
    {
      "epoch": 0.41242978027447913,
      "grad_norm": 4.74326753616333,
      "learning_rate": 8.24232081911263e-06,
      "loss": 0.5019,
      "step": 1450
    },
    {
      "epoch": 0.42665149683566805,
      "grad_norm": 4.215937614440918,
      "learning_rate": 8.526734926052333e-06,
      "loss": 0.5046,
      "step": 1500
    },
    {
      "epoch": 0.440873213396857,
      "grad_norm": 6.181474208831787,
      "learning_rate": 8.811149032992037e-06,
      "loss": 0.4878,
      "step": 1550
    },
    {
      "epoch": 0.45509492995804596,
      "grad_norm": 5.370193958282471,
      "learning_rate": 9.09556313993174e-06,
      "loss": 0.5009,
      "step": 1600
    },
    {
      "epoch": 0.4693166465192349,
      "grad_norm": 3.5297253131866455,
      "learning_rate": 9.379977246871446e-06,
      "loss": 0.4778,
      "step": 1650
    },
    {
      "epoch": 0.4835383630804238,
      "grad_norm": 3.9207372665405273,
      "learning_rate": 9.66439135381115e-06,
      "loss": 0.5001,
      "step": 1700
    },
    {
      "epoch": 0.49776007964161273,
      "grad_norm": 5.196340560913086,
      "learning_rate": 9.948805460750855e-06,
      "loss": 0.4717,
      "step": 1750
    },
    {
      "epoch": 0.5119817962028017,
      "grad_norm": 3.84230375289917,
      "learning_rate": 1.0233219567690557e-05,
      "loss": 0.4862,
      "step": 1800
    },
    {
      "epoch": 0.5262035127639906,
      "grad_norm": 3.8402140140533447,
      "learning_rate": 1.0517633674630263e-05,
      "loss": 0.4728,
      "step": 1850
    },
    {
      "epoch": 0.5404252293251796,
      "grad_norm": 6.224212646484375,
      "learning_rate": 1.0802047781569966e-05,
      "loss": 0.4668,
      "step": 1900
    },
    {
      "epoch": 0.5546469458863685,
      "grad_norm": 3.377894163131714,
      "learning_rate": 1.1086461888509672e-05,
      "loss": 0.4619,
      "step": 1950
    },
    {
      "epoch": 0.5688686624475574,
      "grad_norm": 3.783355236053467,
      "learning_rate": 1.1370875995449376e-05,
      "loss": 0.4696,
      "step": 2000
    },
    {
      "epoch": 0.5688686624475574,
      "eval_f1_macro": 0.7950257674284922,
      "eval_loss": 0.4553146958351135,
      "eval_runtime": 218.0429,
      "eval_samples_per_second": 917.251,
      "eval_steps_per_second": 7.168,
      "step": 2000
    },
    {
      "epoch": 0.5830903790087464,
      "grad_norm": 5.029723644256592,
      "learning_rate": 1.1655290102389078e-05,
      "loss": 0.4555,
      "step": 2050
    },
    {
      "epoch": 0.5973120955699353,
      "grad_norm": 3.2045228481292725,
      "learning_rate": 1.1939704209328785e-05,
      "loss": 0.436,
      "step": 2100
    },
    {
      "epoch": 0.6115338121311242,
      "grad_norm": 2.965982437133789,
      "learning_rate": 1.2224118316268487e-05,
      "loss": 0.461,
      "step": 2150
    },
    {
      "epoch": 0.6257555286923132,
      "grad_norm": 4.384160041809082,
      "learning_rate": 1.2508532423208192e-05,
      "loss": 0.4428,
      "step": 2200
    },
    {
      "epoch": 0.6399772452535021,
      "grad_norm": 4.665952205657959,
      "learning_rate": 1.2792946530147896e-05,
      "loss": 0.4502,
      "step": 2250
    },
    {
      "epoch": 0.6541989618146911,
      "grad_norm": 5.062201023101807,
      "learning_rate": 1.3077360637087602e-05,
      "loss": 0.4469,
      "step": 2300
    },
    {
      "epoch": 0.6684206783758799,
      "grad_norm": 4.249529838562012,
      "learning_rate": 1.3361774744027305e-05,
      "loss": 0.4367,
      "step": 2350
    },
    {
      "epoch": 0.6826423949370689,
      "grad_norm": 4.130416393280029,
      "learning_rate": 1.3646188850967007e-05,
      "loss": 0.4347,
      "step": 2400
    },
    {
      "epoch": 0.6968641114982579,
      "grad_norm": 4.94219446182251,
      "learning_rate": 1.3930602957906713e-05,
      "loss": 0.4327,
      "step": 2450
    },
    {
      "epoch": 0.7110858280594468,
      "grad_norm": 4.649360179901123,
      "learning_rate": 1.4215017064846417e-05,
      "loss": 0.439,
      "step": 2500
    },
    {
      "epoch": 0.7253075446206357,
      "grad_norm": 4.775397777557373,
      "learning_rate": 1.4499431171786122e-05,
      "loss": 0.4409,
      "step": 2550
    },
    {
      "epoch": 0.7395292611818246,
      "grad_norm": 2.5690858364105225,
      "learning_rate": 1.4783845278725826e-05,
      "loss": 0.424,
      "step": 2600
    },
    {
      "epoch": 0.7537509777430136,
      "grad_norm": 3.659601926803589,
      "learning_rate": 1.5068259385665531e-05,
      "loss": 0.4181,
      "step": 2650
    },
    {
      "epoch": 0.7679726943042026,
      "grad_norm": 3.8386378288269043,
      "learning_rate": 1.5352673492605233e-05,
      "loss": 0.4123,
      "step": 2700
    },
    {
      "epoch": 0.7821944108653914,
      "grad_norm": 3.2798492908477783,
      "learning_rate": 1.5637087599544937e-05,
      "loss": 0.4088,
      "step": 2750
    },
    {
      "epoch": 0.7964161274265804,
      "grad_norm": 3.344672441482544,
      "learning_rate": 1.5921501706484644e-05,
      "loss": 0.4092,
      "step": 2800
    },
    {
      "epoch": 0.8106378439877693,
      "grad_norm": 2.303947925567627,
      "learning_rate": 1.6205915813424348e-05,
      "loss": 0.4227,
      "step": 2850
    },
    {
      "epoch": 0.8248595605489583,
      "grad_norm": 3.446415424346924,
      "learning_rate": 1.6490329920364052e-05,
      "loss": 0.4071,
      "step": 2900
    },
    {
      "epoch": 0.8390812771101472,
      "grad_norm": 4.338700771331787,
      "learning_rate": 1.6774744027303756e-05,
      "loss": 0.4209,
      "step": 2950
    },
    {
      "epoch": 0.8533029936713361,
      "grad_norm": 3.3371224403381348,
      "learning_rate": 1.705915813424346e-05,
      "loss": 0.4193,
      "step": 3000
    },
    {
      "epoch": 0.8533029936713361,
      "eval_f1_macro": 0.7826273339524692,
      "eval_loss": 0.39668038487434387,
      "eval_runtime": 218.0246,
      "eval_samples_per_second": 917.328,
      "eval_steps_per_second": 7.169,
      "step": 3000
    },
    {
      "epoch": 0.8675247102325251,
      "grad_norm": 3.5615406036376953,
      "learning_rate": 1.7343572241183163e-05,
      "loss": 0.4215,
      "step": 3050
    },
    {
      "epoch": 0.881746426793714,
      "grad_norm": 2.986664295196533,
      "learning_rate": 1.7627986348122867e-05,
      "loss": 0.3952,
      "step": 3100
    },
    {
      "epoch": 0.8959681433549029,
      "grad_norm": 3.5884346961975098,
      "learning_rate": 1.7912400455062574e-05,
      "loss": 0.4031,
      "step": 3150
    },
    {
      "epoch": 0.9101898599160919,
      "grad_norm": 2.9477121829986572,
      "learning_rate": 1.8196814562002278e-05,
      "loss": 0.4142,
      "step": 3200
    },
    {
      "epoch": 0.9244115764772808,
      "grad_norm": 3.655144453048706,
      "learning_rate": 1.848122866894198e-05,
      "loss": 0.4127,
      "step": 3250
    },
    {
      "epoch": 0.9386332930384698,
      "grad_norm": 2.464702844619751,
      "learning_rate": 1.8765642775881685e-05,
      "loss": 0.3951,
      "step": 3300
    },
    {
      "epoch": 0.9528550095996586,
      "grad_norm": 2.8936550617218018,
      "learning_rate": 1.905005688282139e-05,
      "loss": 0.3935,
      "step": 3350
    },
    {
      "epoch": 0.9670767261608476,
      "grad_norm": 2.839953660964966,
      "learning_rate": 1.9334470989761093e-05,
      "loss": 0.399,
      "step": 3400
    },
    {
      "epoch": 0.9812984427220366,
      "grad_norm": 2.8150718212127686,
      "learning_rate": 1.9618885096700797e-05,
      "loss": 0.3953,
      "step": 3450
    },
    {
      "epoch": 0.9955201592832255,
      "grad_norm": 4.06385612487793,
      "learning_rate": 1.9903299203640504e-05,
      "loss": 0.3798,
      "step": 3500
    },
    {
      "epoch": 1.0096707672616085,
      "grad_norm": 2.2889161109924316,
      "learning_rate": 1.997914296549109e-05,
      "loss": 0.3689,
      "step": 3550
    },
    {
      "epoch": 1.0238924838227974,
      "grad_norm": 4.248363494873047,
      "learning_rate": 1.9947541398053346e-05,
      "loss": 0.3697,
      "step": 3600
    },
    {
      "epoch": 1.0381142003839863,
      "grad_norm": 3.3940417766571045,
      "learning_rate": 1.99159398306156e-05,
      "loss": 0.3759,
      "step": 3650
    },
    {
      "epoch": 1.0523359169451754,
      "grad_norm": 4.578360557556152,
      "learning_rate": 1.9884338263177856e-05,
      "loss": 0.3682,
      "step": 3700
    },
    {
      "epoch": 1.0665576335063642,
      "grad_norm": 3.850754499435425,
      "learning_rate": 1.9852736695740112e-05,
      "loss": 0.3678,
      "step": 3750
    },
    {
      "epoch": 1.080779350067553,
      "grad_norm": 2.4220190048217773,
      "learning_rate": 1.9821135128302366e-05,
      "loss": 0.3666,
      "step": 3800
    },
    {
      "epoch": 1.0950010666287422,
      "grad_norm": 2.8469183444976807,
      "learning_rate": 1.978953356086462e-05,
      "loss": 0.3581,
      "step": 3850
    },
    {
      "epoch": 1.109222783189931,
      "grad_norm": 2.9561705589294434,
      "learning_rate": 1.9757931993426875e-05,
      "loss": 0.3544,
      "step": 3900
    },
    {
      "epoch": 1.12344449975112,
      "grad_norm": 2.336393356323242,
      "learning_rate": 1.9726330425989132e-05,
      "loss": 0.3682,
      "step": 3950
    },
    {
      "epoch": 1.1376662163123088,
      "grad_norm": 3.1682541370391846,
      "learning_rate": 1.9694728858551385e-05,
      "loss": 0.35,
      "step": 4000
    },
    {
      "epoch": 1.1376662163123088,
      "eval_f1_macro": 0.8056914245138821,
      "eval_loss": 0.3691887855529785,
      "eval_runtime": 217.9965,
      "eval_samples_per_second": 917.446,
      "eval_steps_per_second": 7.17,
      "step": 4000
    },
    {
      "epoch": 1.1518879328734979,
      "grad_norm": 3.2526659965515137,
      "learning_rate": 1.9663127291113642e-05,
      "loss": 0.379,
      "step": 4050
    },
    {
      "epoch": 1.1661096494346868,
      "grad_norm": 1.9434645175933838,
      "learning_rate": 1.9631525723675895e-05,
      "loss": 0.3618,
      "step": 4100
    },
    {
      "epoch": 1.1803313659958756,
      "grad_norm": 2.9501335620880127,
      "learning_rate": 1.9599924156238152e-05,
      "loss": 0.3578,
      "step": 4150
    },
    {
      "epoch": 1.1945530825570647,
      "grad_norm": 2.7621397972106934,
      "learning_rate": 1.9568322588800405e-05,
      "loss": 0.3465,
      "step": 4200
    },
    {
      "epoch": 1.2087747991182536,
      "grad_norm": 2.3752636909484863,
      "learning_rate": 1.9536721021362662e-05,
      "loss": 0.3628,
      "step": 4250
    },
    {
      "epoch": 1.2229965156794425,
      "grad_norm": 2.6690480709075928,
      "learning_rate": 1.9505119453924915e-05,
      "loss": 0.3494,
      "step": 4300
    },
    {
      "epoch": 1.2372182322406315,
      "grad_norm": 2.243185520172119,
      "learning_rate": 1.9473517886487172e-05,
      "loss": 0.3534,
      "step": 4350
    },
    {
      "epoch": 1.2514399488018204,
      "grad_norm": 3.778947353363037,
      "learning_rate": 1.9441916319049425e-05,
      "loss": 0.354,
      "step": 4400
    },
    {
      "epoch": 1.2656616653630093,
      "grad_norm": 2.5044240951538086,
      "learning_rate": 1.941031475161168e-05,
      "loss": 0.3577,
      "step": 4450
    },
    {
      "epoch": 1.2798833819241984,
      "grad_norm": 2.210514545440674,
      "learning_rate": 1.9378713184173935e-05,
      "loss": 0.3581,
      "step": 4500
    },
    {
      "epoch": 1.2941050984853872,
      "grad_norm": 1.815394639968872,
      "learning_rate": 1.934711161673619e-05,
      "loss": 0.3447,
      "step": 4550
    },
    {
      "epoch": 1.308326815046576,
      "grad_norm": 3.083376884460449,
      "learning_rate": 1.9315510049298448e-05,
      "loss": 0.3454,
      "step": 4600
    },
    {
      "epoch": 1.322548531607765,
      "grad_norm": 3.3359103202819824,
      "learning_rate": 1.92839084818607e-05,
      "loss": 0.3611,
      "step": 4650
    },
    {
      "epoch": 1.336770248168954,
      "grad_norm": 4.057024955749512,
      "learning_rate": 1.9252306914422958e-05,
      "loss": 0.3436,
      "step": 4700
    },
    {
      "epoch": 1.350991964730143,
      "grad_norm": 2.0821359157562256,
      "learning_rate": 1.922070534698521e-05,
      "loss": 0.3537,
      "step": 4750
    },
    {
      "epoch": 1.3652136812913318,
      "grad_norm": 1.92685866355896,
      "learning_rate": 1.9189103779547468e-05,
      "loss": 0.3406,
      "step": 4800
    },
    {
      "epoch": 1.3794353978525207,
      "grad_norm": 2.541468858718872,
      "learning_rate": 1.915750221210972e-05,
      "loss": 0.3343,
      "step": 4850
    },
    {
      "epoch": 1.3936571144137098,
      "grad_norm": 3.577390432357788,
      "learning_rate": 1.9125900644671978e-05,
      "loss": 0.3428,
      "step": 4900
    },
    {
      "epoch": 1.4078788309748986,
      "grad_norm": 3.8392081260681152,
      "learning_rate": 1.9094299077234234e-05,
      "loss": 0.3493,
      "step": 4950
    },
    {
      "epoch": 1.4221005475360875,
      "grad_norm": 2.355546712875366,
      "learning_rate": 1.9062697509796488e-05,
      "loss": 0.3372,
      "step": 5000
    },
    {
      "epoch": 1.4221005475360875,
      "eval_f1_macro": 0.8129207487438709,
      "eval_loss": 0.3663753271102905,
      "eval_runtime": 218.1242,
      "eval_samples_per_second": 916.909,
      "eval_steps_per_second": 7.166,
      "step": 5000
    },
    {
      "epoch": 1.4363222640972766,
      "grad_norm": 2.6371402740478516,
      "learning_rate": 1.903109594235874e-05,
      "loss": 0.335,
      "step": 5050
    },
    {
      "epoch": 1.4505439806584655,
      "grad_norm": 2.842759609222412,
      "learning_rate": 1.8999494374920998e-05,
      "loss": 0.3424,
      "step": 5100
    },
    {
      "epoch": 1.4647656972196543,
      "grad_norm": 2.3341357707977295,
      "learning_rate": 1.896789280748325e-05,
      "loss": 0.347,
      "step": 5150
    },
    {
      "epoch": 1.4789874137808434,
      "grad_norm": 2.80631685256958,
      "learning_rate": 1.8936291240045508e-05,
      "loss": 0.3436,
      "step": 5200
    },
    {
      "epoch": 1.4932091303420323,
      "grad_norm": 2.6466424465179443,
      "learning_rate": 1.8904689672607764e-05,
      "loss": 0.3407,
      "step": 5250
    },
    {
      "epoch": 1.5074308469032212,
      "grad_norm": 2.4191224575042725,
      "learning_rate": 1.8873088105170017e-05,
      "loss": 0.325,
      "step": 5300
    },
    {
      "epoch": 1.5216525634644102,
      "grad_norm": 2.978407382965088,
      "learning_rate": 1.884148653773227e-05,
      "loss": 0.3361,
      "step": 5350
    },
    {
      "epoch": 1.5358742800255991,
      "grad_norm": 2.484076499938965,
      "learning_rate": 1.8809884970294527e-05,
      "loss": 0.3448,
      "step": 5400
    },
    {
      "epoch": 1.550095996586788,
      "grad_norm": 2.472615957260132,
      "learning_rate": 1.8778283402856784e-05,
      "loss": 0.3419,
      "step": 5450
    },
    {
      "epoch": 1.564317713147977,
      "grad_norm": 3.499786376953125,
      "learning_rate": 1.8746681835419037e-05,
      "loss": 0.328,
      "step": 5500
    },
    {
      "epoch": 1.578539429709166,
      "grad_norm": 2.2196147441864014,
      "learning_rate": 1.8715080267981294e-05,
      "loss": 0.3319,
      "step": 5550
    },
    {
      "epoch": 1.5927611462703548,
      "grad_norm": 3.159658908843994,
      "learning_rate": 1.868347870054355e-05,
      "loss": 0.3375,
      "step": 5600
    },
    {
      "epoch": 1.606982862831544,
      "grad_norm": 2.7997496128082275,
      "learning_rate": 1.8651877133105804e-05,
      "loss": 0.3198,
      "step": 5650
    },
    {
      "epoch": 1.6212045793927325,
      "grad_norm": 2.267061471939087,
      "learning_rate": 1.8620275565668057e-05,
      "loss": 0.3403,
      "step": 5700
    },
    {
      "epoch": 1.6354262959539216,
      "grad_norm": 3.01251220703125,
      "learning_rate": 1.8588673998230314e-05,
      "loss": 0.3395,
      "step": 5750
    },
    {
      "epoch": 1.6496480125151107,
      "grad_norm": 2.8399078845977783,
      "learning_rate": 1.855707243079257e-05,
      "loss": 0.3412,
      "step": 5800
    },
    {
      "epoch": 1.6638697290762994,
      "grad_norm": 3.1878139972686768,
      "learning_rate": 1.8525470863354824e-05,
      "loss": 0.3311,
      "step": 5850
    },
    {
      "epoch": 1.6780914456374885,
      "grad_norm": 4.081830024719238,
      "learning_rate": 1.849386929591708e-05,
      "loss": 0.3146,
      "step": 5900
    },
    {
      "epoch": 1.6923131621986773,
      "grad_norm": 3.231579542160034,
      "learning_rate": 1.8462267728479333e-05,
      "loss": 0.322,
      "step": 5950
    },
    {
      "epoch": 1.7065348787598662,
      "grad_norm": 2.3983874320983887,
      "learning_rate": 1.8430666161041587e-05,
      "loss": 0.331,
      "step": 6000
    },
    {
      "epoch": 1.7065348787598662,
      "eval_f1_macro": 0.8135515369449493,
      "eval_loss": 0.3527677059173584,
      "eval_runtime": 218.0852,
      "eval_samples_per_second": 917.073,
      "eval_steps_per_second": 7.167,
      "step": 6000
    },
    {
      "epoch": 1.7207565953210553,
      "grad_norm": 2.2303621768951416,
      "learning_rate": 1.8399064593603843e-05,
      "loss": 0.3304,
      "step": 6050
    },
    {
      "epoch": 1.7349783118822442,
      "grad_norm": 3.008460760116577,
      "learning_rate": 1.83674630261661e-05,
      "loss": 0.3338,
      "step": 6100
    },
    {
      "epoch": 1.749200028443433,
      "grad_norm": 1.8107362985610962,
      "learning_rate": 1.8335861458728353e-05,
      "loss": 0.3329,
      "step": 6150
    },
    {
      "epoch": 1.7634217450046221,
      "grad_norm": 2.406202793121338,
      "learning_rate": 1.830425989129061e-05,
      "loss": 0.3133,
      "step": 6200
    },
    {
      "epoch": 1.777643461565811,
      "grad_norm": 2.234882116317749,
      "learning_rate": 1.8272658323852867e-05,
      "loss": 0.3123,
      "step": 6250
    },
    {
      "epoch": 1.7918651781269999,
      "grad_norm": 2.2456932067871094,
      "learning_rate": 1.824105675641512e-05,
      "loss": 0.3331,
      "step": 6300
    },
    {
      "epoch": 1.806086894688189,
      "grad_norm": 2.2770590782165527,
      "learning_rate": 1.8209455188977373e-05,
      "loss": 0.3268,
      "step": 6350
    },
    {
      "epoch": 1.8203086112493778,
      "grad_norm": 2.0425918102264404,
      "learning_rate": 1.817785362153963e-05,
      "loss": 0.3363,
      "step": 6400
    },
    {
      "epoch": 1.8345303278105667,
      "grad_norm": 2.4416747093200684,
      "learning_rate": 1.8146252054101886e-05,
      "loss": 0.3287,
      "step": 6450
    },
    {
      "epoch": 1.8487520443717558,
      "grad_norm": 3.3610193729400635,
      "learning_rate": 1.811465048666414e-05,
      "loss": 0.3249,
      "step": 6500
    },
    {
      "epoch": 1.8629737609329446,
      "grad_norm": 2.257868766784668,
      "learning_rate": 1.8083048919226396e-05,
      "loss": 0.3308,
      "step": 6550
    },
    {
      "epoch": 1.8771954774941335,
      "grad_norm": 2.6698544025421143,
      "learning_rate": 1.8051447351788653e-05,
      "loss": 0.327,
      "step": 6600
    },
    {
      "epoch": 1.8914171940553226,
      "grad_norm": 4.639113426208496,
      "learning_rate": 1.8019845784350906e-05,
      "loss": 0.3329,
      "step": 6650
    },
    {
      "epoch": 1.9056389106165113,
      "grad_norm": 2.5050952434539795,
      "learning_rate": 1.798824421691316e-05,
      "loss": 0.3189,
      "step": 6700
    },
    {
      "epoch": 1.9198606271777003,
      "grad_norm": 3.719627618789673,
      "learning_rate": 1.7956642649475416e-05,
      "loss": 0.3121,
      "step": 6750
    },
    {
      "epoch": 1.9340823437388894,
      "grad_norm": 1.8754615783691406,
      "learning_rate": 1.792504108203767e-05,
      "loss": 0.3229,
      "step": 6800
    },
    {
      "epoch": 1.948304060300078,
      "grad_norm": 2.2265775203704834,
      "learning_rate": 1.7893439514599926e-05,
      "loss": 0.3208,
      "step": 6850
    },
    {
      "epoch": 1.9625257768612672,
      "grad_norm": 2.8057239055633545,
      "learning_rate": 1.7861837947162183e-05,
      "loss": 0.314,
      "step": 6900
    },
    {
      "epoch": 1.976747493422456,
      "grad_norm": 2.9501333236694336,
      "learning_rate": 1.7830236379724436e-05,
      "loss": 0.3056,
      "step": 6950
    },
    {
      "epoch": 1.990969209983645,
      "grad_norm": 3.318715810775757,
      "learning_rate": 1.779863481228669e-05,
      "loss": 0.3202,
      "step": 7000
    },
    {
      "epoch": 1.990969209983645,
      "eval_f1_macro": 0.8324113312109935,
      "eval_loss": 0.3526877760887146,
      "eval_runtime": 218.0757,
      "eval_samples_per_second": 917.113,
      "eval_steps_per_second": 7.167,
      "step": 7000
    },
    {
      "epoch": 2.005119817962028,
      "grad_norm": 2.4381165504455566,
      "learning_rate": 1.7767033244848946e-05,
      "loss": 0.3069,
      "step": 7050
    },
    {
      "epoch": 2.019341534523217,
      "grad_norm": 2.3824613094329834,
      "learning_rate": 1.7735431677411202e-05,
      "loss": 0.2859,
      "step": 7100
    },
    {
      "epoch": 2.0335632510844057,
      "grad_norm": 2.870439052581787,
      "learning_rate": 1.7703830109973456e-05,
      "loss": 0.2689,
      "step": 7150
    },
    {
      "epoch": 2.047784967645595,
      "grad_norm": 2.656642436981201,
      "learning_rate": 1.7672228542535712e-05,
      "loss": 0.2928,
      "step": 7200
    },
    {
      "epoch": 2.062006684206784,
      "grad_norm": 2.889808416366577,
      "learning_rate": 1.7640626975097966e-05,
      "loss": 0.2853,
      "step": 7250
    },
    {
      "epoch": 2.0762284007679725,
      "grad_norm": 2.7659425735473633,
      "learning_rate": 1.7609025407660222e-05,
      "loss": 0.2876,
      "step": 7300
    },
    {
      "epoch": 2.0904501173291616,
      "grad_norm": 2.4340384006500244,
      "learning_rate": 1.7577423840222475e-05,
      "loss": 0.2784,
      "step": 7350
    },
    {
      "epoch": 2.1046718338903507,
      "grad_norm": 2.0680813789367676,
      "learning_rate": 1.7545822272784732e-05,
      "loss": 0.2775,
      "step": 7400
    },
    {
      "epoch": 2.1188935504515394,
      "grad_norm": 2.321683168411255,
      "learning_rate": 1.7514220705346985e-05,
      "loss": 0.2868,
      "step": 7450
    },
    {
      "epoch": 2.1331152670127285,
      "grad_norm": 1.8688262701034546,
      "learning_rate": 1.7482619137909242e-05,
      "loss": 0.2873,
      "step": 7500
    },
    {
      "epoch": 2.1473369835739176,
      "grad_norm": 2.220468759536743,
      "learning_rate": 1.74510175704715e-05,
      "loss": 0.284,
      "step": 7550
    },
    {
      "epoch": 2.161558700135106,
      "grad_norm": 2.674103260040283,
      "learning_rate": 1.7419416003033752e-05,
      "loss": 0.2855,
      "step": 7600
    },
    {
      "epoch": 2.1757804166962953,
      "grad_norm": 1.9365195035934448,
      "learning_rate": 1.7387814435596005e-05,
      "loss": 0.2751,
      "step": 7650
    },
    {
      "epoch": 2.1900021332574844,
      "grad_norm": 2.4998040199279785,
      "learning_rate": 1.7356212868158262e-05,
      "loss": 0.2771,
      "step": 7700
    },
    {
      "epoch": 2.204223849818673,
      "grad_norm": 2.5431461334228516,
      "learning_rate": 1.732461130072052e-05,
      "loss": 0.2845,
      "step": 7750
    },
    {
      "epoch": 2.218445566379862,
      "grad_norm": 2.387693405151367,
      "learning_rate": 1.729300973328277e-05,
      "loss": 0.2775,
      "step": 7800
    },
    {
      "epoch": 2.232667282941051,
      "grad_norm": 2.5795698165893555,
      "learning_rate": 1.726140816584503e-05,
      "loss": 0.2909,
      "step": 7850
    },
    {
      "epoch": 2.24688899950224,
      "grad_norm": 3.4390668869018555,
      "learning_rate": 1.722980659840728e-05,
      "loss": 0.2733,
      "step": 7900
    },
    {
      "epoch": 2.261110716063429,
      "grad_norm": 2.638031005859375,
      "learning_rate": 1.7198205030969538e-05,
      "loss": 0.285,
      "step": 7950
    },
    {
      "epoch": 2.2753324326246176,
      "grad_norm": 2.4799959659576416,
      "learning_rate": 1.716660346353179e-05,
      "loss": 0.2841,
      "step": 8000
    },
    {
      "epoch": 2.2753324326246176,
      "eval_f1_macro": 0.8394980160294858,
      "eval_loss": 0.3300468623638153,
      "eval_runtime": 218.0253,
      "eval_samples_per_second": 917.325,
      "eval_steps_per_second": 7.169,
      "step": 8000
    },
    {
      "epoch": 2.2895541491858067,
      "grad_norm": 2.4569458961486816,
      "learning_rate": 1.7135001896094048e-05,
      "loss": 0.2925,
      "step": 8050
    },
    {
      "epoch": 2.3037758657469958,
      "grad_norm": 2.1478066444396973,
      "learning_rate": 1.7103400328656305e-05,
      "loss": 0.2721,
      "step": 8100
    },
    {
      "epoch": 2.3179975823081844,
      "grad_norm": 2.4985570907592773,
      "learning_rate": 1.7071798761218558e-05,
      "loss": 0.2728,
      "step": 8150
    },
    {
      "epoch": 2.3322192988693735,
      "grad_norm": 2.448009729385376,
      "learning_rate": 1.704019719378081e-05,
      "loss": 0.2775,
      "step": 8200
    },
    {
      "epoch": 2.3464410154305626,
      "grad_norm": 3.3597328662872314,
      "learning_rate": 1.7008595626343068e-05,
      "loss": 0.2735,
      "step": 8250
    },
    {
      "epoch": 2.3606627319917513,
      "grad_norm": 2.132582664489746,
      "learning_rate": 1.697699405890532e-05,
      "loss": 0.2763,
      "step": 8300
    },
    {
      "epoch": 2.3748844485529403,
      "grad_norm": 2.0898544788360596,
      "learning_rate": 1.6945392491467578e-05,
      "loss": 0.2747,
      "step": 8350
    },
    {
      "epoch": 2.3891061651141294,
      "grad_norm": 2.470771551132202,
      "learning_rate": 1.6913790924029834e-05,
      "loss": 0.2764,
      "step": 8400
    },
    {
      "epoch": 2.403327881675318,
      "grad_norm": 3.225238084793091,
      "learning_rate": 1.6882189356592088e-05,
      "loss": 0.2811,
      "step": 8450
    },
    {
      "epoch": 2.417549598236507,
      "grad_norm": 2.9582526683807373,
      "learning_rate": 1.685058778915434e-05,
      "loss": 0.2764,
      "step": 8500
    },
    {
      "epoch": 2.4317713147976963,
      "grad_norm": 2.2282512187957764,
      "learning_rate": 1.6818986221716598e-05,
      "loss": 0.2875,
      "step": 8550
    },
    {
      "epoch": 2.445993031358885,
      "grad_norm": 2.035191535949707,
      "learning_rate": 1.6787384654278854e-05,
      "loss": 0.2724,
      "step": 8600
    },
    {
      "epoch": 2.460214747920074,
      "grad_norm": 2.054356813430786,
      "learning_rate": 1.6755783086841108e-05,
      "loss": 0.2799,
      "step": 8650
    },
    {
      "epoch": 2.474436464481263,
      "grad_norm": 3.1802945137023926,
      "learning_rate": 1.6724181519403364e-05,
      "loss": 0.2851,
      "step": 8700
    },
    {
      "epoch": 2.4886581810424517,
      "grad_norm": 2.7975940704345703,
      "learning_rate": 1.669257995196562e-05,
      "loss": 0.2777,
      "step": 8750
    },
    {
      "epoch": 2.502879897603641,
      "grad_norm": 2.2024688720703125,
      "learning_rate": 1.6660978384527874e-05,
      "loss": 0.2786,
      "step": 8800
    },
    {
      "epoch": 2.5171016141648295,
      "grad_norm": 2.973994493484497,
      "learning_rate": 1.6629376817090127e-05,
      "loss": 0.2774,
      "step": 8850
    },
    {
      "epoch": 2.5313233307260186,
      "grad_norm": 2.72121262550354,
      "learning_rate": 1.6597775249652384e-05,
      "loss": 0.2788,
      "step": 8900
    },
    {
      "epoch": 2.5455450472872077,
      "grad_norm": 3.809072256088257,
      "learning_rate": 1.656617368221464e-05,
      "loss": 0.2864,
      "step": 8950
    },
    {
      "epoch": 2.5597667638483967,
      "grad_norm": 1.9985495805740356,
      "learning_rate": 1.6534572114776894e-05,
      "loss": 0.2711,
      "step": 9000
    },
    {
      "epoch": 2.5597667638483967,
      "eval_f1_macro": 0.834562237066304,
      "eval_loss": 0.3322518467903137,
      "eval_runtime": 218.1496,
      "eval_samples_per_second": 916.802,
      "eval_steps_per_second": 7.165,
      "step": 9000
    },
    {
      "epoch": 2.5739884804095854,
      "grad_norm": 2.6541566848754883,
      "learning_rate": 1.650297054733915e-05,
      "loss": 0.2766,
      "step": 9050
    },
    {
      "epoch": 2.5882101969707745,
      "grad_norm": 2.695305109024048,
      "learning_rate": 1.6471368979901404e-05,
      "loss": 0.2679,
      "step": 9100
    },
    {
      "epoch": 2.602431913531963,
      "grad_norm": 4.020824909210205,
      "learning_rate": 1.6439767412463657e-05,
      "loss": 0.2899,
      "step": 9150
    },
    {
      "epoch": 2.616653630093152,
      "grad_norm": 2.2719852924346924,
      "learning_rate": 1.6408165845025914e-05,
      "loss": 0.2969,
      "step": 9200
    },
    {
      "epoch": 2.6308753466543413,
      "grad_norm": 1.992153286933899,
      "learning_rate": 1.637656427758817e-05,
      "loss": 0.2932,
      "step": 9250
    },
    {
      "epoch": 2.64509706321553,
      "grad_norm": 2.2114875316619873,
      "learning_rate": 1.6344962710150424e-05,
      "loss": 0.2916,
      "step": 9300
    },
    {
      "epoch": 2.659318779776719,
      "grad_norm": 2.428882122039795,
      "learning_rate": 1.631336114271268e-05,
      "loss": 0.2872,
      "step": 9350
    },
    {
      "epoch": 2.673540496337908,
      "grad_norm": 2.7785842418670654,
      "learning_rate": 1.6281759575274937e-05,
      "loss": 0.2723,
      "step": 9400
    },
    {
      "epoch": 2.687762212899097,
      "grad_norm": 3.5083069801330566,
      "learning_rate": 1.625015800783719e-05,
      "loss": 0.2709,
      "step": 9450
    },
    {
      "epoch": 2.701983929460286,
      "grad_norm": 2.195455312728882,
      "learning_rate": 1.6218556440399443e-05,
      "loss": 0.2764,
      "step": 9500
    },
    {
      "epoch": 2.716205646021475,
      "grad_norm": 2.9660732746124268,
      "learning_rate": 1.61869548729617e-05,
      "loss": 0.2696,
      "step": 9550
    },
    {
      "epoch": 2.7304273625826636,
      "grad_norm": 2.4678425788879395,
      "learning_rate": 1.6155353305523957e-05,
      "loss": 0.2791,
      "step": 9600
    },
    {
      "epoch": 2.7446490791438527,
      "grad_norm": 2.488131523132324,
      "learning_rate": 1.612375173808621e-05,
      "loss": 0.2878,
      "step": 9650
    },
    {
      "epoch": 2.7588707957050413,
      "grad_norm": 2.6680731773376465,
      "learning_rate": 1.6092150170648467e-05,
      "loss": 0.2673,
      "step": 9700
    },
    {
      "epoch": 2.7730925122662304,
      "grad_norm": 2.3827109336853027,
      "learning_rate": 1.6060548603210723e-05,
      "loss": 0.2816,
      "step": 9750
    },
    {
      "epoch": 2.7873142288274195,
      "grad_norm": 2.8812308311462402,
      "learning_rate": 1.6028947035772976e-05,
      "loss": 0.2781,
      "step": 9800
    },
    {
      "epoch": 2.8015359453886086,
      "grad_norm": 2.660655975341797,
      "learning_rate": 1.599734546833523e-05,
      "loss": 0.2812,
      "step": 9850
    },
    {
      "epoch": 2.8157576619497973,
      "grad_norm": 2.3815481662750244,
      "learning_rate": 1.5965743900897486e-05,
      "loss": 0.2782,
      "step": 9900
    },
    {
      "epoch": 2.8299793785109864,
      "grad_norm": 2.8941662311553955,
      "learning_rate": 1.593414233345974e-05,
      "loss": 0.276,
      "step": 9950
    },
    {
      "epoch": 2.844201095072175,
      "grad_norm": 3.2444498538970947,
      "learning_rate": 1.5902540766021996e-05,
      "loss": 0.2711,
      "step": 10000
    },
    {
      "epoch": 2.844201095072175,
      "eval_f1_macro": 0.853762461217568,
      "eval_loss": 0.312804251909256,
      "eval_runtime": 218.0347,
      "eval_samples_per_second": 917.285,
      "eval_steps_per_second": 7.169,
      "step": 10000
    },
    {
      "epoch": 2.858422811633364,
      "grad_norm": 3.2045769691467285,
      "learning_rate": 1.5870939198584253e-05,
      "loss": 0.2783,
      "step": 10050
    },
    {
      "epoch": 2.872644528194553,
      "grad_norm": 2.364990234375,
      "learning_rate": 1.5839337631146506e-05,
      "loss": 0.2853,
      "step": 10100
    },
    {
      "epoch": 2.8868662447557423,
      "grad_norm": 1.9411289691925049,
      "learning_rate": 1.580773606370876e-05,
      "loss": 0.266,
      "step": 10150
    },
    {
      "epoch": 2.901087961316931,
      "grad_norm": 2.8442940711975098,
      "learning_rate": 1.5776134496271016e-05,
      "loss": 0.2828,
      "step": 10200
    },
    {
      "epoch": 2.91530967787812,
      "grad_norm": 2.601864814758301,
      "learning_rate": 1.5744532928833273e-05,
      "loss": 0.2698,
      "step": 10250
    },
    {
      "epoch": 2.9295313944393087,
      "grad_norm": 2.4073727130889893,
      "learning_rate": 1.5712931361395526e-05,
      "loss": 0.2861,
      "step": 10300
    },
    {
      "epoch": 2.9437531110004977,
      "grad_norm": 4.330893516540527,
      "learning_rate": 1.5681329793957783e-05,
      "loss": 0.2795,
      "step": 10350
    },
    {
      "epoch": 2.957974827561687,
      "grad_norm": 2.731947898864746,
      "learning_rate": 1.5649728226520036e-05,
      "loss": 0.2663,
      "step": 10400
    },
    {
      "epoch": 2.9721965441228755,
      "grad_norm": 2.5936076641082764,
      "learning_rate": 1.5618126659082292e-05,
      "loss": 0.2731,
      "step": 10450
    },
    {
      "epoch": 2.9864182606840646,
      "grad_norm": 1.9040313959121704,
      "learning_rate": 1.5586525091644546e-05,
      "loss": 0.273,
      "step": 10500
    },
    {
      "epoch": 3.0005688686624477,
      "grad_norm": 11.856426239013672,
      "learning_rate": 1.5554923524206802e-05,
      "loss": 0.2757,
      "step": 10550
    },
    {
      "epoch": 3.0147905852236363,
      "grad_norm": 4.996047496795654,
      "learning_rate": 1.552332195676906e-05,
      "loss": 0.2426,
      "step": 10600
    },
    {
      "epoch": 3.0290123017848254,
      "grad_norm": 2.444047689437866,
      "learning_rate": 1.5491720389331312e-05,
      "loss": 0.2381,
      "step": 10650
    },
    {
      "epoch": 3.0432340183460145,
      "grad_norm": 1.9507687091827393,
      "learning_rate": 1.546011882189357e-05,
      "loss": 0.2347,
      "step": 10700
    },
    {
      "epoch": 3.057455734907203,
      "grad_norm": 3.0197629928588867,
      "learning_rate": 1.5428517254455822e-05,
      "loss": 0.2407,
      "step": 10750
    },
    {
      "epoch": 3.071677451468392,
      "grad_norm": 2.8972744941711426,
      "learning_rate": 1.5396915687018075e-05,
      "loss": 0.2404,
      "step": 10800
    },
    {
      "epoch": 3.0858991680295813,
      "grad_norm": 2.107598066329956,
      "learning_rate": 1.5365314119580332e-05,
      "loss": 0.2407,
      "step": 10850
    },
    {
      "epoch": 3.10012088459077,
      "grad_norm": 4.294186592102051,
      "learning_rate": 1.533371255214259e-05,
      "loss": 0.2391,
      "step": 10900
    },
    {
      "epoch": 3.114342601151959,
      "grad_norm": 3.793856382369995,
      "learning_rate": 1.5302110984704842e-05,
      "loss": 0.2292,
      "step": 10950
    },
    {
      "epoch": 3.128564317713148,
      "grad_norm": 1.6952309608459473,
      "learning_rate": 1.52705094172671e-05,
      "loss": 0.2466,
      "step": 11000
    },
    {
      "epoch": 3.128564317713148,
      "eval_f1_macro": 0.8486753577750731,
      "eval_loss": 0.33656829595565796,
      "eval_runtime": 218.0225,
      "eval_samples_per_second": 917.337,
      "eval_steps_per_second": 7.169,
      "step": 11000
    },
    {
      "epoch": 3.142786034274337,
      "grad_norm": 3.139033079147339,
      "learning_rate": 1.5238907849829352e-05,
      "loss": 0.2373,
      "step": 11050
    },
    {
      "epoch": 3.157007750835526,
      "grad_norm": 3.3134493827819824,
      "learning_rate": 1.5207306282391607e-05,
      "loss": 0.2373,
      "step": 11100
    },
    {
      "epoch": 3.171229467396715,
      "grad_norm": 2.68369197845459,
      "learning_rate": 1.5175704714953863e-05,
      "loss": 0.2257,
      "step": 11150
    },
    {
      "epoch": 3.1854511839579036,
      "grad_norm": 2.5385711193084717,
      "learning_rate": 1.5144103147516118e-05,
      "loss": 0.2429,
      "step": 11200
    },
    {
      "epoch": 3.1996729005190927,
      "grad_norm": 4.118649482727051,
      "learning_rate": 1.5112501580078373e-05,
      "loss": 0.2461,
      "step": 11250
    },
    {
      "epoch": 3.213894617080282,
      "grad_norm": 3.0749053955078125,
      "learning_rate": 1.5080900012640628e-05,
      "loss": 0.2397,
      "step": 11300
    },
    {
      "epoch": 3.2281163336414704,
      "grad_norm": 2.492638349533081,
      "learning_rate": 1.5049298445202882e-05,
      "loss": 0.2396,
      "step": 11350
    },
    {
      "epoch": 3.2423380502026595,
      "grad_norm": 2.876415491104126,
      "learning_rate": 1.5017696877765138e-05,
      "loss": 0.2366,
      "step": 11400
    },
    {
      "epoch": 3.256559766763848,
      "grad_norm": 2.9285457134246826,
      "learning_rate": 1.4986095310327393e-05,
      "loss": 0.2256,
      "step": 11450
    },
    {
      "epoch": 3.2707814833250373,
      "grad_norm": 4.236849784851074,
      "learning_rate": 1.4954493742889648e-05,
      "loss": 0.2244,
      "step": 11500
    },
    {
      "epoch": 3.2850031998862264,
      "grad_norm": 3.1449596881866455,
      "learning_rate": 1.4922892175451905e-05,
      "loss": 0.2363,
      "step": 11550
    },
    {
      "epoch": 3.2992249164474154,
      "grad_norm": 3.019659996032715,
      "learning_rate": 1.489129060801416e-05,
      "loss": 0.231,
      "step": 11600
    },
    {
      "epoch": 3.313446633008604,
      "grad_norm": 2.346696376800537,
      "learning_rate": 1.4859689040576413e-05,
      "loss": 0.2488,
      "step": 11650
    },
    {
      "epoch": 3.327668349569793,
      "grad_norm": 2.8566365242004395,
      "learning_rate": 1.4828087473138668e-05,
      "loss": 0.234,
      "step": 11700
    },
    {
      "epoch": 3.341890066130982,
      "grad_norm": 2.9802443981170654,
      "learning_rate": 1.4796485905700923e-05,
      "loss": 0.2354,
      "step": 11750
    },
    {
      "epoch": 3.356111782692171,
      "grad_norm": 3.0608725547790527,
      "learning_rate": 1.476488433826318e-05,
      "loss": 0.239,
      "step": 11800
    },
    {
      "epoch": 3.37033349925336,
      "grad_norm": 3.5101890563964844,
      "learning_rate": 1.4733282770825434e-05,
      "loss": 0.2314,
      "step": 11850
    },
    {
      "epoch": 3.3845552158145487,
      "grad_norm": 3.3520848751068115,
      "learning_rate": 1.470168120338769e-05,
      "loss": 0.23,
      "step": 11900
    },
    {
      "epoch": 3.3987769323757377,
      "grad_norm": 3.6505322456359863,
      "learning_rate": 1.4670079635949946e-05,
      "loss": 0.2376,
      "step": 11950
    },
    {
      "epoch": 3.412998648936927,
      "grad_norm": 2.765575408935547,
      "learning_rate": 1.46384780685122e-05,
      "loss": 0.2434,
      "step": 12000
    },
    {
      "epoch": 3.412998648936927,
      "eval_f1_macro": 0.8491453864064282,
      "eval_loss": 0.311077356338501,
      "eval_runtime": 218.0656,
      "eval_samples_per_second": 917.155,
      "eval_steps_per_second": 7.168,
      "step": 12000
    },
    {
      "epoch": 3.4272203654981155,
      "grad_norm": 2.994039535522461,
      "learning_rate": 1.4606876501074454e-05,
      "loss": 0.2329,
      "step": 12050
    },
    {
      "epoch": 3.4414420820593046,
      "grad_norm": 2.464277505874634,
      "learning_rate": 1.457527493363671e-05,
      "loss": 0.2375,
      "step": 12100
    },
    {
      "epoch": 3.4556637986204937,
      "grad_norm": 2.798668384552002,
      "learning_rate": 1.4543673366198964e-05,
      "loss": 0.2247,
      "step": 12150
    },
    {
      "epoch": 3.4698855151816823,
      "grad_norm": 2.467594861984253,
      "learning_rate": 1.451207179876122e-05,
      "loss": 0.2299,
      "step": 12200
    },
    {
      "epoch": 3.4841072317428714,
      "grad_norm": 3.2514264583587646,
      "learning_rate": 1.4480470231323476e-05,
      "loss": 0.2339,
      "step": 12250
    },
    {
      "epoch": 3.4983289483040605,
      "grad_norm": 2.9567654132843018,
      "learning_rate": 1.4448868663885729e-05,
      "loss": 0.2356,
      "step": 12300
    },
    {
      "epoch": 3.512550664865249,
      "grad_norm": 3.0129828453063965,
      "learning_rate": 1.4417267096447984e-05,
      "loss": 0.2315,
      "step": 12350
    },
    {
      "epoch": 3.5267723814264382,
      "grad_norm": 3.9774324893951416,
      "learning_rate": 1.438566552901024e-05,
      "loss": 0.2426,
      "step": 12400
    },
    {
      "epoch": 3.5409940979876273,
      "grad_norm": 2.431269884109497,
      "learning_rate": 1.4354063961572496e-05,
      "loss": 0.2342,
      "step": 12450
    },
    {
      "epoch": 3.555215814548816,
      "grad_norm": 3.0499961376190186,
      "learning_rate": 1.432246239413475e-05,
      "loss": 0.2374,
      "step": 12500
    },
    {
      "epoch": 3.569437531110005,
      "grad_norm": 2.03695011138916,
      "learning_rate": 1.4290860826697005e-05,
      "loss": 0.2325,
      "step": 12550
    },
    {
      "epoch": 3.5836592476711937,
      "grad_norm": 2.591414451599121,
      "learning_rate": 1.4259259259259259e-05,
      "loss": 0.2317,
      "step": 12600
    },
    {
      "epoch": 3.597880964232383,
      "grad_norm": 2.980947732925415,
      "learning_rate": 1.4227657691821515e-05,
      "loss": 0.2408,
      "step": 12650
    },
    {
      "epoch": 3.612102680793572,
      "grad_norm": 2.572643518447876,
      "learning_rate": 1.419605612438377e-05,
      "loss": 0.2481,
      "step": 12700
    },
    {
      "epoch": 3.626324397354761,
      "grad_norm": 2.6535654067993164,
      "learning_rate": 1.4164454556946025e-05,
      "loss": 0.2297,
      "step": 12750
    },
    {
      "epoch": 3.6405461139159496,
      "grad_norm": 3.8443539142608643,
      "learning_rate": 1.4132852989508282e-05,
      "loss": 0.2328,
      "step": 12800
    },
    {
      "epoch": 3.6547678304771387,
      "grad_norm": 2.3406882286071777,
      "learning_rate": 1.4101251422070537e-05,
      "loss": 0.2396,
      "step": 12850
    },
    {
      "epoch": 3.6689895470383274,
      "grad_norm": 2.872074842453003,
      "learning_rate": 1.4069649854632792e-05,
      "loss": 0.2326,
      "step": 12900
    },
    {
      "epoch": 3.6832112635995164,
      "grad_norm": 2.356523275375366,
      "learning_rate": 1.4038048287195045e-05,
      "loss": 0.2396,
      "step": 12950
    },
    {
      "epoch": 3.6974329801607055,
      "grad_norm": 3.292111396789551,
      "learning_rate": 1.40064467197573e-05,
      "loss": 0.2376,
      "step": 13000
    },
    {
      "epoch": 3.6974329801607055,
      "eval_f1_macro": 0.8413167599954908,
      "eval_loss": 0.3361353874206543,
      "eval_runtime": 218.1433,
      "eval_samples_per_second": 916.828,
      "eval_steps_per_second": 7.165,
      "step": 13000
    },
    {
      "epoch": 3.711654696721894,
      "grad_norm": 3.1652376651763916,
      "learning_rate": 1.3974845152319557e-05,
      "loss": 0.2533,
      "step": 13050
    },
    {
      "epoch": 3.7258764132830833,
      "grad_norm": 2.5104832649230957,
      "learning_rate": 1.3943243584881812e-05,
      "loss": 0.2337,
      "step": 13100
    },
    {
      "epoch": 3.7400981298442724,
      "grad_norm": 2.7479050159454346,
      "learning_rate": 1.3911642017444067e-05,
      "loss": 0.2326,
      "step": 13150
    },
    {
      "epoch": 3.754319846405461,
      "grad_norm": 2.0143444538116455,
      "learning_rate": 1.3880040450006323e-05,
      "loss": 0.2394,
      "step": 13200
    },
    {
      "epoch": 3.76854156296665,
      "grad_norm": 2.0674896240234375,
      "learning_rate": 1.3848438882568576e-05,
      "loss": 0.2354,
      "step": 13250
    },
    {
      "epoch": 3.782763279527839,
      "grad_norm": 2.635674476623535,
      "learning_rate": 1.3816837315130831e-05,
      "loss": 0.2305,
      "step": 13300
    },
    {
      "epoch": 3.796984996089028,
      "grad_norm": 2.0069057941436768,
      "learning_rate": 1.3785235747693086e-05,
      "loss": 0.2282,
      "step": 13350
    },
    {
      "epoch": 3.811206712650217,
      "grad_norm": 3.646801233291626,
      "learning_rate": 1.3753634180255341e-05,
      "loss": 0.2382,
      "step": 13400
    },
    {
      "epoch": 3.8254284292114056,
      "grad_norm": 3.4413042068481445,
      "learning_rate": 1.3722032612817598e-05,
      "loss": 0.2362,
      "step": 13450
    },
    {
      "epoch": 3.8396501457725947,
      "grad_norm": 2.859231948852539,
      "learning_rate": 1.3690431045379853e-05,
      "loss": 0.2399,
      "step": 13500
    },
    {
      "epoch": 3.8538718623337838,
      "grad_norm": 2.166712760925293,
      "learning_rate": 1.3658829477942106e-05,
      "loss": 0.2393,
      "step": 13550
    },
    {
      "epoch": 3.868093578894973,
      "grad_norm": 2.0480339527130127,
      "learning_rate": 1.3627227910504361e-05,
      "loss": 0.2309,
      "step": 13600
    },
    {
      "epoch": 3.8823152954561615,
      "grad_norm": 3.02870774269104,
      "learning_rate": 1.3595626343066618e-05,
      "loss": 0.229,
      "step": 13650
    },
    {
      "epoch": 3.8965370120173506,
      "grad_norm": 3.3041832447052,
      "learning_rate": 1.3564024775628873e-05,
      "loss": 0.2316,
      "step": 13700
    },
    {
      "epoch": 3.9107587285785392,
      "grad_norm": 3.4874303340911865,
      "learning_rate": 1.3532423208191128e-05,
      "loss": 0.2431,
      "step": 13750
    },
    {
      "epoch": 3.9249804451397283,
      "grad_norm": 2.009392738342285,
      "learning_rate": 1.3500821640753383e-05,
      "loss": 0.2304,
      "step": 13800
    },
    {
      "epoch": 3.9392021617009174,
      "grad_norm": 2.7667388916015625,
      "learning_rate": 1.346922007331564e-05,
      "loss": 0.2302,
      "step": 13850
    },
    {
      "epoch": 3.9534238782621065,
      "grad_norm": 3.2748615741729736,
      "learning_rate": 1.3437618505877892e-05,
      "loss": 0.2287,
      "step": 13900
    },
    {
      "epoch": 3.967645594823295,
      "grad_norm": 2.7581748962402344,
      "learning_rate": 1.3406016938440147e-05,
      "loss": 0.2334,
      "step": 13950
    },
    {
      "epoch": 3.9818673113844842,
      "grad_norm": 2.7279813289642334,
      "learning_rate": 1.3374415371002402e-05,
      "loss": 0.2475,
      "step": 14000
    },
    {
      "epoch": 3.9818673113844842,
      "eval_f1_macro": 0.8592346760638814,
      "eval_loss": 0.3137340545654297,
      "eval_runtime": 218.1548,
      "eval_samples_per_second": 916.78,
      "eval_steps_per_second": 7.165,
      "step": 14000
    },
    {
      "epoch": 3.996089027945673,
      "grad_norm": 2.9634127616882324,
      "learning_rate": 1.3342813803564657e-05,
      "loss": 0.2329,
      "step": 14050
    },
    {
      "epoch": 4.010239635924056,
      "grad_norm": 4.600017547607422,
      "learning_rate": 1.3311212236126914e-05,
      "loss": 0.1942,
      "step": 14100
    },
    {
      "epoch": 4.024461352485245,
      "grad_norm": 3.6994943618774414,
      "learning_rate": 1.3279610668689169e-05,
      "loss": 0.1974,
      "step": 14150
    },
    {
      "epoch": 4.038683069046434,
      "grad_norm": 3.716561794281006,
      "learning_rate": 1.3248009101251422e-05,
      "loss": 0.2013,
      "step": 14200
    },
    {
      "epoch": 4.052904785607623,
      "grad_norm": 3.2737061977386475,
      "learning_rate": 1.3216407533813677e-05,
      "loss": 0.1955,
      "step": 14250
    },
    {
      "epoch": 4.067126502168811,
      "grad_norm": 3.7008895874023438,
      "learning_rate": 1.3184805966375934e-05,
      "loss": 0.1959,
      "step": 14300
    },
    {
      "epoch": 4.0813482187300005,
      "grad_norm": 3.3809409141540527,
      "learning_rate": 1.3153204398938189e-05,
      "loss": 0.193,
      "step": 14350
    },
    {
      "epoch": 4.09556993529119,
      "grad_norm": 2.751371145248413,
      "learning_rate": 1.3121602831500444e-05,
      "loss": 0.1973,
      "step": 14400
    },
    {
      "epoch": 4.109791651852379,
      "grad_norm": 2.93459415435791,
      "learning_rate": 1.3090001264062699e-05,
      "loss": 0.1886,
      "step": 14450
    },
    {
      "epoch": 4.124013368413568,
      "grad_norm": 2.4245729446411133,
      "learning_rate": 1.3058399696624952e-05,
      "loss": 0.1926,
      "step": 14500
    },
    {
      "epoch": 4.138235084974756,
      "grad_norm": 4.771632671356201,
      "learning_rate": 1.3026798129187209e-05,
      "loss": 0.1913,
      "step": 14550
    },
    {
      "epoch": 4.152456801535945,
      "grad_norm": 4.5785956382751465,
      "learning_rate": 1.2995196561749463e-05,
      "loss": 0.1934,
      "step": 14600
    },
    {
      "epoch": 4.166678518097134,
      "grad_norm": 3.540764570236206,
      "learning_rate": 1.2963594994311718e-05,
      "loss": 0.1911,
      "step": 14650
    },
    {
      "epoch": 4.180900234658323,
      "grad_norm": 4.097346782684326,
      "learning_rate": 1.2931993426873975e-05,
      "loss": 0.1955,
      "step": 14700
    },
    {
      "epoch": 4.195121951219512,
      "grad_norm": 2.774057149887085,
      "learning_rate": 1.290039185943623e-05,
      "loss": 0.191,
      "step": 14750
    },
    {
      "epoch": 4.2093436677807015,
      "grad_norm": 3.426776647567749,
      "learning_rate": 1.2868790291998485e-05,
      "loss": 0.1954,
      "step": 14800
    },
    {
      "epoch": 4.22356538434189,
      "grad_norm": 3.0721595287323,
      "learning_rate": 1.2837188724560738e-05,
      "loss": 0.1933,
      "step": 14850
    },
    {
      "epoch": 4.237787100903079,
      "grad_norm": 2.71537446975708,
      "learning_rate": 1.2805587157122993e-05,
      "loss": 0.1951,
      "step": 14900
    },
    {
      "epoch": 4.252008817464268,
      "grad_norm": 3.063156843185425,
      "learning_rate": 1.277398558968525e-05,
      "loss": 0.1974,
      "step": 14950
    },
    {
      "epoch": 4.266230534025457,
      "grad_norm": 2.919572114944458,
      "learning_rate": 1.2742384022247505e-05,
      "loss": 0.2007,
      "step": 15000
    },
    {
      "epoch": 4.266230534025457,
      "eval_f1_macro": 0.8493426370956061,
      "eval_loss": 0.3511503040790558,
      "eval_runtime": 217.9947,
      "eval_samples_per_second": 917.454,
      "eval_steps_per_second": 7.17,
      "step": 15000
    },
    {
      "epoch": 4.280452250586646,
      "grad_norm": 3.447943687438965,
      "learning_rate": 1.271078245480976e-05,
      "loss": 0.1961,
      "step": 15050
    },
    {
      "epoch": 4.294673967147835,
      "grad_norm": 2.8716681003570557,
      "learning_rate": 1.2679180887372016e-05,
      "loss": 0.1904,
      "step": 15100
    },
    {
      "epoch": 4.308895683709023,
      "grad_norm": 2.6715140342712402,
      "learning_rate": 1.264757931993427e-05,
      "loss": 0.1984,
      "step": 15150
    },
    {
      "epoch": 4.323117400270212,
      "grad_norm": 3.838892936706543,
      "learning_rate": 1.2615977752496525e-05,
      "loss": 0.2004,
      "step": 15200
    },
    {
      "epoch": 4.3373391168314015,
      "grad_norm": 2.709991931915283,
      "learning_rate": 1.258437618505878e-05,
      "loss": 0.1999,
      "step": 15250
    },
    {
      "epoch": 4.351560833392591,
      "grad_norm": 2.131117105484009,
      "learning_rate": 1.2552774617621034e-05,
      "loss": 0.2007,
      "step": 15300
    },
    {
      "epoch": 4.36578254995378,
      "grad_norm": 2.0793440341949463,
      "learning_rate": 1.2521173050183291e-05,
      "loss": 0.193,
      "step": 15350
    },
    {
      "epoch": 4.380004266514969,
      "grad_norm": 2.58252215385437,
      "learning_rate": 1.2489571482745546e-05,
      "loss": 0.1976,
      "step": 15400
    },
    {
      "epoch": 4.394225983076157,
      "grad_norm": 2.5519461631774902,
      "learning_rate": 1.24579699153078e-05,
      "loss": 0.1996,
      "step": 15450
    },
    {
      "epoch": 4.408447699637346,
      "grad_norm": 2.998828411102295,
      "learning_rate": 1.2426368347870054e-05,
      "loss": 0.193,
      "step": 15500
    },
    {
      "epoch": 4.422669416198535,
      "grad_norm": 2.4155051708221436,
      "learning_rate": 1.2394766780432311e-05,
      "loss": 0.1953,
      "step": 15550
    },
    {
      "epoch": 4.436891132759724,
      "grad_norm": 2.964078187942505,
      "learning_rate": 1.2363165212994566e-05,
      "loss": 0.1985,
      "step": 15600
    },
    {
      "epoch": 4.451112849320913,
      "grad_norm": 2.4279849529266357,
      "learning_rate": 1.233156364555682e-05,
      "loss": 0.2011,
      "step": 15650
    },
    {
      "epoch": 4.465334565882102,
      "grad_norm": 3.220268487930298,
      "learning_rate": 1.2299962078119076e-05,
      "loss": 0.2111,
      "step": 15700
    },
    {
      "epoch": 4.479556282443291,
      "grad_norm": 3.4722588062286377,
      "learning_rate": 1.2268360510681329e-05,
      "loss": 0.1846,
      "step": 15750
    },
    {
      "epoch": 4.49377799900448,
      "grad_norm": 2.5521414279937744,
      "learning_rate": 1.2236758943243586e-05,
      "loss": 0.199,
      "step": 15800
    },
    {
      "epoch": 4.507999715565669,
      "grad_norm": 2.542476177215576,
      "learning_rate": 1.220515737580584e-05,
      "loss": 0.2114,
      "step": 15850
    },
    {
      "epoch": 4.522221432126858,
      "grad_norm": 3.1841917037963867,
      "learning_rate": 1.2173555808368096e-05,
      "loss": 0.1977,
      "step": 15900
    },
    {
      "epoch": 4.536443148688047,
      "grad_norm": 5.227343559265137,
      "learning_rate": 1.2141954240930352e-05,
      "loss": 0.195,
      "step": 15950
    },
    {
      "epoch": 4.550664865249235,
      "grad_norm": 2.6753056049346924,
      "learning_rate": 1.2110352673492607e-05,
      "loss": 0.2003,
      "step": 16000
    },
    {
      "epoch": 4.550664865249235,
      "eval_f1_macro": 0.8551907570803706,
      "eval_loss": 0.33672523498535156,
      "eval_runtime": 218.124,
      "eval_samples_per_second": 916.91,
      "eval_steps_per_second": 7.166,
      "step": 16000
    },
    {
      "epoch": 4.564886581810424,
      "grad_norm": 3.624788284301758,
      "learning_rate": 1.2078751106054862e-05,
      "loss": 0.2017,
      "step": 16050
    },
    {
      "epoch": 4.579108298371613,
      "grad_norm": 2.9135899543762207,
      "learning_rate": 1.2047149538617115e-05,
      "loss": 0.2078,
      "step": 16100
    },
    {
      "epoch": 4.5933300149328025,
      "grad_norm": 3.3433828353881836,
      "learning_rate": 1.201554797117937e-05,
      "loss": 0.1932,
      "step": 16150
    },
    {
      "epoch": 4.6075517314939916,
      "grad_norm": 3.720510482788086,
      "learning_rate": 1.1983946403741627e-05,
      "loss": 0.201,
      "step": 16200
    },
    {
      "epoch": 4.621773448055181,
      "grad_norm": 4.014780044555664,
      "learning_rate": 1.1952344836303882e-05,
      "loss": 0.2014,
      "step": 16250
    },
    {
      "epoch": 4.635995164616369,
      "grad_norm": 2.7629048824310303,
      "learning_rate": 1.1920743268866137e-05,
      "loss": 0.1921,
      "step": 16300
    },
    {
      "epoch": 4.650216881177558,
      "grad_norm": 3.191256284713745,
      "learning_rate": 1.1889141701428393e-05,
      "loss": 0.2013,
      "step": 16350
    },
    {
      "epoch": 4.664438597738747,
      "grad_norm": 2.649754285812378,
      "learning_rate": 1.1857540133990647e-05,
      "loss": 0.2003,
      "step": 16400
    },
    {
      "epoch": 4.678660314299936,
      "grad_norm": 2.8266546726226807,
      "learning_rate": 1.1825938566552902e-05,
      "loss": 0.1952,
      "step": 16450
    },
    {
      "epoch": 4.692882030861125,
      "grad_norm": 2.2990047931671143,
      "learning_rate": 1.1794336999115157e-05,
      "loss": 0.1976,
      "step": 16500
    },
    {
      "epoch": 4.707103747422314,
      "grad_norm": 3.428391218185425,
      "learning_rate": 1.1762735431677412e-05,
      "loss": 0.1915,
      "step": 16550
    },
    {
      "epoch": 4.7213254639835025,
      "grad_norm": 3.3853189945220947,
      "learning_rate": 1.1731133864239668e-05,
      "loss": 0.1916,
      "step": 16600
    },
    {
      "epoch": 4.735547180544692,
      "grad_norm": 3.882333755493164,
      "learning_rate": 1.1699532296801923e-05,
      "loss": 0.2034,
      "step": 16650
    },
    {
      "epoch": 4.749768897105881,
      "grad_norm": 2.1818878650665283,
      "learning_rate": 1.1667930729364176e-05,
      "loss": 0.2006,
      "step": 16700
    },
    {
      "epoch": 4.76399061366707,
      "grad_norm": 3.7927308082580566,
      "learning_rate": 1.1636329161926431e-05,
      "loss": 0.1938,
      "step": 16750
    },
    {
      "epoch": 4.778212330228259,
      "grad_norm": 2.292189359664917,
      "learning_rate": 1.1604727594488688e-05,
      "loss": 0.2047,
      "step": 16800
    },
    {
      "epoch": 4.792434046789447,
      "grad_norm": 4.425091743469238,
      "learning_rate": 1.1573126027050943e-05,
      "loss": 0.1965,
      "step": 16850
    },
    {
      "epoch": 4.806655763350636,
      "grad_norm": 4.154648780822754,
      "learning_rate": 1.1541524459613198e-05,
      "loss": 0.2016,
      "step": 16900
    },
    {
      "epoch": 4.820877479911825,
      "grad_norm": 3.34840989112854,
      "learning_rate": 1.1509922892175453e-05,
      "loss": 0.1966,
      "step": 16950
    },
    {
      "epoch": 4.835099196473014,
      "grad_norm": 5.334840297698975,
      "learning_rate": 1.147832132473771e-05,
      "loss": 0.1984,
      "step": 17000
    },
    {
      "epoch": 4.835099196473014,
      "eval_f1_macro": 0.860340681072345,
      "eval_loss": 0.36616188287734985,
      "eval_runtime": 218.15,
      "eval_samples_per_second": 916.8,
      "eval_steps_per_second": 7.165,
      "step": 17000
    },
    {
      "epoch": 4.849320913034203,
      "grad_norm": 3.8486268520355225,
      "learning_rate": 1.1446719757299963e-05,
      "loss": 0.2141,
      "step": 17050
    },
    {
      "epoch": 4.8635426295953925,
      "grad_norm": 2.6898300647735596,
      "learning_rate": 1.1415118189862218e-05,
      "loss": 0.1843,
      "step": 17100
    },
    {
      "epoch": 4.877764346156581,
      "grad_norm": 2.911985158920288,
      "learning_rate": 1.1383516622424473e-05,
      "loss": 0.203,
      "step": 17150
    },
    {
      "epoch": 4.89198606271777,
      "grad_norm": 3.1392931938171387,
      "learning_rate": 1.135191505498673e-05,
      "loss": 0.1889,
      "step": 17200
    },
    {
      "epoch": 4.906207779278959,
      "grad_norm": 2.7037205696105957,
      "learning_rate": 1.1320313487548984e-05,
      "loss": 0.2018,
      "step": 17250
    },
    {
      "epoch": 4.920429495840148,
      "grad_norm": 3.7477002143859863,
      "learning_rate": 1.128871192011124e-05,
      "loss": 0.1965,
      "step": 17300
    },
    {
      "epoch": 4.934651212401337,
      "grad_norm": 2.505265951156616,
      "learning_rate": 1.1257110352673492e-05,
      "loss": 0.1997,
      "step": 17350
    },
    {
      "epoch": 4.948872928962526,
      "grad_norm": 3.9008188247680664,
      "learning_rate": 1.1225508785235747e-05,
      "loss": 0.1996,
      "step": 17400
    },
    {
      "epoch": 4.963094645523714,
      "grad_norm": 3.584928512573242,
      "learning_rate": 1.1193907217798004e-05,
      "loss": 0.1959,
      "step": 17450
    },
    {
      "epoch": 4.9773163620849035,
      "grad_norm": 4.757489204406738,
      "learning_rate": 1.1162305650360259e-05,
      "loss": 0.1906,
      "step": 17500
    },
    {
      "epoch": 4.991538078646093,
      "grad_norm": 2.898198366165161,
      "learning_rate": 1.1130704082922514e-05,
      "loss": 0.2012,
      "step": 17550
    },
    {
      "epoch": 5.005688686624476,
      "grad_norm": 3.2291033267974854,
      "learning_rate": 1.109910251548477e-05,
      "loss": 0.1899,
      "step": 17600
    },
    {
      "epoch": 5.019910403185665,
      "grad_norm": 3.5180764198303223,
      "learning_rate": 1.1067500948047024e-05,
      "loss": 0.1624,
      "step": 17650
    },
    {
      "epoch": 5.034132119746854,
      "grad_norm": 3.8021538257598877,
      "learning_rate": 1.1035899380609279e-05,
      "loss": 0.1492,
      "step": 17700
    },
    {
      "epoch": 5.048353836308042,
      "grad_norm": 3.8908071517944336,
      "learning_rate": 1.1004297813171534e-05,
      "loss": 0.1495,
      "step": 17750
    },
    {
      "epoch": 5.062575552869231,
      "grad_norm": 3.6993815898895264,
      "learning_rate": 1.0972696245733789e-05,
      "loss": 0.1559,
      "step": 17800
    },
    {
      "epoch": 5.07679726943042,
      "grad_norm": 4.963061809539795,
      "learning_rate": 1.0941094678296045e-05,
      "loss": 0.1617,
      "step": 17850
    },
    {
      "epoch": 5.091018985991609,
      "grad_norm": 4.781299591064453,
      "learning_rate": 1.09094931108583e-05,
      "loss": 0.1558,
      "step": 17900
    },
    {
      "epoch": 5.105240702552798,
      "grad_norm": 7.810328006744385,
      "learning_rate": 1.0877891543420555e-05,
      "loss": 0.1674,
      "step": 17950
    },
    {
      "epoch": 5.1194624191139875,
      "grad_norm": 4.245778560638428,
      "learning_rate": 1.0846289975982808e-05,
      "loss": 0.1665,
      "step": 18000
    },
    {
      "epoch": 5.1194624191139875,
      "eval_f1_macro": 0.8580329180683439,
      "eval_loss": 0.3722202777862549,
      "eval_runtime": 218.1039,
      "eval_samples_per_second": 916.994,
      "eval_steps_per_second": 7.166,
      "step": 18000
    },
    {
      "epoch": 5.133684135675176,
      "grad_norm": 4.144603729248047,
      "learning_rate": 1.0814688408545065e-05,
      "loss": 0.1628,
      "step": 18050
    },
    {
      "epoch": 5.147905852236365,
      "grad_norm": 4.292088985443115,
      "learning_rate": 1.078308684110732e-05,
      "loss": 0.1597,
      "step": 18100
    },
    {
      "epoch": 5.162127568797554,
      "grad_norm": 2.358781337738037,
      "learning_rate": 1.0751485273669575e-05,
      "loss": 0.1543,
      "step": 18150
    },
    {
      "epoch": 5.176349285358743,
      "grad_norm": 3.39306640625,
      "learning_rate": 1.071988370623183e-05,
      "loss": 0.1586,
      "step": 18200
    },
    {
      "epoch": 5.190571001919932,
      "grad_norm": 3.7965011596679688,
      "learning_rate": 1.0688282138794087e-05,
      "loss": 0.1602,
      "step": 18250
    },
    {
      "epoch": 5.204792718481121,
      "grad_norm": 3.055543899536133,
      "learning_rate": 1.065668057135634e-05,
      "loss": 0.1635,
      "step": 18300
    },
    {
      "epoch": 5.219014435042309,
      "grad_norm": 3.177379846572876,
      "learning_rate": 1.0625079003918595e-05,
      "loss": 0.1572,
      "step": 18350
    },
    {
      "epoch": 5.233236151603498,
      "grad_norm": 6.6527886390686035,
      "learning_rate": 1.059347743648085e-05,
      "loss": 0.1628,
      "step": 18400
    },
    {
      "epoch": 5.2474578681646875,
      "grad_norm": 4.757478713989258,
      "learning_rate": 1.0561875869043105e-05,
      "loss": 0.16,
      "step": 18450
    },
    {
      "epoch": 5.261679584725877,
      "grad_norm": 3.6853115558624268,
      "learning_rate": 1.0530274301605361e-05,
      "loss": 0.1627,
      "step": 18500
    },
    {
      "epoch": 5.275901301287066,
      "grad_norm": 4.088004112243652,
      "learning_rate": 1.0498672734167616e-05,
      "loss": 0.1576,
      "step": 18550
    },
    {
      "epoch": 5.290123017848254,
      "grad_norm": 4.392301082611084,
      "learning_rate": 1.046707116672987e-05,
      "loss": 0.1567,
      "step": 18600
    },
    {
      "epoch": 5.304344734409443,
      "grad_norm": 3.0362019538879395,
      "learning_rate": 1.0435469599292125e-05,
      "loss": 0.1639,
      "step": 18650
    },
    {
      "epoch": 5.318566450970632,
      "grad_norm": 4.444710731506348,
      "learning_rate": 1.0403868031854381e-05,
      "loss": 0.164,
      "step": 18700
    },
    {
      "epoch": 5.332788167531821,
      "grad_norm": 2.5174803733825684,
      "learning_rate": 1.0372266464416636e-05,
      "loss": 0.1766,
      "step": 18750
    },
    {
      "epoch": 5.34700988409301,
      "grad_norm": 3.099421739578247,
      "learning_rate": 1.0340664896978891e-05,
      "loss": 0.1604,
      "step": 18800
    },
    {
      "epoch": 5.361231600654199,
      "grad_norm": 3.3878610134124756,
      "learning_rate": 1.0309063329541146e-05,
      "loss": 0.1617,
      "step": 18850
    },
    {
      "epoch": 5.3754533172153875,
      "grad_norm": 3.4501235485076904,
      "learning_rate": 1.02774617621034e-05,
      "loss": 0.1595,
      "step": 18900
    },
    {
      "epoch": 5.389675033776577,
      "grad_norm": 4.53314733505249,
      "learning_rate": 1.0245860194665656e-05,
      "loss": 0.1599,
      "step": 18950
    },
    {
      "epoch": 5.403896750337766,
      "grad_norm": 3.5207109451293945,
      "learning_rate": 1.0214258627227911e-05,
      "loss": 0.1689,
      "step": 19000
    },
    {
      "epoch": 5.403896750337766,
      "eval_f1_macro": 0.8572143799810115,
      "eval_loss": 0.3817954659461975,
      "eval_runtime": 218.0175,
      "eval_samples_per_second": 917.358,
      "eval_steps_per_second": 7.169,
      "step": 19000
    },
    {
      "epoch": 5.418118466898955,
      "grad_norm": 4.1388068199157715,
      "learning_rate": 1.0182657059790166e-05,
      "loss": 0.1637,
      "step": 19050
    },
    {
      "epoch": 5.432340183460144,
      "grad_norm": 3.878958225250244,
      "learning_rate": 1.0151055492352422e-05,
      "loss": 0.1595,
      "step": 19100
    },
    {
      "epoch": 5.446561900021333,
      "grad_norm": 2.961740493774414,
      "learning_rate": 1.0119453924914677e-05,
      "loss": 0.1668,
      "step": 19150
    },
    {
      "epoch": 5.460783616582521,
      "grad_norm": 4.788749694824219,
      "learning_rate": 1.0087852357476932e-05,
      "loss": 0.1564,
      "step": 19200
    },
    {
      "epoch": 5.47500533314371,
      "grad_norm": 6.938267707824707,
      "learning_rate": 1.0056250790039186e-05,
      "loss": 0.1673,
      "step": 19250
    },
    {
      "epoch": 5.489227049704899,
      "grad_norm": 2.779574394226074,
      "learning_rate": 1.002464922260144e-05,
      "loss": 0.1608,
      "step": 19300
    },
    {
      "epoch": 5.5034487662660885,
      "grad_norm": 3.0655875205993652,
      "learning_rate": 9.993047655163697e-06,
      "loss": 0.1662,
      "step": 19350
    },
    {
      "epoch": 5.517670482827278,
      "grad_norm": 2.6096651554107666,
      "learning_rate": 9.961446087725952e-06,
      "loss": 0.1544,
      "step": 19400
    },
    {
      "epoch": 5.531892199388466,
      "grad_norm": 4.0794758796691895,
      "learning_rate": 9.929844520288207e-06,
      "loss": 0.1539,
      "step": 19450
    },
    {
      "epoch": 5.546113915949655,
      "grad_norm": 2.4197676181793213,
      "learning_rate": 9.898242952850462e-06,
      "loss": 0.1688,
      "step": 19500
    },
    {
      "epoch": 5.560335632510844,
      "grad_norm": 2.675513744354248,
      "learning_rate": 9.866641385412717e-06,
      "loss": 0.1618,
      "step": 19550
    },
    {
      "epoch": 5.574557349072033,
      "grad_norm": 4.397250175476074,
      "learning_rate": 9.835039817974974e-06,
      "loss": 0.1667,
      "step": 19600
    },
    {
      "epoch": 5.588779065633222,
      "grad_norm": 5.789759159088135,
      "learning_rate": 9.803438250537227e-06,
      "loss": 0.1661,
      "step": 19650
    },
    {
      "epoch": 5.603000782194411,
      "grad_norm": 3.6866629123687744,
      "learning_rate": 9.771836683099482e-06,
      "loss": 0.1735,
      "step": 19700
    },
    {
      "epoch": 5.617222498755599,
      "grad_norm": 5.204658031463623,
      "learning_rate": 9.740235115661739e-06,
      "loss": 0.1538,
      "step": 19750
    },
    {
      "epoch": 5.6314442153167885,
      "grad_norm": 2.710986852645874,
      "learning_rate": 9.708633548223992e-06,
      "loss": 0.1539,
      "step": 19800
    },
    {
      "epoch": 5.645665931877978,
      "grad_norm": 4.68524694442749,
      "learning_rate": 9.677031980786248e-06,
      "loss": 0.1627,
      "step": 19850
    },
    {
      "epoch": 5.659887648439167,
      "grad_norm": 1.8406726121902466,
      "learning_rate": 9.645430413348503e-06,
      "loss": 0.1639,
      "step": 19900
    },
    {
      "epoch": 5.674109365000356,
      "grad_norm": 2.2148497104644775,
      "learning_rate": 9.613828845910758e-06,
      "loss": 0.1678,
      "step": 19950
    },
    {
      "epoch": 5.688331081561545,
      "grad_norm": 2.829019069671631,
      "learning_rate": 9.582227278473013e-06,
      "loss": 0.1578,
      "step": 20000
    },
    {
      "epoch": 5.688331081561545,
      "eval_f1_macro": 0.8560897368405342,
      "eval_loss": 0.40346601605415344,
      "eval_runtime": 218.0921,
      "eval_samples_per_second": 917.044,
      "eval_steps_per_second": 7.167,
      "step": 20000
    },
    {
      "epoch": 5.702552798122733,
      "grad_norm": 4.3451151847839355,
      "learning_rate": 9.550625711035268e-06,
      "loss": 0.159,
      "step": 20050
    },
    {
      "epoch": 5.716774514683922,
      "grad_norm": 2.124279499053955,
      "learning_rate": 9.519024143597523e-06,
      "loss": 0.1596,
      "step": 20100
    },
    {
      "epoch": 5.730996231245111,
      "grad_norm": 3.679018497467041,
      "learning_rate": 9.487422576159778e-06,
      "loss": 0.1599,
      "step": 20150
    },
    {
      "epoch": 5.7452179478063,
      "grad_norm": 4.7870330810546875,
      "learning_rate": 9.455821008722033e-06,
      "loss": 0.1615,
      "step": 20200
    },
    {
      "epoch": 5.759439664367489,
      "grad_norm": 3.5056490898132324,
      "learning_rate": 9.424219441284288e-06,
      "loss": 0.1669,
      "step": 20250
    },
    {
      "epoch": 5.773661380928678,
      "grad_norm": 5.950620651245117,
      "learning_rate": 9.392617873846543e-06,
      "loss": 0.1603,
      "step": 20300
    },
    {
      "epoch": 5.787883097489867,
      "grad_norm": 4.408079147338867,
      "learning_rate": 9.3610163064088e-06,
      "loss": 0.1575,
      "step": 20350
    },
    {
      "epoch": 5.802104814051056,
      "grad_norm": 2.249549388885498,
      "learning_rate": 9.329414738971053e-06,
      "loss": 0.16,
      "step": 20400
    },
    {
      "epoch": 5.816326530612245,
      "grad_norm": 3.6721115112304688,
      "learning_rate": 9.29781317153331e-06,
      "loss": 0.1641,
      "step": 20450
    },
    {
      "epoch": 5.830548247173434,
      "grad_norm": 5.5241217613220215,
      "learning_rate": 9.266211604095564e-06,
      "loss": 0.1646,
      "step": 20500
    },
    {
      "epoch": 5.844769963734623,
      "grad_norm": 4.118773937225342,
      "learning_rate": 9.23461003665782e-06,
      "loss": 0.1592,
      "step": 20550
    },
    {
      "epoch": 5.858991680295812,
      "grad_norm": 3.6378440856933594,
      "learning_rate": 9.203008469220074e-06,
      "loss": 0.1645,
      "step": 20600
    },
    {
      "epoch": 5.873213396857,
      "grad_norm": 3.0771477222442627,
      "learning_rate": 9.17140690178233e-06,
      "loss": 0.1686,
      "step": 20650
    },
    {
      "epoch": 5.8874351134181895,
      "grad_norm": 3.7514100074768066,
      "learning_rate": 9.139805334344584e-06,
      "loss": 0.1653,
      "step": 20700
    },
    {
      "epoch": 5.901656829979379,
      "grad_norm": 3.915036916732788,
      "learning_rate": 9.10820376690684e-06,
      "loss": 0.166,
      "step": 20750
    },
    {
      "epoch": 5.915878546540568,
      "grad_norm": 2.3821887969970703,
      "learning_rate": 9.076602199469094e-06,
      "loss": 0.1519,
      "step": 20800
    },
    {
      "epoch": 5.930100263101757,
      "grad_norm": 4.163029670715332,
      "learning_rate": 9.045000632031349e-06,
      "loss": 0.1696,
      "step": 20850
    },
    {
      "epoch": 5.944321979662945,
      "grad_norm": 6.217637538909912,
      "learning_rate": 9.013399064593604e-06,
      "loss": 0.1616,
      "step": 20900
    },
    {
      "epoch": 5.958543696224134,
      "grad_norm": 3.822009325027466,
      "learning_rate": 8.981797497155859e-06,
      "loss": 0.1648,
      "step": 20950
    },
    {
      "epoch": 5.972765412785323,
      "grad_norm": 3.1721792221069336,
      "learning_rate": 8.950195929718116e-06,
      "loss": 0.1575,
      "step": 21000
    },
    {
      "epoch": 5.972765412785323,
      "eval_f1_macro": 0.8610395992109688,
      "eval_loss": 0.38802969455718994,
      "eval_runtime": 218.0773,
      "eval_samples_per_second": 917.106,
      "eval_steps_per_second": 7.167,
      "step": 21000
    },
    {
      "epoch": 5.986987129346512,
      "grad_norm": 3.3847312927246094,
      "learning_rate": 8.918594362280369e-06,
      "loss": 0.1615,
      "step": 21050
    },
    {
      "epoch": 6.001137737324895,
      "grad_norm": 2.6270813941955566,
      "learning_rate": 8.886992794842626e-06,
      "loss": 0.1585,
      "step": 21100
    },
    {
      "epoch": 6.015359453886084,
      "grad_norm": 2.707531452178955,
      "learning_rate": 8.85539122740488e-06,
      "loss": 0.1307,
      "step": 21150
    },
    {
      "epoch": 6.029581170447273,
      "grad_norm": 3.6084749698638916,
      "learning_rate": 8.823789659967135e-06,
      "loss": 0.1294,
      "step": 21200
    },
    {
      "epoch": 6.043802887008462,
      "grad_norm": 6.522093772888184,
      "learning_rate": 8.79218809252939e-06,
      "loss": 0.1286,
      "step": 21250
    },
    {
      "epoch": 6.058024603569651,
      "grad_norm": 3.5816290378570557,
      "learning_rate": 8.760586525091645e-06,
      "loss": 0.134,
      "step": 21300
    },
    {
      "epoch": 6.07224632013084,
      "grad_norm": 4.6725311279296875,
      "learning_rate": 8.7289849576539e-06,
      "loss": 0.119,
      "step": 21350
    },
    {
      "epoch": 6.086468036692029,
      "grad_norm": 3.69138503074646,
      "learning_rate": 8.697383390216155e-06,
      "loss": 0.1338,
      "step": 21400
    },
    {
      "epoch": 6.100689753253218,
      "grad_norm": 3.351938009262085,
      "learning_rate": 8.66578182277841e-06,
      "loss": 0.1284,
      "step": 21450
    },
    {
      "epoch": 6.114911469814406,
      "grad_norm": 4.567198753356934,
      "learning_rate": 8.634180255340665e-06,
      "loss": 0.131,
      "step": 21500
    },
    {
      "epoch": 6.129133186375595,
      "grad_norm": 5.31956672668457,
      "learning_rate": 8.60257868790292e-06,
      "loss": 0.1304,
      "step": 21550
    },
    {
      "epoch": 6.143354902936784,
      "grad_norm": 1.812917709350586,
      "learning_rate": 8.570977120465177e-06,
      "loss": 0.1304,
      "step": 21600
    },
    {
      "epoch": 6.1575766194979735,
      "grad_norm": 4.93165397644043,
      "learning_rate": 8.539375553027432e-06,
      "loss": 0.1378,
      "step": 21650
    },
    {
      "epoch": 6.171798336059163,
      "grad_norm": 2.8161303997039795,
      "learning_rate": 8.507773985589685e-06,
      "loss": 0.1248,
      "step": 21700
    },
    {
      "epoch": 6.186020052620352,
      "grad_norm": 3.3516790866851807,
      "learning_rate": 8.476172418151942e-06,
      "loss": 0.1232,
      "step": 21750
    },
    {
      "epoch": 6.20024176918154,
      "grad_norm": 4.210117816925049,
      "learning_rate": 8.444570850714197e-06,
      "loss": 0.1357,
      "step": 21800
    },
    {
      "epoch": 6.214463485742729,
      "grad_norm": 3.8001978397369385,
      "learning_rate": 8.412969283276451e-06,
      "loss": 0.1408,
      "step": 21850
    },
    {
      "epoch": 6.228685202303918,
      "grad_norm": 3.2949652671813965,
      "learning_rate": 8.381367715838706e-06,
      "loss": 0.1284,
      "step": 21900
    },
    {
      "epoch": 6.242906918865107,
      "grad_norm": 5.464118957519531,
      "learning_rate": 8.349766148400961e-06,
      "loss": 0.1359,
      "step": 21950
    },
    {
      "epoch": 6.257128635426296,
      "grad_norm": 2.650075674057007,
      "learning_rate": 8.318164580963216e-06,
      "loss": 0.1386,
      "step": 22000
    },
    {
      "epoch": 6.257128635426296,
      "eval_f1_macro": 0.8610193721346517,
      "eval_loss": 0.431467741727829,
      "eval_runtime": 218.1459,
      "eval_samples_per_second": 916.818,
      "eval_steps_per_second": 7.165,
      "step": 22000
    },
    {
      "epoch": 6.2713503519874845,
      "grad_norm": 3.136183261871338,
      "learning_rate": 8.286563013525471e-06,
      "loss": 0.1325,
      "step": 22050
    },
    {
      "epoch": 6.285572068548674,
      "grad_norm": 3.6660661697387695,
      "learning_rate": 8.254961446087726e-06,
      "loss": 0.1329,
      "step": 22100
    },
    {
      "epoch": 6.299793785109863,
      "grad_norm": 3.2641847133636475,
      "learning_rate": 8.223359878649981e-06,
      "loss": 0.1322,
      "step": 22150
    },
    {
      "epoch": 6.314015501671052,
      "grad_norm": 2.5084872245788574,
      "learning_rate": 8.191758311212236e-06,
      "loss": 0.1411,
      "step": 22200
    },
    {
      "epoch": 6.328237218232241,
      "grad_norm": 3.017895221710205,
      "learning_rate": 8.160156743774493e-06,
      "loss": 0.135,
      "step": 22250
    },
    {
      "epoch": 6.34245893479343,
      "grad_norm": 2.7154412269592285,
      "learning_rate": 8.128555176336746e-06,
      "loss": 0.1289,
      "step": 22300
    },
    {
      "epoch": 6.356680651354618,
      "grad_norm": 5.531528949737549,
      "learning_rate": 8.096953608899003e-06,
      "loss": 0.1381,
      "step": 22350
    },
    {
      "epoch": 6.370902367915807,
      "grad_norm": 4.625243186950684,
      "learning_rate": 8.065352041461258e-06,
      "loss": 0.1369,
      "step": 22400
    },
    {
      "epoch": 6.385124084476996,
      "grad_norm": 3.29376220703125,
      "learning_rate": 8.033750474023513e-06,
      "loss": 0.1442,
      "step": 22450
    },
    {
      "epoch": 6.399345801038185,
      "grad_norm": 6.244524955749512,
      "learning_rate": 8.002148906585768e-06,
      "loss": 0.1353,
      "step": 22500
    },
    {
      "epoch": 6.4135675175993745,
      "grad_norm": 3.9215333461761475,
      "learning_rate": 7.970547339148022e-06,
      "loss": 0.14,
      "step": 22550
    },
    {
      "epoch": 6.427789234160564,
      "grad_norm": 5.151461601257324,
      "learning_rate": 7.938945771710277e-06,
      "loss": 0.1234,
      "step": 22600
    },
    {
      "epoch": 6.442010950721752,
      "grad_norm": 3.5827088356018066,
      "learning_rate": 7.907344204272532e-06,
      "loss": 0.1376,
      "step": 22650
    },
    {
      "epoch": 6.456232667282941,
      "grad_norm": 3.8280162811279297,
      "learning_rate": 7.875742636834787e-06,
      "loss": 0.1227,
      "step": 22700
    },
    {
      "epoch": 6.47045438384413,
      "grad_norm": 3.3191423416137695,
      "learning_rate": 7.844141069397044e-06,
      "loss": 0.1399,
      "step": 22750
    },
    {
      "epoch": 6.484676100405319,
      "grad_norm": 8.871683120727539,
      "learning_rate": 7.812539501959297e-06,
      "loss": 0.1273,
      "step": 22800
    },
    {
      "epoch": 6.498897816966508,
      "grad_norm": 4.325204849243164,
      "learning_rate": 7.780937934521552e-06,
      "loss": 0.1243,
      "step": 22850
    },
    {
      "epoch": 6.513119533527696,
      "grad_norm": 5.185089111328125,
      "learning_rate": 7.749336367083809e-06,
      "loss": 0.1411,
      "step": 22900
    },
    {
      "epoch": 6.527341250088885,
      "grad_norm": 8.301040649414062,
      "learning_rate": 7.717734799646062e-06,
      "loss": 0.133,
      "step": 22950
    },
    {
      "epoch": 6.5415629666500745,
      "grad_norm": 3.5607738494873047,
      "learning_rate": 7.686133232208319e-06,
      "loss": 0.1338,
      "step": 23000
    },
    {
      "epoch": 6.5415629666500745,
      "eval_f1_macro": 0.8549976962623889,
      "eval_loss": 0.41351765394210815,
      "eval_runtime": 218.03,
      "eval_samples_per_second": 917.305,
      "eval_steps_per_second": 7.169,
      "step": 23000
    },
    {
      "epoch": 6.555784683211264,
      "grad_norm": 2.788093328475952,
      "learning_rate": 7.654531664770574e-06,
      "loss": 0.1363,
      "step": 23050
    },
    {
      "epoch": 6.570006399772453,
      "grad_norm": 3.0631015300750732,
      "learning_rate": 7.622930097332828e-06,
      "loss": 0.1316,
      "step": 23100
    },
    {
      "epoch": 6.584228116333642,
      "grad_norm": 3.243628740310669,
      "learning_rate": 7.5913285298950835e-06,
      "loss": 0.1298,
      "step": 23150
    },
    {
      "epoch": 6.598449832894831,
      "grad_norm": 3.7351183891296387,
      "learning_rate": 7.5597269624573385e-06,
      "loss": 0.1353,
      "step": 23200
    },
    {
      "epoch": 6.612671549456019,
      "grad_norm": 5.179813385009766,
      "learning_rate": 7.5281253950195934e-06,
      "loss": 0.1352,
      "step": 23250
    },
    {
      "epoch": 6.626893266017208,
      "grad_norm": 3.0902559757232666,
      "learning_rate": 7.496523827581848e-06,
      "loss": 0.1263,
      "step": 23300
    },
    {
      "epoch": 6.641114982578397,
      "grad_norm": 7.995272636413574,
      "learning_rate": 7.464922260144104e-06,
      "loss": 0.1373,
      "step": 23350
    },
    {
      "epoch": 6.655336699139586,
      "grad_norm": 2.7134077548980713,
      "learning_rate": 7.433320692706358e-06,
      "loss": 0.1394,
      "step": 23400
    },
    {
      "epoch": 6.6695584157007755,
      "grad_norm": 2.191889762878418,
      "learning_rate": 7.401719125268614e-06,
      "loss": 0.1354,
      "step": 23450
    },
    {
      "epoch": 6.683780132261964,
      "grad_norm": 2.4404752254486084,
      "learning_rate": 7.370117557830869e-06,
      "loss": 0.1318,
      "step": 23500
    },
    {
      "epoch": 6.698001848823153,
      "grad_norm": 2.890408992767334,
      "learning_rate": 7.338515990393124e-06,
      "loss": 0.1478,
      "step": 23550
    },
    {
      "epoch": 6.712223565384342,
      "grad_norm": 3.165227174758911,
      "learning_rate": 7.306914422955379e-06,
      "loss": 0.1377,
      "step": 23600
    },
    {
      "epoch": 6.726445281945531,
      "grad_norm": 3.213654041290283,
      "learning_rate": 7.275312855517635e-06,
      "loss": 0.1258,
      "step": 23650
    },
    {
      "epoch": 6.74066699850672,
      "grad_norm": 1.7442078590393066,
      "learning_rate": 7.24371128807989e-06,
      "loss": 0.1274,
      "step": 23700
    },
    {
      "epoch": 6.754888715067908,
      "grad_norm": 3.9630861282348633,
      "learning_rate": 7.212109720642145e-06,
      "loss": 0.1382,
      "step": 23750
    },
    {
      "epoch": 6.769110431629097,
      "grad_norm": 4.243279457092285,
      "learning_rate": 7.1805081532043996e-06,
      "loss": 0.1305,
      "step": 23800
    },
    {
      "epoch": 6.783332148190286,
      "grad_norm": 3.7390518188476562,
      "learning_rate": 7.148906585766655e-06,
      "loss": 0.1292,
      "step": 23850
    },
    {
      "epoch": 6.7975538647514755,
      "grad_norm": 4.478607654571533,
      "learning_rate": 7.1173050183289095e-06,
      "loss": 0.1308,
      "step": 23900
    },
    {
      "epoch": 6.811775581312665,
      "grad_norm": 4.197579383850098,
      "learning_rate": 7.0857034508911644e-06,
      "loss": 0.1312,
      "step": 23950
    },
    {
      "epoch": 6.825997297873854,
      "grad_norm": 3.078422784805298,
      "learning_rate": 7.05410188345342e-06,
      "loss": 0.1419,
      "step": 24000
    },
    {
      "epoch": 6.825997297873854,
      "eval_f1_macro": 0.8599032157775338,
      "eval_loss": 0.41536325216293335,
      "eval_runtime": 218.0895,
      "eval_samples_per_second": 917.055,
      "eval_steps_per_second": 7.167,
      "step": 24000
    },
    {
      "epoch": 6.840219014435043,
      "grad_norm": 2.590371608734131,
      "learning_rate": 7.022500316015674e-06,
      "loss": 0.1298,
      "step": 24050
    },
    {
      "epoch": 6.854440730996231,
      "grad_norm": 6.538434982299805,
      "learning_rate": 6.99089874857793e-06,
      "loss": 0.1361,
      "step": 24100
    },
    {
      "epoch": 6.86866244755742,
      "grad_norm": 3.5198211669921875,
      "learning_rate": 6.959297181140185e-06,
      "loss": 0.1342,
      "step": 24150
    },
    {
      "epoch": 6.882884164118609,
      "grad_norm": 3.0477230548858643,
      "learning_rate": 6.92769561370244e-06,
      "loss": 0.1294,
      "step": 24200
    },
    {
      "epoch": 6.897105880679798,
      "grad_norm": 2.8356027603149414,
      "learning_rate": 6.896094046264695e-06,
      "loss": 0.1396,
      "step": 24250
    },
    {
      "epoch": 6.911327597240987,
      "grad_norm": 5.341462135314941,
      "learning_rate": 6.864492478826951e-06,
      "loss": 0.1334,
      "step": 24300
    },
    {
      "epoch": 6.9255493138021755,
      "grad_norm": 4.081827640533447,
      "learning_rate": 6.832890911389205e-06,
      "loss": 0.1357,
      "step": 24350
    },
    {
      "epoch": 6.939771030363365,
      "grad_norm": 3.0212366580963135,
      "learning_rate": 6.801289343951461e-06,
      "loss": 0.14,
      "step": 24400
    },
    {
      "epoch": 6.953992746924554,
      "grad_norm": 3.120161294937134,
      "learning_rate": 6.769687776513716e-06,
      "loss": 0.1325,
      "step": 24450
    },
    {
      "epoch": 6.968214463485743,
      "grad_norm": 4.6781110763549805,
      "learning_rate": 6.7380862090759706e-06,
      "loss": 0.1365,
      "step": 24500
    },
    {
      "epoch": 6.982436180046932,
      "grad_norm": 3.725191593170166,
      "learning_rate": 6.7064846416382255e-06,
      "loss": 0.1288,
      "step": 24550
    },
    {
      "epoch": 6.996657896608121,
      "grad_norm": 4.8218560218811035,
      "learning_rate": 6.674883074200481e-06,
      "loss": 0.131,
      "step": 24600
    },
    {
      "epoch": 7.010808504586503,
      "grad_norm": 3.328596830368042,
      "learning_rate": 6.643281506762735e-06,
      "loss": 0.1123,
      "step": 24650
    },
    {
      "epoch": 7.025030221147692,
      "grad_norm": 3.3266091346740723,
      "learning_rate": 6.611679939324991e-06,
      "loss": 0.1052,
      "step": 24700
    },
    {
      "epoch": 7.039251937708881,
      "grad_norm": 4.409760475158691,
      "learning_rate": 6.580078371887246e-06,
      "loss": 0.0987,
      "step": 24750
    },
    {
      "epoch": 7.0534736542700704,
      "grad_norm": 4.892301559448242,
      "learning_rate": 6.548476804449502e-06,
      "loss": 0.104,
      "step": 24800
    },
    {
      "epoch": 7.0676953708312595,
      "grad_norm": 3.9536635875701904,
      "learning_rate": 6.516875237011756e-06,
      "loss": 0.1203,
      "step": 24850
    },
    {
      "epoch": 7.081917087392449,
      "grad_norm": 3.4676761627197266,
      "learning_rate": 6.485273669574012e-06,
      "loss": 0.1085,
      "step": 24900
    },
    {
      "epoch": 7.096138803953637,
      "grad_norm": 3.722076892852783,
      "learning_rate": 6.453672102136267e-06,
      "loss": 0.1133,
      "step": 24950
    },
    {
      "epoch": 7.110360520514826,
      "grad_norm": 3.8311116695404053,
      "learning_rate": 6.422070534698521e-06,
      "loss": 0.1103,
      "step": 25000
    },
    {
      "epoch": 7.110360520514826,
      "eval_f1_macro": 0.8589346462471061,
      "eval_loss": 0.47309553623199463,
      "eval_runtime": 218.0248,
      "eval_samples_per_second": 917.327,
      "eval_steps_per_second": 7.169,
      "step": 25000
    },
    {
      "epoch": 7.124582237076015,
      "grad_norm": 3.6320462226867676,
      "learning_rate": 6.390468967260777e-06,
      "loss": 0.1084,
      "step": 25050
    },
    {
      "epoch": 7.138803953637204,
      "grad_norm": 2.5269153118133545,
      "learning_rate": 6.3588673998230325e-06,
      "loss": 0.119,
      "step": 25100
    },
    {
      "epoch": 7.153025670198393,
      "grad_norm": 5.239440441131592,
      "learning_rate": 6.327265832385287e-06,
      "loss": 0.1113,
      "step": 25150
    },
    {
      "epoch": 7.167247386759582,
      "grad_norm": 4.896716117858887,
      "learning_rate": 6.2956642649475416e-06,
      "loss": 0.1029,
      "step": 25200
    },
    {
      "epoch": 7.1814691033207705,
      "grad_norm": 6.332510948181152,
      "learning_rate": 6.264062697509797e-06,
      "loss": 0.1116,
      "step": 25250
    },
    {
      "epoch": 7.19569081988196,
      "grad_norm": 2.924973964691162,
      "learning_rate": 6.2324611300720514e-06,
      "loss": 0.1067,
      "step": 25300
    },
    {
      "epoch": 7.209912536443149,
      "grad_norm": 2.954179048538208,
      "learning_rate": 6.200859562634307e-06,
      "loss": 0.1067,
      "step": 25350
    },
    {
      "epoch": 7.224134253004338,
      "grad_norm": 6.681628704071045,
      "learning_rate": 6.169257995196562e-06,
      "loss": 0.1123,
      "step": 25400
    },
    {
      "epoch": 7.238355969565527,
      "grad_norm": 2.7338614463806152,
      "learning_rate": 6.137656427758817e-06,
      "loss": 0.1045,
      "step": 25450
    },
    {
      "epoch": 7.252577686126715,
      "grad_norm": 5.343385696411133,
      "learning_rate": 6.106054860321072e-06,
      "loss": 0.1155,
      "step": 25500
    },
    {
      "epoch": 7.266799402687904,
      "grad_norm": 3.447800636291504,
      "learning_rate": 6.074453292883328e-06,
      "loss": 0.1053,
      "step": 25550
    },
    {
      "epoch": 7.281021119249093,
      "grad_norm": 2.4166951179504395,
      "learning_rate": 6.042851725445582e-06,
      "loss": 0.1033,
      "step": 25600
    },
    {
      "epoch": 7.295242835810282,
      "grad_norm": 4.236661434173584,
      "learning_rate": 6.011250158007838e-06,
      "loss": 0.1053,
      "step": 25650
    },
    {
      "epoch": 7.309464552371471,
      "grad_norm": 4.77406644821167,
      "learning_rate": 5.979648590570093e-06,
      "loss": 0.1091,
      "step": 25700
    },
    {
      "epoch": 7.3236862689326605,
      "grad_norm": 4.24624490737915,
      "learning_rate": 5.9480470231323485e-06,
      "loss": 0.1116,
      "step": 25750
    },
    {
      "epoch": 7.337907985493849,
      "grad_norm": 2.7060418128967285,
      "learning_rate": 5.916445455694603e-06,
      "loss": 0.1147,
      "step": 25800
    },
    {
      "epoch": 7.352129702055038,
      "grad_norm": 4.7939910888671875,
      "learning_rate": 5.8848438882568584e-06,
      "loss": 0.1067,
      "step": 25850
    },
    {
      "epoch": 7.366351418616227,
      "grad_norm": 3.3142898082733154,
      "learning_rate": 5.853242320819113e-06,
      "loss": 0.1092,
      "step": 25900
    },
    {
      "epoch": 7.380573135177416,
      "grad_norm": 3.8690531253814697,
      "learning_rate": 5.821640753381368e-06,
      "loss": 0.1109,
      "step": 25950
    },
    {
      "epoch": 7.394794851738605,
      "grad_norm": 4.503002166748047,
      "learning_rate": 5.790039185943623e-06,
      "loss": 0.1111,
      "step": 26000
    },
    {
      "epoch": 7.394794851738605,
      "eval_f1_macro": 0.8613606554762723,
      "eval_loss": 0.5010526776313782,
      "eval_runtime": 218.1358,
      "eval_samples_per_second": 916.86,
      "eval_steps_per_second": 7.165,
      "step": 26000
    },
    {
      "epoch": 7.409016568299794,
      "grad_norm": 5.292129039764404,
      "learning_rate": 5.758437618505879e-06,
      "loss": 0.1076,
      "step": 26050
    },
    {
      "epoch": 7.423238284860982,
      "grad_norm": 4.312017440795898,
      "learning_rate": 5.726836051068133e-06,
      "loss": 0.1061,
      "step": 26100
    },
    {
      "epoch": 7.4374600014221715,
      "grad_norm": 4.0601582527160645,
      "learning_rate": 5.695234483630388e-06,
      "loss": 0.1242,
      "step": 26150
    },
    {
      "epoch": 7.4516817179833605,
      "grad_norm": 6.505219459533691,
      "learning_rate": 5.663632916192644e-06,
      "loss": 0.1115,
      "step": 26200
    },
    {
      "epoch": 7.46590343454455,
      "grad_norm": 4.12226676940918,
      "learning_rate": 5.632031348754898e-06,
      "loss": 0.1139,
      "step": 26250
    },
    {
      "epoch": 7.480125151105739,
      "grad_norm": 2.420093536376953,
      "learning_rate": 5.600429781317154e-06,
      "loss": 0.1036,
      "step": 26300
    },
    {
      "epoch": 7.494346867666928,
      "grad_norm": 4.803366184234619,
      "learning_rate": 5.568828213879409e-06,
      "loss": 0.1044,
      "step": 26350
    },
    {
      "epoch": 7.508568584228116,
      "grad_norm": 5.484000205993652,
      "learning_rate": 5.537226646441664e-06,
      "loss": 0.1022,
      "step": 26400
    },
    {
      "epoch": 7.522790300789305,
      "grad_norm": 4.504178524017334,
      "learning_rate": 5.505625079003919e-06,
      "loss": 0.1124,
      "step": 26450
    },
    {
      "epoch": 7.537012017350494,
      "grad_norm": 7.963150978088379,
      "learning_rate": 5.4740235115661745e-06,
      "loss": 0.119,
      "step": 26500
    },
    {
      "epoch": 7.551233733911683,
      "grad_norm": 2.611863851547241,
      "learning_rate": 5.4424219441284286e-06,
      "loss": 0.1104,
      "step": 26550
    },
    {
      "epoch": 7.565455450472872,
      "grad_norm": 5.909348011016846,
      "learning_rate": 5.410820376690684e-06,
      "loss": 0.1101,
      "step": 26600
    },
    {
      "epoch": 7.5796771670340615,
      "grad_norm": 2.5159544944763184,
      "learning_rate": 5.379218809252939e-06,
      "loss": 0.1141,
      "step": 26650
    },
    {
      "epoch": 7.59389888359525,
      "grad_norm": 6.512901306152344,
      "learning_rate": 5.347617241815194e-06,
      "loss": 0.1168,
      "step": 26700
    },
    {
      "epoch": 7.608120600156439,
      "grad_norm": 3.8251113891601562,
      "learning_rate": 5.316015674377449e-06,
      "loss": 0.1158,
      "step": 26750
    },
    {
      "epoch": 7.622342316717628,
      "grad_norm": 12.838051795959473,
      "learning_rate": 5.284414106939705e-06,
      "loss": 0.122,
      "step": 26800
    },
    {
      "epoch": 7.636564033278817,
      "grad_norm": 3.5804100036621094,
      "learning_rate": 5.25281253950196e-06,
      "loss": 0.109,
      "step": 26850
    },
    {
      "epoch": 7.650785749840006,
      "grad_norm": 3.7981228828430176,
      "learning_rate": 5.221210972064215e-06,
      "loss": 0.1095,
      "step": 26900
    },
    {
      "epoch": 7.665007466401194,
      "grad_norm": 4.036133289337158,
      "learning_rate": 5.18960940462647e-06,
      "loss": 0.108,
      "step": 26950
    },
    {
      "epoch": 7.679229182962383,
      "grad_norm": 3.9715099334716797,
      "learning_rate": 5.158007837188726e-06,
      "loss": 0.1032,
      "step": 27000
    },
    {
      "epoch": 7.679229182962383,
      "eval_f1_macro": 0.8593942812326618,
      "eval_loss": 0.49366047978401184,
      "eval_runtime": 218.0994,
      "eval_samples_per_second": 917.013,
      "eval_steps_per_second": 7.166,
      "step": 27000
    },
    {
      "epoch": 7.693450899523572,
      "grad_norm": 3.030025005340576,
      "learning_rate": 5.12640626975098e-06,
      "loss": 0.1085,
      "step": 27050
    },
    {
      "epoch": 7.7076726160847615,
      "grad_norm": 4.310856342315674,
      "learning_rate": 5.0948047023132356e-06,
      "loss": 0.1128,
      "step": 27100
    },
    {
      "epoch": 7.721894332645951,
      "grad_norm": 6.3903422355651855,
      "learning_rate": 5.0632031348754905e-06,
      "loss": 0.1201,
      "step": 27150
    },
    {
      "epoch": 7.73611604920714,
      "grad_norm": 4.1131110191345215,
      "learning_rate": 5.031601567437745e-06,
      "loss": 0.1055,
      "step": 27200
    },
    {
      "epoch": 7.750337765768328,
      "grad_norm": 2.978675603866577,
      "learning_rate": 5e-06,
      "loss": 0.1092,
      "step": 27250
    },
    {
      "epoch": 7.764559482329517,
      "grad_norm": 2.195495128631592,
      "learning_rate": 4.968398432562255e-06,
      "loss": 0.1098,
      "step": 27300
    },
    {
      "epoch": 7.778781198890706,
      "grad_norm": 3.4335436820983887,
      "learning_rate": 4.93679686512451e-06,
      "loss": 0.108,
      "step": 27350
    },
    {
      "epoch": 7.793002915451895,
      "grad_norm": 4.7489094734191895,
      "learning_rate": 4.905195297686765e-06,
      "loss": 0.1178,
      "step": 27400
    },
    {
      "epoch": 7.807224632013084,
      "grad_norm": 5.27225923538208,
      "learning_rate": 4.87359373024902e-06,
      "loss": 0.1021,
      "step": 27450
    },
    {
      "epoch": 7.821446348574273,
      "grad_norm": 5.07611083984375,
      "learning_rate": 4.841992162811276e-06,
      "loss": 0.1139,
      "step": 27500
    },
    {
      "epoch": 7.8356680651354615,
      "grad_norm": 4.946592807769775,
      "learning_rate": 4.810390595373531e-06,
      "loss": 0.1054,
      "step": 27550
    },
    {
      "epoch": 7.849889781696651,
      "grad_norm": 2.611365795135498,
      "learning_rate": 4.778789027935786e-06,
      "loss": 0.1084,
      "step": 27600
    },
    {
      "epoch": 7.86411149825784,
      "grad_norm": 4.348325729370117,
      "learning_rate": 4.747187460498041e-06,
      "loss": 0.1104,
      "step": 27650
    },
    {
      "epoch": 7.878333214819029,
      "grad_norm": 2.9366509914398193,
      "learning_rate": 4.715585893060296e-06,
      "loss": 0.108,
      "step": 27700
    },
    {
      "epoch": 7.892554931380218,
      "grad_norm": 4.317876815795898,
      "learning_rate": 4.683984325622552e-06,
      "loss": 0.1101,
      "step": 27750
    },
    {
      "epoch": 7.906776647941406,
      "grad_norm": 6.935853481292725,
      "learning_rate": 4.6523827581848065e-06,
      "loss": 0.1074,
      "step": 27800
    },
    {
      "epoch": 7.920998364502595,
      "grad_norm": 6.322969913482666,
      "learning_rate": 4.6207811907470615e-06,
      "loss": 0.1076,
      "step": 27850
    },
    {
      "epoch": 7.935220081063784,
      "grad_norm": 4.181331157684326,
      "learning_rate": 4.5891796233093164e-06,
      "loss": 0.1047,
      "step": 27900
    },
    {
      "epoch": 7.949441797624973,
      "grad_norm": 3.3777997493743896,
      "learning_rate": 4.557578055871571e-06,
      "loss": 0.1085,
      "step": 27950
    },
    {
      "epoch": 7.9636635141861625,
      "grad_norm": 4.597916126251221,
      "learning_rate": 4.525976488433826e-06,
      "loss": 0.1059,
      "step": 28000
    },
    {
      "epoch": 7.9636635141861625,
      "eval_f1_macro": 0.8583380282547535,
      "eval_loss": 0.48274195194244385,
      "eval_runtime": 218.0644,
      "eval_samples_per_second": 917.16,
      "eval_steps_per_second": 7.168,
      "step": 28000
    },
    {
      "epoch": 7.977885230747352,
      "grad_norm": 3.5887014865875244,
      "learning_rate": 4.494374920996082e-06,
      "loss": 0.104,
      "step": 28050
    },
    {
      "epoch": 7.99210694730854,
      "grad_norm": 4.695251941680908,
      "learning_rate": 4.462773353558337e-06,
      "loss": 0.1069,
      "step": 28100
    },
    {
      "epoch": 8.006257555286924,
      "grad_norm": 4.327525615692139,
      "learning_rate": 4.431171786120592e-06,
      "loss": 0.1008,
      "step": 28150
    },
    {
      "epoch": 8.020479271848112,
      "grad_norm": 4.381306171417236,
      "learning_rate": 4.399570218682847e-06,
      "loss": 0.0921,
      "step": 28200
    },
    {
      "epoch": 8.0347009884093,
      "grad_norm": 3.450770139694214,
      "learning_rate": 4.367968651245102e-06,
      "loss": 0.0926,
      "step": 28250
    },
    {
      "epoch": 8.04892270497049,
      "grad_norm": 2.548892021179199,
      "learning_rate": 4.336367083807358e-06,
      "loss": 0.0875,
      "step": 28300
    },
    {
      "epoch": 8.063144421531678,
      "grad_norm": 3.9846556186676025,
      "learning_rate": 4.304765516369613e-06,
      "loss": 0.0844,
      "step": 28350
    },
    {
      "epoch": 8.077366138092868,
      "grad_norm": 2.3680810928344727,
      "learning_rate": 4.273163948931867e-06,
      "loss": 0.095,
      "step": 28400
    },
    {
      "epoch": 8.091587854654056,
      "grad_norm": 7.158418655395508,
      "learning_rate": 4.241562381494123e-06,
      "loss": 0.0972,
      "step": 28450
    },
    {
      "epoch": 8.105809571215246,
      "grad_norm": 6.382047176361084,
      "learning_rate": 4.2099608140563775e-06,
      "loss": 0.0913,
      "step": 28500
    },
    {
      "epoch": 8.120031287776435,
      "grad_norm": 4.66513729095459,
      "learning_rate": 4.1783592466186325e-06,
      "loss": 0.0919,
      "step": 28550
    },
    {
      "epoch": 8.134253004337623,
      "grad_norm": 8.056142807006836,
      "learning_rate": 4.1467576791808874e-06,
      "loss": 0.0843,
      "step": 28600
    },
    {
      "epoch": 8.148474720898813,
      "grad_norm": 8.182130813598633,
      "learning_rate": 4.115156111743142e-06,
      "loss": 0.0915,
      "step": 28650
    },
    {
      "epoch": 8.162696437460001,
      "grad_norm": 2.7744266986846924,
      "learning_rate": 4.083554544305398e-06,
      "loss": 0.0934,
      "step": 28700
    },
    {
      "epoch": 8.176918154021191,
      "grad_norm": 3.171952486038208,
      "learning_rate": 4.051952976867653e-06,
      "loss": 0.0922,
      "step": 28750
    },
    {
      "epoch": 8.19113987058238,
      "grad_norm": 5.686628818511963,
      "learning_rate": 4.020351409429908e-06,
      "loss": 0.0919,
      "step": 28800
    },
    {
      "epoch": 8.205361587143567,
      "grad_norm": 5.070412635803223,
      "learning_rate": 3.988749841992163e-06,
      "loss": 0.0938,
      "step": 28850
    },
    {
      "epoch": 8.219583303704757,
      "grad_norm": 5.038537502288818,
      "learning_rate": 3.957148274554418e-06,
      "loss": 0.0915,
      "step": 28900
    },
    {
      "epoch": 8.233805020265946,
      "grad_norm": 3.452954053878784,
      "learning_rate": 3.925546707116673e-06,
      "loss": 0.0938,
      "step": 28950
    },
    {
      "epoch": 8.248026736827136,
      "grad_norm": 3.8119089603424072,
      "learning_rate": 3.893945139678929e-06,
      "loss": 0.0896,
      "step": 29000
    },
    {
      "epoch": 8.248026736827136,
      "eval_f1_macro": 0.8602762785801623,
      "eval_loss": 0.5322389602661133,
      "eval_runtime": 218.0992,
      "eval_samples_per_second": 917.014,
      "eval_steps_per_second": 7.166,
      "step": 29000
    },
    {
      "epoch": 8.262248453388324,
      "grad_norm": 1.7406822443008423,
      "learning_rate": 3.862343572241184e-06,
      "loss": 0.0833,
      "step": 29050
    },
    {
      "epoch": 8.276470169949512,
      "grad_norm": 2.8690237998962402,
      "learning_rate": 3.830742004803439e-06,
      "loss": 0.0953,
      "step": 29100
    },
    {
      "epoch": 8.290691886510702,
      "grad_norm": 3.999776840209961,
      "learning_rate": 3.7991404373656936e-06,
      "loss": 0.0878,
      "step": 29150
    },
    {
      "epoch": 8.30491360307189,
      "grad_norm": 5.9808125495910645,
      "learning_rate": 3.7675388699279485e-06,
      "loss": 0.0924,
      "step": 29200
    },
    {
      "epoch": 8.31913531963308,
      "grad_norm": 3.9156618118286133,
      "learning_rate": 3.735937302490204e-06,
      "loss": 0.0918,
      "step": 29250
    },
    {
      "epoch": 8.333357036194268,
      "grad_norm": 3.3634331226348877,
      "learning_rate": 3.704335735052459e-06,
      "loss": 0.0891,
      "step": 29300
    },
    {
      "epoch": 8.347578752755458,
      "grad_norm": 5.1425862312316895,
      "learning_rate": 3.672734167614714e-06,
      "loss": 0.0917,
      "step": 29350
    },
    {
      "epoch": 8.361800469316647,
      "grad_norm": 5.632605075836182,
      "learning_rate": 3.641132600176969e-06,
      "loss": 0.0931,
      "step": 29400
    },
    {
      "epoch": 8.376022185877835,
      "grad_norm": 4.4726152420043945,
      "learning_rate": 3.609531032739224e-06,
      "loss": 0.0885,
      "step": 29450
    },
    {
      "epoch": 8.390243902439025,
      "grad_norm": 3.786619186401367,
      "learning_rate": 3.577929465301479e-06,
      "loss": 0.0908,
      "step": 29500
    },
    {
      "epoch": 8.404465619000213,
      "grad_norm": 2.7330174446105957,
      "learning_rate": 3.5463278978637344e-06,
      "loss": 0.0902,
      "step": 29550
    },
    {
      "epoch": 8.418687335561403,
      "grad_norm": 12.848916053771973,
      "learning_rate": 3.5147263304259894e-06,
      "loss": 0.1025,
      "step": 29600
    },
    {
      "epoch": 8.432909052122591,
      "grad_norm": 4.1160807609558105,
      "learning_rate": 3.4831247629882448e-06,
      "loss": 0.0895,
      "step": 29650
    },
    {
      "epoch": 8.44713076868378,
      "grad_norm": 2.3357579708099365,
      "learning_rate": 3.4515231955504997e-06,
      "loss": 0.0944,
      "step": 29700
    },
    {
      "epoch": 8.46135248524497,
      "grad_norm": 4.353182792663574,
      "learning_rate": 3.4199216281127547e-06,
      "loss": 0.0957,
      "step": 29750
    },
    {
      "epoch": 8.475574201806158,
      "grad_norm": 4.391909122467041,
      "learning_rate": 3.38832006067501e-06,
      "loss": 0.0926,
      "step": 29800
    },
    {
      "epoch": 8.489795918367347,
      "grad_norm": 4.575143337249756,
      "learning_rate": 3.356718493237265e-06,
      "loss": 0.0926,
      "step": 29850
    },
    {
      "epoch": 8.504017634928536,
      "grad_norm": 7.335185527801514,
      "learning_rate": 3.32511692579952e-06,
      "loss": 0.0917,
      "step": 29900
    },
    {
      "epoch": 8.518239351489726,
      "grad_norm": 5.784053802490234,
      "learning_rate": 3.2935153583617753e-06,
      "loss": 0.0919,
      "step": 29950
    },
    {
      "epoch": 8.532461068050914,
      "grad_norm": 2.3620359897613525,
      "learning_rate": 3.2619137909240303e-06,
      "loss": 0.0999,
      "step": 30000
    },
    {
      "epoch": 8.532461068050914,
      "eval_f1_macro": 0.8573235106925975,
      "eval_loss": 0.522768497467041,
      "eval_runtime": 218.1826,
      "eval_samples_per_second": 916.664,
      "eval_steps_per_second": 7.164,
      "step": 30000
    },
    {
      "epoch": 8.546682784612102,
      "grad_norm": 3.896857738494873,
      "learning_rate": 3.2303122234862848e-06,
      "loss": 0.0893,
      "step": 30050
    },
    {
      "epoch": 8.560904501173292,
      "grad_norm": 2.7402777671813965,
      "learning_rate": 3.19871065604854e-06,
      "loss": 0.0894,
      "step": 30100
    },
    {
      "epoch": 8.57512621773448,
      "grad_norm": 2.975390911102295,
      "learning_rate": 3.167109088610795e-06,
      "loss": 0.0888,
      "step": 30150
    },
    {
      "epoch": 8.58934793429567,
      "grad_norm": 4.168886184692383,
      "learning_rate": 3.1355075211730505e-06,
      "loss": 0.0909,
      "step": 30200
    },
    {
      "epoch": 8.603569650856858,
      "grad_norm": 4.260794162750244,
      "learning_rate": 3.1039059537353054e-06,
      "loss": 0.0895,
      "step": 30250
    },
    {
      "epoch": 8.617791367418047,
      "grad_norm": 5.216709136962891,
      "learning_rate": 3.0723043862975604e-06,
      "loss": 0.092,
      "step": 30300
    },
    {
      "epoch": 8.632013083979237,
      "grad_norm": 4.748688697814941,
      "learning_rate": 3.0407028188598157e-06,
      "loss": 0.0919,
      "step": 30350
    },
    {
      "epoch": 8.646234800540425,
      "grad_norm": 3.5286669731140137,
      "learning_rate": 3.0091012514220707e-06,
      "loss": 0.0892,
      "step": 30400
    },
    {
      "epoch": 8.660456517101615,
      "grad_norm": 3.703465461730957,
      "learning_rate": 2.9774996839843256e-06,
      "loss": 0.0935,
      "step": 30450
    },
    {
      "epoch": 8.674678233662803,
      "grad_norm": 4.203577995300293,
      "learning_rate": 2.945898116546581e-06,
      "loss": 0.0932,
      "step": 30500
    },
    {
      "epoch": 8.688899950223991,
      "grad_norm": 2.8793785572052,
      "learning_rate": 2.914296549108836e-06,
      "loss": 0.0919,
      "step": 30550
    },
    {
      "epoch": 8.703121666785181,
      "grad_norm": 7.840094566345215,
      "learning_rate": 2.882694981671091e-06,
      "loss": 0.0867,
      "step": 30600
    },
    {
      "epoch": 8.71734338334637,
      "grad_norm": 5.024788856506348,
      "learning_rate": 2.8510934142333463e-06,
      "loss": 0.093,
      "step": 30650
    },
    {
      "epoch": 8.73156509990756,
      "grad_norm": 3.5093181133270264,
      "learning_rate": 2.8194918467956012e-06,
      "loss": 0.0919,
      "step": 30700
    },
    {
      "epoch": 8.745786816468748,
      "grad_norm": 9.741178512573242,
      "learning_rate": 2.7878902793578566e-06,
      "loss": 0.0957,
      "step": 30750
    },
    {
      "epoch": 8.760008533029938,
      "grad_norm": 4.601709365844727,
      "learning_rate": 2.7562887119201116e-06,
      "loss": 0.0928,
      "step": 30800
    },
    {
      "epoch": 8.774230249591126,
      "grad_norm": 3.9690091609954834,
      "learning_rate": 2.7246871444823665e-06,
      "loss": 0.0903,
      "step": 30850
    },
    {
      "epoch": 8.788451966152314,
      "grad_norm": 2.585315704345703,
      "learning_rate": 2.693085577044622e-06,
      "loss": 0.0861,
      "step": 30900
    },
    {
      "epoch": 8.802673682713504,
      "grad_norm": 4.702540397644043,
      "learning_rate": 2.661484009606877e-06,
      "loss": 0.0884,
      "step": 30950
    },
    {
      "epoch": 8.816895399274692,
      "grad_norm": 3.484224796295166,
      "learning_rate": 2.6298824421691318e-06,
      "loss": 0.0919,
      "step": 31000
    },
    {
      "epoch": 8.816895399274692,
      "eval_f1_macro": 0.8594851377164784,
      "eval_loss": 0.5547651052474976,
      "eval_runtime": 218.0533,
      "eval_samples_per_second": 917.207,
      "eval_steps_per_second": 7.168,
      "step": 31000
    },
    {
      "epoch": 8.831117115835882,
      "grad_norm": 4.971510887145996,
      "learning_rate": 2.598280874731387e-06,
      "loss": 0.095,
      "step": 31050
    },
    {
      "epoch": 8.84533883239707,
      "grad_norm": 2.2330069541931152,
      "learning_rate": 2.566679307293642e-06,
      "loss": 0.0916,
      "step": 31100
    },
    {
      "epoch": 8.859560548958259,
      "grad_norm": 3.940800428390503,
      "learning_rate": 2.5350777398558975e-06,
      "loss": 0.0867,
      "step": 31150
    },
    {
      "epoch": 8.873782265519448,
      "grad_norm": 4.787307262420654,
      "learning_rate": 2.503476172418152e-06,
      "loss": 0.0865,
      "step": 31200
    },
    {
      "epoch": 8.888003982080637,
      "grad_norm": 2.8547446727752686,
      "learning_rate": 2.471874604980407e-06,
      "loss": 0.0951,
      "step": 31250
    },
    {
      "epoch": 8.902225698641827,
      "grad_norm": 2.650859832763672,
      "learning_rate": 2.4402730375426623e-06,
      "loss": 0.0918,
      "step": 31300
    },
    {
      "epoch": 8.916447415203015,
      "grad_norm": 5.35350227355957,
      "learning_rate": 2.4086714701049173e-06,
      "loss": 0.0951,
      "step": 31350
    },
    {
      "epoch": 8.930669131764205,
      "grad_norm": 6.075776100158691,
      "learning_rate": 2.3770699026671727e-06,
      "loss": 0.0918,
      "step": 31400
    },
    {
      "epoch": 8.944890848325393,
      "grad_norm": 3.939025402069092,
      "learning_rate": 2.3454683352294276e-06,
      "loss": 0.0867,
      "step": 31450
    },
    {
      "epoch": 8.959112564886581,
      "grad_norm": 6.157125949859619,
      "learning_rate": 2.3138667677916826e-06,
      "loss": 0.0909,
      "step": 31500
    },
    {
      "epoch": 8.973334281447771,
      "grad_norm": 4.451195240020752,
      "learning_rate": 2.282265200353938e-06,
      "loss": 0.0931,
      "step": 31550
    },
    {
      "epoch": 8.98755599800896,
      "grad_norm": 4.562838554382324,
      "learning_rate": 2.250663632916193e-06,
      "loss": 0.0913,
      "step": 31600
    },
    {
      "epoch": 9.001706605987343,
      "grad_norm": 5.264076232910156,
      "learning_rate": 2.219062065478448e-06,
      "loss": 0.0908,
      "step": 31650
    },
    {
      "epoch": 9.015928322548532,
      "grad_norm": 4.974276542663574,
      "learning_rate": 2.1874604980407028e-06,
      "loss": 0.0833,
      "step": 31700
    },
    {
      "epoch": 9.03015003910972,
      "grad_norm": 7.949167728424072,
      "learning_rate": 2.155858930602958e-06,
      "loss": 0.0775,
      "step": 31750
    },
    {
      "epoch": 9.044371755670909,
      "grad_norm": 6.998676776885986,
      "learning_rate": 2.124257363165213e-06,
      "loss": 0.0791,
      "step": 31800
    },
    {
      "epoch": 9.058593472232099,
      "grad_norm": 8.032923698425293,
      "learning_rate": 2.092655795727468e-06,
      "loss": 0.0814,
      "step": 31850
    },
    {
      "epoch": 9.072815188793287,
      "grad_norm": 2.251675605773926,
      "learning_rate": 2.0610542282897234e-06,
      "loss": 0.0836,
      "step": 31900
    },
    {
      "epoch": 9.087036905354477,
      "grad_norm": 2.4723687171936035,
      "learning_rate": 2.0294526608519784e-06,
      "loss": 0.0824,
      "step": 31950
    },
    {
      "epoch": 9.101258621915665,
      "grad_norm": 6.12636137008667,
      "learning_rate": 1.9978510934142333e-06,
      "loss": 0.0753,
      "step": 32000
    },
    {
      "epoch": 9.101258621915665,
      "eval_f1_macro": 0.8612758528500382,
      "eval_loss": 0.5852991938591003,
      "eval_runtime": 218.0786,
      "eval_samples_per_second": 917.101,
      "eval_steps_per_second": 7.167,
      "step": 32000
    },
    {
      "epoch": 9.115480338476853,
      "grad_norm": 2.901430368423462,
      "learning_rate": 1.9662495259764887e-06,
      "loss": 0.079,
      "step": 32050
    },
    {
      "epoch": 9.129702055038043,
      "grad_norm": 9.146818161010742,
      "learning_rate": 1.9346479585387436e-06,
      "loss": 0.0743,
      "step": 32100
    },
    {
      "epoch": 9.143923771599232,
      "grad_norm": 3.9881253242492676,
      "learning_rate": 1.9030463911009988e-06,
      "loss": 0.0771,
      "step": 32150
    },
    {
      "epoch": 9.158145488160422,
      "grad_norm": 4.7526631355285645,
      "learning_rate": 1.8714448236632538e-06,
      "loss": 0.0791,
      "step": 32200
    },
    {
      "epoch": 9.17236720472161,
      "grad_norm": 5.104323387145996,
      "learning_rate": 1.839843256225509e-06,
      "loss": 0.0788,
      "step": 32250
    },
    {
      "epoch": 9.186588921282798,
      "grad_norm": 4.836315631866455,
      "learning_rate": 1.808241688787764e-06,
      "loss": 0.0829,
      "step": 32300
    },
    {
      "epoch": 9.200810637843988,
      "grad_norm": 4.907761573791504,
      "learning_rate": 1.7766401213500192e-06,
      "loss": 0.0803,
      "step": 32350
    },
    {
      "epoch": 9.215032354405176,
      "grad_norm": 4.185654640197754,
      "learning_rate": 1.7450385539122742e-06,
      "loss": 0.0762,
      "step": 32400
    },
    {
      "epoch": 9.229254070966366,
      "grad_norm": 5.224372863769531,
      "learning_rate": 1.7134369864745293e-06,
      "loss": 0.0901,
      "step": 32450
    },
    {
      "epoch": 9.243475787527554,
      "grad_norm": 2.5702669620513916,
      "learning_rate": 1.6818354190367845e-06,
      "loss": 0.0811,
      "step": 32500
    },
    {
      "epoch": 9.257697504088744,
      "grad_norm": 5.053160190582275,
      "learning_rate": 1.6502338515990392e-06,
      "loss": 0.0774,
      "step": 32550
    },
    {
      "epoch": 9.271919220649933,
      "grad_norm": 3.2515594959259033,
      "learning_rate": 1.6186322841612944e-06,
      "loss": 0.0843,
      "step": 32600
    },
    {
      "epoch": 9.28614093721112,
      "grad_norm": 3.881838083267212,
      "learning_rate": 1.5870307167235496e-06,
      "loss": 0.0771,
      "step": 32650
    },
    {
      "epoch": 9.30036265377231,
      "grad_norm": 4.498822212219238,
      "learning_rate": 1.5554291492858047e-06,
      "loss": 0.0811,
      "step": 32700
    },
    {
      "epoch": 9.314584370333499,
      "grad_norm": 3.0171170234680176,
      "learning_rate": 1.5238275818480597e-06,
      "loss": 0.0739,
      "step": 32750
    },
    {
      "epoch": 9.328806086894689,
      "grad_norm": 3.3827950954437256,
      "learning_rate": 1.4922260144103148e-06,
      "loss": 0.0753,
      "step": 32800
    },
    {
      "epoch": 9.343027803455877,
      "grad_norm": 4.564173221588135,
      "learning_rate": 1.46062444697257e-06,
      "loss": 0.0761,
      "step": 32850
    },
    {
      "epoch": 9.357249520017065,
      "grad_norm": 2.3515868186950684,
      "learning_rate": 1.4290228795348252e-06,
      "loss": 0.0713,
      "step": 32900
    },
    {
      "epoch": 9.371471236578255,
      "grad_norm": 2.710826873779297,
      "learning_rate": 1.3974213120970801e-06,
      "loss": 0.0716,
      "step": 32950
    },
    {
      "epoch": 9.385692953139444,
      "grad_norm": 3.872007369995117,
      "learning_rate": 1.3658197446593353e-06,
      "loss": 0.0814,
      "step": 33000
    },
    {
      "epoch": 9.385692953139444,
      "eval_f1_macro": 0.8601637186894882,
      "eval_loss": 0.589492678642273,
      "eval_runtime": 218.0544,
      "eval_samples_per_second": 917.202,
      "eval_steps_per_second": 7.168,
      "step": 33000
    },
    {
      "epoch": 9.399914669700633,
      "grad_norm": 2.1764912605285645,
      "learning_rate": 1.3342181772215904e-06,
      "loss": 0.0771,
      "step": 33050
    },
    {
      "epoch": 9.414136386261822,
      "grad_norm": 4.428362846374512,
      "learning_rate": 1.3026166097838456e-06,
      "loss": 0.0779,
      "step": 33100
    },
    {
      "epoch": 9.42835810282301,
      "grad_norm": 4.854575157165527,
      "learning_rate": 1.2710150423461003e-06,
      "loss": 0.0699,
      "step": 33150
    },
    {
      "epoch": 9.4425798193842,
      "grad_norm": 4.0973687171936035,
      "learning_rate": 1.2394134749083555e-06,
      "loss": 0.08,
      "step": 33200
    },
    {
      "epoch": 9.456801535945388,
      "grad_norm": 2.512420177459717,
      "learning_rate": 1.2078119074706107e-06,
      "loss": 0.0735,
      "step": 33250
    },
    {
      "epoch": 9.471023252506578,
      "grad_norm": 5.6583075523376465,
      "learning_rate": 1.1762103400328658e-06,
      "loss": 0.0849,
      "step": 33300
    },
    {
      "epoch": 9.485244969067766,
      "grad_norm": 3.7796781063079834,
      "learning_rate": 1.1446087725951208e-06,
      "loss": 0.0727,
      "step": 33350
    },
    {
      "epoch": 9.499466685628956,
      "grad_norm": 6.968571186065674,
      "learning_rate": 1.113007205157376e-06,
      "loss": 0.0801,
      "step": 33400
    },
    {
      "epoch": 9.513688402190144,
      "grad_norm": 1.8245253562927246,
      "learning_rate": 1.0814056377196309e-06,
      "loss": 0.0775,
      "step": 33450
    },
    {
      "epoch": 9.527910118751333,
      "grad_norm": 3.042792558670044,
      "learning_rate": 1.049804070281886e-06,
      "loss": 0.0782,
      "step": 33500
    },
    {
      "epoch": 9.542131835312523,
      "grad_norm": 4.875923156738281,
      "learning_rate": 1.0182025028441412e-06,
      "loss": 0.079,
      "step": 33550
    },
    {
      "epoch": 9.55635355187371,
      "grad_norm": 3.0269381999969482,
      "learning_rate": 9.866009354063964e-07,
      "loss": 0.0787,
      "step": 33600
    },
    {
      "epoch": 9.5705752684349,
      "grad_norm": 3.346668243408203,
      "learning_rate": 9.549993679686513e-07,
      "loss": 0.0795,
      "step": 33650
    },
    {
      "epoch": 9.584796984996089,
      "grad_norm": 3.6441822052001953,
      "learning_rate": 9.233978005309065e-07,
      "loss": 0.0836,
      "step": 33700
    },
    {
      "epoch": 9.599018701557277,
      "grad_norm": 3.859269142150879,
      "learning_rate": 8.917962330931615e-07,
      "loss": 0.0768,
      "step": 33750
    },
    {
      "epoch": 9.613240418118467,
      "grad_norm": 2.795952558517456,
      "learning_rate": 8.601946656554165e-07,
      "loss": 0.0835,
      "step": 33800
    },
    {
      "epoch": 9.627462134679655,
      "grad_norm": 4.552578449249268,
      "learning_rate": 8.285930982176716e-07,
      "loss": 0.0783,
      "step": 33850
    },
    {
      "epoch": 9.641683851240845,
      "grad_norm": 2.601792573928833,
      "learning_rate": 7.969915307799267e-07,
      "loss": 0.0711,
      "step": 33900
    },
    {
      "epoch": 9.655905567802034,
      "grad_norm": 5.868841648101807,
      "learning_rate": 7.653899633421819e-07,
      "loss": 0.0794,
      "step": 33950
    },
    {
      "epoch": 9.670127284363222,
      "grad_norm": 5.846611499786377,
      "learning_rate": 7.337883959044369e-07,
      "loss": 0.0906,
      "step": 34000
    },
    {
      "epoch": 9.670127284363222,
      "eval_f1_macro": 0.8606205705585958,
      "eval_loss": 0.5763850212097168,
      "eval_runtime": 218.1997,
      "eval_samples_per_second": 916.591,
      "eval_steps_per_second": 7.163,
      "step": 34000
    },
    {
      "epoch": 9.684349000924412,
      "grad_norm": 3.564739227294922,
      "learning_rate": 7.021868284666921e-07,
      "loss": 0.0801,
      "step": 34050
    },
    {
      "epoch": 9.6985707174856,
      "grad_norm": 3.2555227279663086,
      "learning_rate": 6.70585261028947e-07,
      "loss": 0.07,
      "step": 34100
    },
    {
      "epoch": 9.71279243404679,
      "grad_norm": 7.186800956726074,
      "learning_rate": 6.389836935912022e-07,
      "loss": 0.0783,
      "step": 34150
    },
    {
      "epoch": 9.727014150607978,
      "grad_norm": 5.268882751464844,
      "learning_rate": 6.073821261534572e-07,
      "loss": 0.0796,
      "step": 34200
    },
    {
      "epoch": 9.741235867169168,
      "grad_norm": 5.049280643463135,
      "learning_rate": 5.757805587157123e-07,
      "loss": 0.0775,
      "step": 34250
    },
    {
      "epoch": 9.755457583730356,
      "grad_norm": 4.7813825607299805,
      "learning_rate": 5.441789912779675e-07,
      "loss": 0.0838,
      "step": 34300
    },
    {
      "epoch": 9.769679300291545,
      "grad_norm": 3.932894229888916,
      "learning_rate": 5.125774238402225e-07,
      "loss": 0.0673,
      "step": 34350
    },
    {
      "epoch": 9.783901016852735,
      "grad_norm": 2.569417715072632,
      "learning_rate": 4.809758564024776e-07,
      "loss": 0.0712,
      "step": 34400
    },
    {
      "epoch": 9.798122733413923,
      "grad_norm": 5.094742774963379,
      "learning_rate": 4.4937428896473267e-07,
      "loss": 0.0805,
      "step": 34450
    },
    {
      "epoch": 9.812344449975113,
      "grad_norm": 3.2105557918548584,
      "learning_rate": 4.177727215269878e-07,
      "loss": 0.0745,
      "step": 34500
    },
    {
      "epoch": 9.8265661665363,
      "grad_norm": 5.945407867431641,
      "learning_rate": 3.861711540892429e-07,
      "loss": 0.0762,
      "step": 34550
    },
    {
      "epoch": 9.840787883097489,
      "grad_norm": 2.5522589683532715,
      "learning_rate": 3.5456958665149794e-07,
      "loss": 0.0751,
      "step": 34600
    },
    {
      "epoch": 9.855009599658679,
      "grad_norm": 3.6309545040130615,
      "learning_rate": 3.2296801921375305e-07,
      "loss": 0.0834,
      "step": 34650
    },
    {
      "epoch": 9.869231316219867,
      "grad_norm": 2.544480085372925,
      "learning_rate": 2.913664517760081e-07,
      "loss": 0.0816,
      "step": 34700
    },
    {
      "epoch": 9.883453032781057,
      "grad_norm": 3.1699774265289307,
      "learning_rate": 2.597648843382632e-07,
      "loss": 0.0698,
      "step": 34750
    },
    {
      "epoch": 9.897674749342245,
      "grad_norm": 5.5235490798950195,
      "learning_rate": 2.281633169005183e-07,
      "loss": 0.078,
      "step": 34800
    },
    {
      "epoch": 9.911896465903435,
      "grad_norm": 4.387147903442383,
      "learning_rate": 1.9656174946277338e-07,
      "loss": 0.0767,
      "step": 34850
    },
    {
      "epoch": 9.926118182464624,
      "grad_norm": 3.5509979724884033,
      "learning_rate": 1.6496018202502846e-07,
      "loss": 0.0742,
      "step": 34900
    },
    {
      "epoch": 9.940339899025812,
      "grad_norm": 2.5016417503356934,
      "learning_rate": 1.3335861458728354e-07,
      "loss": 0.0725,
      "step": 34950
    },
    {
      "epoch": 9.954561615587002,
      "grad_norm": 3.242623805999756,
      "learning_rate": 1.0175704714953864e-07,
      "loss": 0.0715,
      "step": 35000
    },
    {
      "epoch": 9.954561615587002,
      "eval_f1_macro": 0.859882053419511,
      "eval_loss": 0.5834800601005554,
      "eval_runtime": 218.1439,
      "eval_samples_per_second": 916.826,
      "eval_steps_per_second": 7.165,
      "step": 35000
    },
    {
      "epoch": 9.96878333214819,
      "grad_norm": 5.92598819732666,
      "learning_rate": 7.015547971179372e-08,
      "loss": 0.0734,
      "step": 35050
    },
    {
      "epoch": 9.98300504870938,
      "grad_norm": 3.219072103500366,
      "learning_rate": 3.8553912274048796e-08,
      "loss": 0.0792,
      "step": 35100
    },
    {
      "epoch": 9.997226765270568,
      "grad_norm": 2.9851887226104736,
      "learning_rate": 6.952344836303882e-09,
      "loss": 0.0756,
      "step": 35150
    }
  ],
  "logging_steps": 50,
  "max_steps": 35160,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.35879185672e+18,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
